{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27158e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import JQL, FIELDS, BASE_URL, JIRA_DOMAIN,EMAIL, MAX_RESULTS, MODULE_DEVS, VALID_STATUSES_BT, MAIL_BT_MAP, DAILY_BT_HOURS,MIN_BT_PROJECT_RATIO,PROJECT_MAP, DEFAULT_END_DATE, DEFAULT_END_DATE_with_timezone, DEFAULT_START_DATE,DEFAULT_START_DATE_with_timezone\n",
    "from token_hidden import API_TOKEN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "942e7ffe",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 219\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;66;03m# ========= Main =========\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# 1) Descargar issues base (con issuelinks)\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m     base_issues \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_issues_paged\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJQL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAIN_FIELDS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# 2) Recolectar keys de issues vinculados\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     linked_keys \u001b[38;5;241m=\u001b[39m collect_linked_issue_keys(base_issues, only_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# podÃ©s filtrar por tipo si querÃ©s\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 71\u001b[0m, in \u001b[0;36mfetch_issues_paged\u001b[1;34m(jql, fields)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m next_token:\n\u001b[0;32m     69\u001b[0m     payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnextPageToken\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m next_token\n\u001b[1;32m---> 71\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSEARCH_JQL_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHEADERS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAUTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m resp\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     73\u001b[0m data \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:716\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    730\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    463\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    466\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    467\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 468\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:463\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 463\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    467\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "from typing import List, Dict, Any, Set\n",
    "\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "# ========= Config =========\n",
    "\n",
    "\n",
    "AUTH = HTTPBasicAuth(EMAIL, API_TOKEN)\n",
    "HEADERS = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "\n",
    "# JQL principal (ajustar a lo que uses)\n",
    "JQL = \"\"\"\n",
    "project = BTP\n",
    "AND issuetype NOT IN (Epic, Sub-task, Subtarea)\n",
    "ORDER BY priority DESC, duedate ASC\n",
    "\"\"\".strip()\n",
    "\n",
    "# Campos que querÃ©s en los issues \"base\"\n",
    "MAIN_FIELDS = [\n",
    "    \"summary\",\n",
    "    \"project\",\n",
    "    \"reporter\",\n",
    "    \"assignee\",\n",
    "    \"status\",\n",
    "    \"priority\",\n",
    "    \"issuetype\",\n",
    "    \"timetracking\",\n",
    "    \"duedate\",\n",
    "    \"customfield_10016\",  # Story Points\n",
    "    \"customfield_10212\",  # MÃ³dulo (ejemplo)\n",
    "    \"customfield_10214\",\n",
    "    \"customfield_10442\",\n",
    "    \"customfield_10608\",\n",
    "    \"issuelinks\"          # Â¡necesario para ver vÃ­nculos!\n",
    "]\n",
    "\n",
    "# Campos que querÃ©s traer del issue vinculado (ademÃ¡s de summary/status/priority, etc.)\n",
    "WANTED_FIELDS = [\n",
    "    \"customfield_10209\",\n",
    "]\n",
    "\n",
    "MAX_RESULTS = 100\n",
    "CHUNK_LINKED = 50  # tamaÃ±o de lote para buscar issues vinculados\n",
    "OUT_JSON = \"jira_bt_issues.json\"\n",
    "  # opcional\n",
    "JIRA_API_ROOT = \"https://team-1583163151751.atlassian.net/rest/api/3\"\n",
    "SEARCH_JQL_URL = f\"{JIRA_API_ROOT}/search/jql\"  \n",
    "\n",
    "# ========= Funciones utilitarias =========\n",
    "def fetch_issues_paged(jql: str, fields: list[str]) -> list[dict]:\n",
    "    all_issues = []\n",
    "    next_token = None\n",
    "    while True:\n",
    "        payload = {\n",
    "            \"jql\": jql,\n",
    "            \"fields\": fields,          # lista (incluÃ­ siempre 'issuelinks')\n",
    "            \"maxResults\": MAX_RESULTS, # mismo nombre\n",
    "        }\n",
    "        if next_token:\n",
    "            payload[\"nextPageToken\"] = next_token\n",
    "\n",
    "        resp = requests.post(SEARCH_JQL_URL, headers=HEADERS, auth=AUTH, json=payload, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "\n",
    "        issues = data.get(\"issues\", [])\n",
    "        all_issues.extend(issues)\n",
    "\n",
    "        # Nueva paginaciÃ³n\n",
    "        if data.get(\"isLast\", False):\n",
    "            break\n",
    "        next_token = data.get(\"nextPageToken\")\n",
    "        if not next_token:  # fallback defensivo\n",
    "            break\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    return all_issues\n",
    "\n",
    "\n",
    "def collect_linked_issue_keys(issues: List[Dict[str, Any]], only_types: List[str] = None) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Recolecta todas las keys de inward/outward de issuelinks.\n",
    "    only_types: si lo pasÃ¡s, filtrÃ¡s por nombre de tipo de vÃ­nculo (p.ej. [\"Problem/Incident\"])\n",
    "    \"\"\"\n",
    "    keys: Set[str] = set()\n",
    "    for it in issues:\n",
    "        links = it.get(\"fields\", {}).get(\"issuelinks\", []) or []\n",
    "        for link in links:\n",
    "            if only_types and link.get(\"type\", {}).get(\"name\") not in only_types:\n",
    "                continue\n",
    "            for side in (\"outwardIssue\", \"inwardIssue\"):\n",
    "                if side in link and \"key\" in link[side]:\n",
    "                    keys.add(link[side][\"key\"])\n",
    "    print(f\"ğŸ”— Linked keys found: {len(keys)}\")\n",
    "    return keys\n",
    "\n",
    "\n",
    "def fetch_issues_by_keys(keys: list[str], fields: list[str], chunk: int = CHUNK_LINKED) -> dict[str, dict]:\n",
    "    out = {}\n",
    "    for i in range(0, len(keys), chunk):\n",
    "        slice_keys = keys[i:i+chunk]\n",
    "        jql = f\"issuekey in ({','.join(slice_keys)})\"\n",
    "\n",
    "        next_token = None\n",
    "        while True:\n",
    "            payload = {\n",
    "                \"jql\": jql,\n",
    "                \"fields\": fields,\n",
    "                \"maxResults\": 100,\n",
    "            }\n",
    "            if next_token:\n",
    "                payload[\"nextPageToken\"] = next_token\n",
    "\n",
    "            resp = requests.post(SEARCH_JQL_URL, headers=HEADERS, auth=AUTH, json=payload, timeout=30)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "\n",
    "            for issue in data.get(\"issues\", []):\n",
    "                out[issue[\"key\"]] = issue\n",
    "\n",
    "            if data.get(\"isLast\", False):\n",
    "                break\n",
    "            next_token = data.get(\"nextPageToken\")\n",
    "            if not next_token:\n",
    "                break\n",
    "            time.sleep(0.2)\n",
    "    return out\n",
    "\n",
    "def enrich_issue_links_with_fields(issues: List[Dict[str, Any]],\n",
    "                                   linked_map: Dict[str, Dict[str, Any]],\n",
    "                                   fields_to_copy: List[str]) -> None:\n",
    "    \"\"\"Inyecta 'fields_to_copy' dentro de outward/inwardIssue.fields si NO existen aÃºn en el issue base.\"\"\"\n",
    "    for it in issues:\n",
    "        links = it.get(\"fields\", {}).get(\"issuelinks\", []) or []\n",
    "        for link in links:\n",
    "            for side in (\"outwardIssue\", \"inwardIssue\"):\n",
    "                if side in link and \"key\" in link[side]:\n",
    "                    k = link[side][\"key\"]\n",
    "                    if k in linked_map:\n",
    "                        link[side].setdefault(\"fields\", {})\n",
    "                        src_fields = linked_map[k].get(\"fields\", {})\n",
    "                        for f in fields_to_copy:\n",
    "                            # â›”ï¸ Solo insertar si NO estaba definido antes\n",
    "                            if f not in link[side][\"fields\"]:\n",
    "                                link[side][\"fields\"][f] = src_fields.get(f)\n",
    "\n",
    "def check_links_integrity(before: List[Dict[str, Any]], after: List[Dict[str, Any]]) -> None:\n",
    "    \"\"\"Verifica que los vÃ­nculos crÃ­ticos como 'Blocks' no se hayan perdido tras enriquecer.\"\"\"\n",
    "    for b_issue, a_issue in zip(before, after):\n",
    "        b_links = b_issue.get(\"fields\", {}).get(\"issuelinks\", [])\n",
    "        a_links = a_issue.get(\"fields\", {}).get(\"issuelinks\", [])\n",
    "        b_blocks = {(l.get(\"type\", {}).get(\"name\"), l.get(\"outwardIssue\", {}).get(\"key\"), l.get(\"inwardIssue\", {}).get(\"key\")) for l in b_links if l.get(\"type\", {}).get(\"name\") == \"Blocks\"}\n",
    "        a_blocks = {(l.get(\"type\", {}).get(\"name\"), l.get(\"outwardIssue\", {}).get(\"key\"), l.get(\"inwardIssue\", {}).get(\"key\")) for l in a_links if l.get(\"type\", {}).get(\"name\") == \"Blocks\"}\n",
    "\n",
    "        if b_blocks != a_blocks:\n",
    "            print(f\"ğŸš¨ WARNING: Issue {b_issue['key']} had Blocks links altered!\")\n",
    "\n",
    "def flatten_links_to_csv(issues: List[Dict[str, Any]],\n",
    "                         csv_path: str,\n",
    "                         sides: List[str] = (\"outwardIssue\", \"inwardIssue\"),\n",
    "                         fields_for_flat: List[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Aplana vÃ­nculos a CSV: una fila por (issue base, vÃ­nculo).\n",
    "    fields_for_flat: columnas a sacar del vinculado (ademÃ¡s de key y type).\n",
    "    \"\"\"\n",
    "    if fields_for_flat is None:\n",
    "        fields_for_flat = [\"summary\", \"status\", \"priority\", \"duedate\", \"customfield_10016\"]\n",
    "\n",
    "    rows = []\n",
    "    for it in issues:\n",
    "        base_key = it.get(\"key\")\n",
    "        base_summary = it.get(\"fields\", {}).get(\"summary\")\n",
    "        links = it.get(\"fields\", {}).get(\"issuelinks\", []) or []\n",
    "        for link in links:\n",
    "            link_type = link.get(\"type\", {}).get(\"name\")\n",
    "            for side in sides:\n",
    "                linked = link.get(side)\n",
    "                if not linked:\n",
    "                    continue\n",
    "                lkey = linked.get(\"key\")\n",
    "                lf = (linked.get(\"fields\") or {})\n",
    "                row = {\n",
    "                    \"base_issue\": base_key,\n",
    "                    \"base_summary\": base_summary,\n",
    "                    \"link_type\": link_type or \"\",\n",
    "                    \"link_side\": side,\n",
    "                    \"linked_issue\": lkey,\n",
    "                }\n",
    "                # Agregar columnas pedidas\n",
    "                # status/priority vienen como objetos; sacar el \"name\" si existe\n",
    "                for col in fields_for_flat:\n",
    "                    val = lf.get(col)\n",
    "                    if isinstance(val, dict) and \"name\" in val:\n",
    "                        val = val[\"name\"]\n",
    "                    row[col] = val\n",
    "                rows.append(row)\n",
    "\n",
    "    # Escribir CSV\n",
    "    fieldnames = [\"base_issue\", \"base_summary\", \"link_type\", \"link_side\", \"linked_issue\"] + fields_for_flat\n",
    "    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "    print(f\"ğŸ“„ Links CSV saved: {csv_path} ({len(rows)} rows)\")\n",
    "\n",
    "\n",
    "# ========= Main =========\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Descargar issues base (con issuelinks)\n",
    "    base_issues = fetch_issues_paged(JQL, MAIN_FIELDS)\n",
    "\n",
    "    # 2) Recolectar keys de issues vinculados\n",
    "    linked_keys = collect_linked_issue_keys(base_issues, only_types=None)  # podÃ©s filtrar por tipo si querÃ©s\n",
    "\n",
    "    # 3) Traer info de issues vinculados (campos personalizados deseados)\n",
    "    linked_map = {}\n",
    "    if linked_keys:\n",
    "        linked_map = fetch_issues_by_keys(\n",
    "            list(linked_keys),\n",
    "            fields=WANTED_FIELDS,\n",
    "        )\n",
    "\n",
    "    # 4) Enriquecer los vÃ­nculos en la estructura original\n",
    "    base_issues_before = base_issues\n",
    "    if linked_map:\n",
    "        enrich_issue_links_with_fields(base_issues, linked_map, WANTED_FIELDS)\n",
    "\n",
    "    check_links_integrity(base_issues_before, base_issues)\n",
    "    # 5) Guardar JSON enriquecido\n",
    "    with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"issues\": base_issues}, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"ğŸ’¾ JSON enriched saved: {OUT_JSON}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Download epics\n",
    "def fetch_epics():\n",
    "    all_epics = {}\n",
    "\n",
    "    # Epics del proyecto\n",
    "    jql_epics = 'project = BTP AND issuetype = Epic'\n",
    "    for_epics = {\"jql\": jql_epics, \"fields\": [\"key\",\"duedate\",\"summary\"], \"maxResults\": 100}\n",
    "\n",
    "    next_token = None\n",
    "    while True:\n",
    "        payload = dict(for_epics, **({\"nextPageToken\": next_token} if next_token else {}))\n",
    "        r = requests.post(SEARCH_JQL_URL, headers=HEADERS, auth=AUTH, json=payload, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "\n",
    "        for issue in data.get(\"issues\", []):\n",
    "            epic_key = issue[\"key\"]\n",
    "            f = issue.get(\"fields\", {}) or {}\n",
    "            all_epics[epic_key] = {\n",
    "                \"due_date\": f.get(\"duedate\"),\n",
    "                \"summary\": f.get(\"summary\", \"\"),\n",
    "                \"tasks\": []\n",
    "            }\n",
    "\n",
    "            # Historias de esa Ã©pica\n",
    "            jql_stories = f'\"Epic Link\" = {epic_key}'\n",
    "            next_story = None\n",
    "            while True:\n",
    "                story_payload = {\n",
    "                    \"jql\": jql_stories,\n",
    "                    \"fields\": [\"key\",\"customfield_10016\",\"status\"],\n",
    "                    \"maxResults\": 100\n",
    "                }\n",
    "                if next_story:\n",
    "                    story_payload[\"nextPageToken\"] = next_story\n",
    "\n",
    "                sr = requests.post(SEARCH_JQL_URL, headers=HEADERS, auth=AUTH, json=story_payload, timeout=30)\n",
    "                sr.raise_for_status()\n",
    "                sd = sr.json()\n",
    "\n",
    "                for st in sd.get(\"issues\", []):\n",
    "                    sf = st.get(\"fields\", {}) or {}\n",
    "                    all_epics[epic_key][\"tasks\"].append({\n",
    "                        \"key\": st[\"key\"],\n",
    "                        \"story_points\": sf.get(\"customfield_10016\"),\n",
    "                        \"status\": (sf.get(\"status\") or {}).get(\"name\", \"Sin estado\")\n",
    "                    })\n",
    "\n",
    "                if sd.get(\"isLast\", False):\n",
    "                    break\n",
    "                next_story = sd.get(\"nextPageToken\")\n",
    "                if not next_story:\n",
    "                    break\n",
    "\n",
    "        if data.get(\"isLast\", False):\n",
    "            break\n",
    "        next_token = data.get(\"nextPageToken\")\n",
    "        if not next_token:\n",
    "            break\n",
    "\n",
    "    return all_epics\n",
    "\n",
    "epics = fetch_epics()\n",
    "\n",
    "# Guardar en archivo si lo deseas\n",
    "with open(\"epics_bt_due_lookup.json\", \"w\") as f:\n",
    "    json.dump(epics, f, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f606bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc0aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7e65b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = '346436483896-non6bmg405eh4avr5saql5m1r0r37rim.apps.googleusercontent.com'\n",
    "client_secret = '346436483896-non6bmg405eh4avr5saql5m1r0r37rim.apps.googleusercontent.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711b5556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Consultando reuniones de federicomacias (federicomacias@biamex.com)...\n",
      "ğŸ” Consultando reuniones de MartÃ­n Horn (martinhorn@biamex.com)...\n",
      "ğŸ” Consultando reuniones de Joaquin Fernandez - Carestino (joaquinfernandez@biamex.com)...\n",
      "ğŸ” Consultando reuniones de Juan Ignacio Morelis - Carestino (juanmorelis@biamex.com)...\n",
      "ğŸ” Consultando reuniones de Thiago Cabrera (thiagocabrera@biamex.com)...\n",
      "ğŸ“… federicomacias: 7 bloque(s) ocupado(s)\n",
      "   ğŸ•“ 2025-09-01 10:30 â†’ 11:00\n",
      "   ğŸ•“ 2025-09-02 10:00 â†’ 10:30\n",
      "   ğŸ•“ 2025-09-02 16:30 â†’ 17:00\n",
      "   ğŸ•“ 2025-09-04 10:00 â†’ 10:30\n",
      "   ğŸ•“ 2025-09-05 15:00 â†’ 16:00\n",
      "   ğŸ•“ 2025-09-09 10:00 â†’ 10:30\n",
      "   ğŸ•“ 2025-09-11 10:00 â†’ 10:30\n",
      "ğŸ“… MartÃ­n Horn: 72 bloque(s) ocupado(s)\n",
      "   ğŸ•“ 2025-09-01 08:30 â†’ 08:35\n",
      "   ğŸ•“ 2025-09-01 10:00 â†’ 10:30\n",
      "   ğŸ•“ 2025-09-01 11:00 â†’ 11:10\n",
      "   ğŸ•“ 2025-09-01 11:30 â†’ 12:30\n",
      "   ğŸ•“ 2025-09-01 12:30 â†’ 13:30\n",
      "   ğŸ•“ 2025-09-01 13:30 â†’ 14:30\n",
      "   ğŸ•“ 2025-09-01 14:30 â†’ 15:00\n",
      "   ğŸ•“ 2025-09-01 15:00 â†’ 15:30\n",
      "   ğŸ•“ 2025-09-01 15:30 â†’ 16:30\n",
      "   ğŸ•“ 2025-09-01 16:30 â†’ 17:00\n",
      "   ğŸ•“ 2025-09-01 17:00 â†’ 17:30\n",
      "   ğŸ•“ 2025-09-01 17:30 â†’ 17:35\n",
      "   ğŸ•“ 2025-09-01 19:00 â†’ 21:00\n",
      "   ğŸ•“ 2025-09-02 06:00 â†’ 08:00\n",
      "   ğŸ•“ 2025-09-02 10:00 â†’ 11:00\n",
      "   ğŸ•“ 2025-09-02 12:30 â†’ 13:30\n",
      "   ğŸ•“ 2025-09-02 14:30 â†’ 15:00\n",
      "   ğŸ•“ 2025-09-02 15:00 â†’ 15:30\n",
      "   ğŸ•“ 2025-09-02 16:00 â†’ 16:30\n",
      "   ğŸ•“ 2025-09-02 16:30 â†’ 17:00\n",
      "   ğŸ•“ 2025-09-02 17:30 â†’ 17:35\n",
      "   ğŸ•“ 2025-09-02 19:00 â†’ 21:00\n",
      "   ğŸ•“ 2025-09-03 10:00 â†’ 11:15\n",
      "   ğŸ•“ 2025-09-03 12:00 â†’ 13:00\n",
      "   ğŸ•“ 2025-09-03 13:00 â†’ 13:30\n",
      "   ğŸ•“ 2025-09-03 14:00 â†’ 14:45\n",
      "   ğŸ•“ 2025-09-03 15:00 â†’ 15:45\n",
      "   ğŸ•“ 2025-09-03 16:00 â†’ 16:30\n",
      "   ğŸ•“ 2025-09-03 16:30 â†’ 17:00\n",
      "   ğŸ•“ 2025-09-03 17:00 â†’ 17:30\n",
      "   ğŸ•“ 2025-09-03 17:30 â†’ 17:35\n",
      "   ğŸ•“ 2025-09-04 06:00 â†’ 08:00\n",
      "   ğŸ•“ 2025-09-04 09:30 â†’ 10:00\n",
      "   ğŸ•“ 2025-09-04 12:00 â†’ 13:00\n",
      "   ğŸ•“ 2025-09-04 13:00 â†’ 14:00\n",
      "   ğŸ•“ 2025-09-04 14:00 â†’ 15:00\n",
      "   ğŸ•“ 2025-09-04 16:00 â†’ 16:30\n",
      "   ğŸ•“ 2025-09-04 17:30 â†’ 17:35\n",
      "   ğŸ•“ 2025-09-04 19:00 â†’ 21:00\n",
      "   ğŸ•“ 2025-09-05 15:00 â†’ 16:00\n",
      "   ğŸ•“ 2025-09-05 17:30 â†’ 17:35\n",
      "   ğŸ•“ 2025-09-05 19:00 â†’ 22:00\n",
      "   ğŸ•“ 2025-09-08 09:15 â†’ 09:25\n",
      "   ğŸ•“ 2025-09-08 10:00 â†’ 10:30\n",
      "   ğŸ•“ 2025-09-08 11:30 â†’ 12:30\n",
      "   ğŸ•“ 2025-09-08 12:30 â†’ 13:15\n",
      "   ğŸ•“ 2025-09-08 14:30 â†’ 15:00\n",
      "   ğŸ•“ 2025-09-08 15:00 â†’ 15:30\n",
      "   ğŸ•“ 2025-09-08 16:30 â†’ 17:00\n",
      "   ğŸ•“ 2025-09-08 17:30 â†’ 17:35\n",
      "   ğŸ•“ 2025-09-08 19:00 â†’ 21:00\n",
      "   ğŸ•“ 2025-09-09 06:00 â†’ 08:00\n",
      "   ğŸ•“ 2025-09-09 10:00 â†’ 11:00\n",
      "   ğŸ•“ 2025-09-09 14:30 â†’ 15:00\n",
      "   ğŸ•“ 2025-09-09 15:00 â†’ 15:30\n",
      "   ğŸ•“ 2025-09-09 17:30 â†’ 17:35\n",
      "   ğŸ•“ 2025-09-09 19:00 â†’ 21:00\n",
      "   ğŸ•“ 2025-09-10 08:30 â†’ 08:31\n",
      "   ğŸ•“ 2025-09-10 10:00 â†’ 12:00\n",
      "   ğŸ•“ 2025-09-10 14:00 â†’ 14:45\n",
      "   ğŸ•“ 2025-09-10 15:00 â†’ 15:45\n",
      "   ğŸ•“ 2025-09-10 16:30 â†’ 17:00\n",
      "   ğŸ•“ 2025-09-10 17:00 â†’ 17:30\n",
      "   ğŸ•“ 2025-09-10 17:30 â†’ 19:00\n",
      "   ğŸ•“ 2025-09-10 17:30 â†’ 17:35\n",
      "   ğŸ•“ 2025-09-11 05:30 â†’ 08:30\n",
      "   ğŸ•“ 2025-09-11 06:00 â†’ 08:00\n",
      "   ğŸ•“ 2025-09-11 09:30 â†’ 10:00\n",
      "   ğŸ•“ 2025-09-11 13:00 â†’ 14:00\n",
      "   ğŸ•“ 2025-09-11 14:00 â†’ 15:00\n",
      "   ğŸ•“ 2025-09-11 17:30 â†’ 17:35\n",
      "   ğŸ•“ 2025-09-11 19:00 â†’ 21:00\n",
      "ğŸ“… Joaquin Fernandez - Carestino: 10 bloque(s) ocupado(s)\n",
      "   ğŸ•“ 2025-09-02 10:00 â†’ 11:00\n",
      "   ğŸ•“ 2025-09-02 14:00 â†’ 15:00\n",
      "   ğŸ•“ 2025-09-03 10:00 â†’ 11:15\n",
      "   ğŸ•“ 2025-09-03 17:00 â†’ 17:30\n",
      "   ğŸ•“ 2025-09-05 14:00 â†’ 15:00\n",
      "   ğŸ•“ 2025-09-08 12:30 â†’ 13:15\n",
      "   ğŸ•“ 2025-09-09 10:00 â†’ 11:00\n",
      "   ğŸ•“ 2025-09-09 14:00 â†’ 15:00\n",
      "   ğŸ•“ 2025-09-10 10:00 â†’ 12:00\n",
      "   ğŸ•“ 2025-09-10 17:00 â†’ 17:30\n",
      "ğŸ“… Juan Ignacio Morelis - Carestino: 19 bloque(s) ocupado(s)\n",
      "   ğŸ•“ 2025-09-01 13:00 â†’ 14:00\n",
      "   ğŸ•“ 2025-09-01 15:30 â†’ 16:00\n",
      "   ğŸ•“ 2025-09-02 13:45 â†’ 14:45\n",
      "   ğŸ•“ 2025-09-02 16:00 â†’ 16:30\n",
      "   ğŸ•“ 2025-09-03 10:00 â†’ 11:15\n",
      "   ğŸ•“ 2025-09-03 14:00 â†’ 14:45\n",
      "   ğŸ•“ 2025-09-03 16:45 â†’ 17:30\n",
      "   ğŸ•“ 2025-09-04 13:00 â†’ 14:00\n",
      "   ğŸ•“ 2025-09-04 14:00 â†’ 15:00\n",
      "   ğŸ•“ 2025-09-05 13:00 â†’ 14:00\n",
      "   ğŸ•“ 2025-09-06 13:00 â†’ 14:00\n",
      "   ğŸ•“ 2025-09-07 13:00 â†’ 14:00\n",
      "   ğŸ•“ 2025-09-08 13:00 â†’ 14:00\n",
      "   ğŸ•“ 2025-09-09 13:00 â†’ 14:00\n",
      "   ğŸ•“ 2025-09-10 10:00 â†’ 12:00\n",
      "   ğŸ•“ 2025-09-10 13:00 â†’ 14:00\n",
      "   ğŸ•“ 2025-09-10 14:00 â†’ 14:45\n",
      "   ğŸ•“ 2025-09-11 13:00 â†’ 14:00\n",
      "   ğŸ•“ 2025-09-11 14:00 â†’ 15:00\n",
      "ğŸ“… Thiago Cabrera: 47 bloque(s) ocupado(s)\n",
      "   ğŸ•“ 2025-09-01 08:30 â†’ 09:00\n",
      "   ğŸ•“ 2025-09-01 09:00 â†’ 11:00\n",
      "   ğŸ•“ 2025-09-01 11:00 â†’ 12:00\n",
      "   ğŸ•“ 2025-09-01 12:00 â†’ 12:30\n",
      "   ğŸ•“ 2025-09-01 12:30 â†’ 13:15\n",
      "   ğŸ•“ 2025-09-01 13:15 â†’ 13:45\n",
      "   ğŸ•“ 2025-09-01 13:45 â†’ 14:45\n",
      "   ğŸ•“ 2025-09-01 15:30 â†’ 16:00\n",
      "   ğŸ•“ 2025-09-01 16:00 â†’ 16:30\n",
      "   ğŸ•“ 2025-09-01 16:30 â†’ 17:00\n",
      "   ğŸ•“ 2025-09-02 08:30 â†’ 09:00\n",
      "   ğŸ•“ 2025-09-02 09:00 â†’ 10:15\n",
      "   ğŸ•“ 2025-09-02 10:15 â†’ 12:30\n",
      "   ğŸ•“ 2025-09-02 12:30 â†’ 13:30\n",
      "   ğŸ•“ 2025-09-02 13:30 â†’ 14:30\n",
      "   ğŸ•“ 2025-09-02 14:30 â†’ 15:00\n",
      "   ğŸ•“ 2025-09-02 15:00 â†’ 16:00\n",
      "   ğŸ•“ 2025-09-02 16:00 â†’ 16:30\n",
      "   ğŸ•“ 2025-09-03 08:45 â†’ 10:30\n",
      "   ğŸ•“ 2025-09-03 10:00 â†’ 11:15\n",
      "   ğŸ•“ 2025-09-03 10:30 â†’ 12:00\n",
      "   ğŸ•“ 2025-09-03 12:00 â†’ 12:30\n",
      "   ğŸ•“ 2025-09-03 13:00 â†’ 13:30\n",
      "   ğŸ•“ 2025-09-03 13:00 â†’ 13:30\n",
      "   ğŸ•“ 2025-09-03 13:30 â†’ 14:30\n",
      "   ğŸ•“ 2025-09-03 15:00 â†’ 15:45\n",
      "   ğŸ•“ 2025-09-03 15:45 â†’ 17:00\n",
      "   ğŸ•“ 2025-09-03 16:00 â†’ 16:15\n",
      "   ğŸ•“ 2025-09-04 08:30 â†’ 09:00\n",
      "   ğŸ•“ 2025-09-04 13:00 â†’ 14:00\n",
      "   ğŸ•“ 2025-09-04 14:00 â†’ 15:00\n",
      "   ğŸ•“ 2025-09-05 10:00 â†’ 10:15\n",
      "   ğŸ•“ 2025-09-05 13:45 â†’ 14:45\n",
      "   ğŸ•“ 2025-09-05 16:00 â†’ 16:30\n",
      "   ğŸ•“ 2025-09-08 12:00 â†’ 12:30\n",
      "   ğŸ•“ 2025-09-08 13:30 â†’ 14:30\n",
      "   ğŸ•“ 2025-09-08 16:30 â†’ 17:00\n",
      "   ğŸ•“ 2025-09-09 08:30 â†’ 09:00\n",
      "   ğŸ•“ 2025-09-09 13:30 â†’ 14:30\n",
      "   ğŸ•“ 2025-09-09 14:30 â†’ 15:00\n",
      "   ğŸ•“ 2025-09-10 10:00 â†’ 12:00\n",
      "   ğŸ•“ 2025-09-10 12:00 â†’ 12:30\n",
      "   ğŸ•“ 2025-09-10 13:30 â†’ 14:30\n",
      "   ğŸ•“ 2025-09-10 15:00 â†’ 15:45\n",
      "   ğŸ•“ 2025-09-11 08:30 â†’ 09:00\n",
      "   ğŸ•“ 2025-09-11 13:00 â†’ 14:00\n",
      "   ğŸ•“ 2025-09-11 14:00 â†’ 15:00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "from collections import defaultdict\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "# ğŸ“Œ Permisos necesarios: lectura del calendario\n",
    "SCOPES = ['https://www.googleapis.com/auth/calendar.readonly']\n",
    "\n",
    "# ğŸ“‚ Archivos de autenticaciÃ³n\n",
    "CREDENTIALS_PATH = 'client_secret.json'\n",
    "TOKEN_PATH = 'token.json'\n",
    "\n",
    "\n",
    "\n",
    "def obtener_credenciales():\n",
    "    creds = None\n",
    "    if os.path.exists(TOKEN_PATH):\n",
    "        creds = Credentials.from_authorized_user_file(TOKEN_PATH, SCOPES)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(CREDENTIALS_PATH, SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open(TOKEN_PATH, 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return creds\n",
    "\n",
    "def obtener_bloques_ocupados(email, creds, start_dt, end_dt):\n",
    "    service = build('calendar', 'v3', credentials=creds)\n",
    "    eventos_resultado = service.events().list(\n",
    "        calendarId=email,\n",
    "        timeMin=start_dt.isoformat(),\n",
    "        timeMax=end_dt.isoformat(),\n",
    "        singleEvents=True,\n",
    "        orderBy=\"startTime\"\n",
    "    ).execute()\n",
    "\n",
    "    eventos = eventos_resultado.get('items', [])\n",
    "    bloques_ocupados = []\n",
    "\n",
    "    for evento in eventos:\n",
    "        start_str = evento['start'].get('dateTime')\n",
    "        end_str = evento['end'].get('dateTime')\n",
    "        if not start_str or not end_str:\n",
    "            continue  # Omitir eventos de todo el dÃ­a\n",
    "\n",
    "        start_time = datetime.datetime.fromisoformat(start_str)\n",
    "        end_time = datetime.datetime.fromisoformat(end_str)\n",
    "        bloques_ocupados.append((start_time, end_time))\n",
    "\n",
    "    return bloques_ocupados\n",
    "\n",
    "def obtener_bloques_por_dev():\n",
    "    creds = obtener_credenciales()\n",
    "    bloques_por_dev = {}\n",
    "\n",
    "    for dev, email in MAIL_BT_MAP.items():\n",
    "        print(f\"ğŸ” Consultando reuniones de {dev} ({email})...\")\n",
    "        try:\n",
    "            bloques = obtener_bloques_ocupados(email, creds, DEFAULT_START_DATE_with_timezone, DEFAULT_END_DATE_with_timezone)\n",
    "            bloques_por_dev[dev] = bloques\n",
    "            #print(f\"   âœ… {len(bloques)} reuniones encontradas.\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Error consultando {email}: {str(e)}\\n\")\n",
    "            bloques_por_dev[dev] = []\n",
    "\n",
    "    return bloques_por_dev\n",
    "\n",
    "# Para usar de forma aislada:\n",
    "if __name__ == \"__main__\":\n",
    "    bloques = obtener_bloques_por_dev()\n",
    "    for dev, bloques_list in bloques.items():\n",
    "        print(f\"ğŸ“… {dev}: {len(bloques_list)} bloque(s) ocupado(s)\")\n",
    "        for start, end in bloques_list:\n",
    "            print(f\"   ğŸ•“ {start.strftime('%Y-%m-%d %H:%M')} â†’ {end.strftime('%H:%M')}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "761eeca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Thiago Cabrera:\n",
      "  ğŸ¯ Epic target: 50.0%\n",
      "  ğŸ“Š Total in range: 1.0 h | Epic in range: 0.0 h\n",
      "  ğŸ” Epic tasks out of range: 0\n",
      "\n",
      "ğŸ” federicomacias:\n",
      "  ğŸ¯ Epic target: 70.0%\n",
      "  ğŸ“Š Total in range: 6.0 h | Epic in range: 0.0 h\n",
      "  ğŸ” Epic tasks out of range: 2\n",
      "    - BTP-3524 (6.0 h) due 2025-09-18\n",
      "    - BTP-2865 (0 h) due 2100-01-01\n",
      " modificando BTP-3524 due 2100-01-01\n",
      "âœ”ï¸ Ratio tras forzar BTP-3524: 6.0 / (60.0) = 10.0%\n",
      " modificando BTP-2865 due 2100-01-01\n",
      "âœ”ï¸ Ratio tras forzar BTP-2865: 6.0 / (60.0) = 10.0%\n",
      "\n",
      "ğŸ” Alan Fernandez:\n",
      "  ğŸ¯ Epic target: 50.0%\n",
      "  ğŸ“Š Total in range: 0.0 h | Epic in range: 0.0 h\n",
      "  ğŸ” Epic tasks out of range: 33\n",
      "    - BTP-2348 (0 h) due 2024-06-28\n",
      "    - BTP-2347 (0 h) due 2024-06-28\n",
      "    - BTP-2346 (0 h) due 2024-06-28\n",
      "    - BTP-2345 (0 h) due 2024-06-28\n",
      "    - BTP-2344 (0 h) due 2024-06-28\n",
      "    - BTP-2343 (0 h) due 2024-06-28\n",
      "    - BTP-2342 (0 h) due 2024-06-28\n",
      "    - BTP-2334 (0 h) due 2024-06-28\n",
      "    - BTP-2333 (0 h) due 2024-06-28\n",
      "    - BTP-2332 (0 h) due 2024-06-28\n",
      "    - BTP-2331 (0 h) due 2024-06-28\n",
      "    - BTP-2330 (0 h) due 2024-06-28\n",
      "    - BTP-2329 (0 h) due 2024-06-28\n",
      "    - BTP-2328 (0 h) due 2024-06-28\n",
      "    - BTP-2327 (0 h) due 2024-06-28\n",
      "    - BTP-2326 (0 h) due 2024-06-28\n",
      "    - BTP-2325 (0 h) due 2024-06-28\n",
      "    - BTP-2324 (0 h) due 2024-06-28\n",
      "    - BTP-2323 (0 h) due 2024-06-28\n",
      "    - BTP-2322 (0 h) due 2024-06-28\n",
      "    - BTP-2321 (0 h) due 2024-06-28\n",
      "    - BTP-2320 (0 h) due 2024-06-28\n",
      "    - BTP-2319 (0 h) due 2024-06-28\n",
      "    - BTP-2318 (0 h) due 2024-06-28\n",
      "    - BTP-2317 (0 h) due 2024-06-28\n",
      "    - BTP-2316 (0 h) due 2024-06-28\n",
      "    - BTP-2315 (0 h) due 2024-06-28\n",
      "    - BTP-2314 (0 h) due 2024-06-28\n",
      "    - BTP-2313 (0 h) due 2024-06-28\n",
      "    - BTP-2312 (0 h) due 2024-06-28\n",
      "    - BTP-2311 (0 h) due 2024-06-28\n",
      "    - BTP-2310 (0 h) due 2024-06-28\n",
      "    - BTP-2309 (0 h) due 2024-06-28\n",
      " modificando BTP-2348 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2348: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2347 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2347: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2346 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2346: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2345 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2345: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2344 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2344: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2343 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2343: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2342 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2342: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2334 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2334: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2333 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2333: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2332 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2332: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2331 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2331: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2330 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2330: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2329 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2329: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2328 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2328: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2327 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2327: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2326 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2326: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2325 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2325: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2324 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2324: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2323 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2323: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2322 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2322: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2321 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2321: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2320 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2320: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2319 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2319: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2318 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2318: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2317 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2317: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2316 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2316: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2315 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2315: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2314 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2314: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2313 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2313: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2312 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2312: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2311 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2311: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2310 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2310: 0.0 / (60.0) = 0.0%\n",
      " modificando BTP-2309 due 2024-06-28\n",
      "âœ”ï¸ Ratio tras forzar BTP-2309: 0.0 / (60.0) = 0.0%\n",
      "â­ï¸ Skipping Alan Fernandez (sin bloques definidos)\n",
      "\n",
      "ğŸ” Alejandro Lopez - Carestino:\n",
      "  ğŸ¯ Epic target: 50.0%\n",
      "  ğŸ“Š Total in range: 0.0 h | Epic in range: 0.0 h\n",
      "  ğŸ” Epic tasks out of range: 0\n",
      "â­ï¸ Skipping Alejandro Lopez - Carestino (sin bloques definidos)\n",
      "\n",
      "ğŸ” Agustin Zanetta:\n",
      "  ğŸ¯ Epic target: 50.0%\n",
      "  ğŸ“Š Total in range: 0.0 h | Epic in range: 0.0 h\n",
      "  ğŸ” Epic tasks out of range: 0\n",
      "â­ï¸ Skipping Agustin Zanetta (sin bloques definidos)\n",
      "\n",
      "ğŸ” Joaquin Fernandez - Carestino:\n",
      "  ğŸ¯ Epic target: 30.0%\n",
      "  ğŸ“Š Total in range: 2.0 h | Epic in range: 0.0 h\n",
      "  ğŸ” Epic tasks out of range: 2\n",
      "    - BTP-3301 (8.0 h) due 2025-06-14\n",
      "    - BTP-3296 (3.0 h) due 2025-06-30\n",
      " modificando BTP-3301 due 2025-06-30\n",
      "âœ”ï¸ Ratio tras forzar BTP-3301: 8.0 / (60.0) = 13.3%\n",
      " modificando BTP-3296 due 2025-06-30\n",
      "âœ”ï¸ Ratio tras forzar BTP-3296: 11.0 / (60.0) = 18.3%\n",
      "\n",
      "ğŸ” MartÃ­n Horn:\n",
      "  ğŸ¯ Epic target: 50.0%\n",
      "  ğŸ“Š Total in range: 0.0 h | Epic in range: 0.0 h\n",
      "  ğŸ” Epic tasks out of range: 0\n",
      "\n",
      "ğŸ” Juan Ignacio Morelis - Carestino:\n",
      "  ğŸ¯ Epic target: 50.0%\n",
      "  ğŸ“Š Total in range: 0.0 h | Epic in range: 0.0 h\n",
      "  ğŸ” Epic tasks out of range: 1\n",
      "    - BTP-3611 (9.0 h) due 2025-11-01\n",
      " modificando BTP-3611 due 2025-11-01\n",
      "âœ”ï¸ Ratio tras forzar BTP-3611: 9.0 / (60.0) = 15.0%\n",
      "\n",
      "ğŸ“ Developer Task Schedule Summary:\n",
      "\n",
      "ğŸ‘¨â€ğŸ’» Developer: Thiago Cabrera\n",
      "   ğŸ”¹ BTP-3490: 3.0h â†’ Due: 2025-08-28 | Finish: Start: 2025-09-01 14:45 | End: 2025-09-03 13:00\n",
      "   ğŸ”¹ BTP-3553: 1.0h â†’ Due: 2025-09-09 | Finish: Start: 2025-09-03 14:30 | End: 2025-09-03 17:30\n",
      "   ğŸ”¹ BTP-3573: 0.5h â†’ Due: 2025-09-25 | Finish: Start: 2025-09-04 09:00 | End: 2025-09-04 09:30\n",
      "   ğŸ”¹ BTP-3567: 1.0h â†’ Due: 2025-10-16 | Finish: Start: 2025-09-04 09:30 | End: 2025-09-04 10:30\n",
      "   ğŸ”¹ BTP-3565: 0.5h â†’ Due: 2025-11-07 | Finish: Start: 2025-09-04 10:30 | End: 2025-09-04 11:00\n",
      "   ğŸ”¹ BTP-3511: 0.2h â†’ Due: 2025-11-07 | Finish: Start: 2025-09-04 11:00 | End: 2025-09-04 11:15\n",
      "   ğŸ”¹ BTP-3476: 0.2h â†’ Due: 2025-11-20 | Finish: Start: 2025-09-04 11:15 | End: 2025-09-04 11:30\n",
      "   ğŸ”¹ BTP-3493: 3.0h â†’ Due: 2025-11-28 | Finish: Start: 2025-09-04 11:30 | End: 2025-09-05 11:15\n",
      "   ğŸ”¹ BTP-3618: 0.5h â†’ Due: 2025-12-31 | Finish: Start: 2025-09-05 11:15 | End: 2025-09-05 11:45\n",
      "   ğŸ”¹ BTP-3302: 15.0h â†’ Due: 2100-01-01 | Finish: Start: 2025-09-08 08:30 | End: 2025-09-12 11:30\n",
      "   ğŸ”¹ BTP-3617: 0.5h â†’ Due: 2100-01-01 | Finish: Start: 2025-09-15 08:30 | End: 2025-09-15 09:00\n",
      "\n",
      "ğŸ‘¨â€ğŸ’» Developer: federicomacias\n",
      "   ğŸ”¹ BTP-3524: 6.0h â†’ Due: 2025-09-01 | Finish: Start: 2025-09-01 08:30 | End: 2025-09-01 15:00\n",
      "   ğŸ”¹ BTP-3104: 6.0h â†’ Due: 2025-09-12 | Finish: Start: 2025-09-02 08:30 | End: 2025-09-02 15:00\n",
      "   ğŸ”¹ BTP-3437: 4.0h â†’ Due: 2025-10-14 | Finish: Start: 2025-09-03 08:30 | End: 2025-09-03 12:30\n",
      "   ğŸ”¹ BTP-3554: 4.0h â†’ Due: 2025-10-24 | Finish: Start: 2025-09-03 12:30 | End: 2025-09-04 11:00\n",
      "   ğŸ”¹ BTP-3501: 6.0h â†’ Due: 2025-10-29 | Finish: Start: 2025-09-04 11:00 | End: 2025-09-05 10:30\n",
      "   ğŸ”¹ BTP-3455: 6.0h â†’ Due: 2025-11-28 | Finish: Start: 2025-09-05 10:30 | End: 2025-09-08 10:30\n",
      "   ğŸ”¹ BTP-3506: 4.0h â†’ Due: 2025-12-19 | Finish: Start: 2025-09-08 10:30 | End: 2025-09-08 14:30\n",
      "\n",
      "ğŸ‘¨â€ğŸ’» Developer: Alan Fernandez\n",
      "\n",
      "ğŸ‘¨â€ğŸ’» Developer: Alejandro Lopez - Carestino\n",
      "\n",
      "ğŸ‘¨â€ğŸ’» Developer: Agustin Zanetta\n",
      "\n",
      "ğŸ‘¨â€ğŸ’» Developer: Joaquin Fernandez - Carestino\n",
      "   ğŸ”¹ BTP-3301: 8.0h â†’ Due: 2025-09-01 | Finish: Start: 2025-09-01 08:30 | End: 2025-09-02 11:30\n",
      "   ğŸ”¹ BTP-3296: 3.0h â†’ Due: 2025-09-01 | Finish: Start: 2025-09-02 11:30 | End: 2025-09-02 15:30\n",
      "   ğŸ”¹ BTP-3269: 2.0h â†’ Due: 2025-09-05 | Finish: Start: 2025-09-02 15:30 | End: 2025-09-03 09:30\n",
      "\n",
      "ğŸ‘¨â€ğŸ’» Developer: MartÃ­n Horn\n",
      "   ğŸ”¹ BTP-3612: 4.0h â†’ Due: 2025-09-24 | Finish: Start: 2025-09-01 08:35 | End: 2025-09-02 11:15\n",
      "   ğŸ”¹ BTP-3577: 1.0h â†’ Due: 2025-11-07 | Finish: Start: 2025-09-02 11:15 | End: 2025-09-02 12:15\n",
      "     ğŸš¨ Puede derivarse a: Alan Mori - Carestino\n",
      "   ğŸ”¹ BTP-3552: 2.0h â†’ Due: 2025-11-18 | Finish: Start: 2025-09-02 12:15 | End: 2025-09-02 17:15\n",
      "   ğŸ”¹ BTP-3560: 1.0h â†’ Due: 2025-11-20 | Finish: Start: 2025-09-02 17:15 | End: 2025-09-03 09:15\n",
      "   ğŸ”¹ BTP-3597: 1.0h â†’ Due: 2025-12-26 | Finish: Start: 2025-09-03 09:15 | End: 2025-09-03 11:30\n",
      "\n",
      "ğŸ‘¨â€ğŸ’» Developer: Juan Ignacio Morelis - Carestino\n",
      "   ğŸ”¹ BTP-3611: 9.0h â†’ Due: 2025-09-01 | Finish: Start: 2025-09-01 08:30 | End: 2025-09-02 11:30\n",
      "   ğŸ”¹ BTP-3491: 4.0h â†’ Due: 2025-10-01 | Finish: Start: 2025-09-02 11:30 | End: 2025-09-03 09:30\n",
      "   ğŸ”¹ BTP-3449: 3.0h â†’ Due: 2025-10-17 | Finish: Start: 2025-09-03 09:30 | End: 2025-09-03 13:45\n",
      "   ğŸ”¹ BTP-3494: 2.0h â†’ Due: 2025-11-28 | Finish: Start: 2025-09-03 13:45 | End: 2025-09-03 16:30\n",
      "   ğŸ”¹ BTP-3492: 2.0h â†’ Due: 2025-11-28 | Finish: Start: 2025-09-04 08:30 | End: 2025-09-04 10:30\n",
      "   ğŸ”¹ BTP-3589: 1.0h â†’ Due: 2025-12-31 | Finish: Start: 2025-09-04 10:30 | End: 2025-09-04 11:30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# === LOAD DATA ===\n",
    "with open(\"jira_bt_issues.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    issues = json.load(f)[\"issues\"]\n",
    "\n",
    "with open(\"epics_bt_due_lookup.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    epic_due_lookup = json.load(f)\n",
    "\n",
    "scheduled = []\n",
    "tasks_by_dev = {}\n",
    "issue_map = {}\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "def _opt_value(v):\n",
    "    \"\"\"Si es opciÃ³n (dict), devuelve .value/.name; si es lista, lista de values; otro -> tal cual.\"\"\"\n",
    "    if isinstance(v, dict):\n",
    "        return v.get(\"value\") or v.get(\"name\")\n",
    "    if isinstance(v, list):\n",
    "        out = []\n",
    "        for x in v:\n",
    "            out.append(x.get(\"value\") or x.get(\"name\") if isinstance(x, dict) else x)\n",
    "        return out\n",
    "    return v\n",
    "\n",
    "def get_cf10209_from_sd_outward(f_fields, only_link_type=None):\n",
    "    \"\"\"\n",
    "    Busca en f_fields['issuelinks'] un outwardIssue cuya key empiece con 'SD-'\n",
    "    y devuelve customfield_10209 (normalizado). Si only_link_type se setea,\n",
    "    filtra por el nombre del tipo de vÃ­nculo (p.ej. 'Problem/Incident').\n",
    "    \"\"\"\n",
    "    links = f_fields.get(\"issuelinks\") or []\n",
    "    for link in links:\n",
    "        if only_link_type and link.get(\"type\", {}).get(\"name\") != only_link_type:\n",
    "            continue\n",
    "        out = link.get(\"outwardIssue\")\n",
    "        if not out:\n",
    "            continue\n",
    "        if not str(out.get(\"key\", \"\")).startswith(\"SD-\"):\n",
    "            continue\n",
    "        lfields = (out.get(\"fields\") or {})\n",
    "        val = _opt_value(lfields.get(\"customfield_10209\"))\n",
    "        if val:\n",
    "            return val\n",
    "    return None\n",
    "\n",
    "def get_epic_key(fields):\n",
    "    \"\"\"\n",
    "    Devuelve la key de la Ã©pica asociada al issue (si existe), probando:\n",
    "    1) customfield_10008 (Epic Link) â€“ clÃ¡sico\n",
    "    2) parent.key si el parent es de tipo 'Epic' â€“ team-managed\n",
    "    3) fields['epic'] (algunas instancias Cloud)\n",
    "    \"\"\"\n",
    "    # 1) Epic Link clÃ¡sico\n",
    "    epic_link = fields.get(\"customfield_10008\")\n",
    "    if isinstance(epic_link, str) and epic_link:\n",
    "        return epic_link\n",
    "\n",
    "    # 2) parent -> Epic\n",
    "    p = fields.get(\"parent\")\n",
    "    if isinstance(p, dict):\n",
    "        p_issuetype = (p.get(\"fields\") or {}).get(\"issuetype\") or p.get(\"issuetype\") or {}\n",
    "        if str(p_issuetype.get(\"name\", \"\")).lower() == \"epic\":\n",
    "            return p.get(\"key\")\n",
    "\n",
    "    # 3) objeto 'epic'\n",
    "    e = fields.get(\"epic\")\n",
    "    if isinstance(e, dict):\n",
    "        return e.get(\"key\") or e.get(\"id\")\n",
    "\n",
    "    return None\n",
    "\n",
    "def contar_dias_laborables(start_date, end_date):\n",
    "    dias = 0\n",
    "    current = start_date\n",
    "    while current <= end_date:\n",
    "        if current.weekday() < 5:  # Lunes a Viernes\n",
    "            dias += 1\n",
    "        current += timedelta(days=1)\n",
    "    return dias\n",
    "\n",
    "for issue in issues:\n",
    "    f = issue[\"fields\"]\n",
    "    status = f.get(\"status\", {}).get(\"name\", \"\").strip()\n",
    "    assignee = f.get(\"assignee\")\n",
    "    if not assignee:\n",
    "        continue\n",
    "    dev = assignee[\"displayName\"]\n",
    "    report = f.get(\"reporter\")\n",
    "    if not report:\n",
    "        continue\n",
    "    reporter = report[\"displayName\"]\n",
    "    key = issue[\"key\"]\n",
    "    summary = f.get(\"summary\", \"\")\n",
    "    module_info = f.get(\"customfield_10212\")\n",
    "    module_value = module_info[\"value\"] if module_info else None\n",
    "    estimate_hours = f.get(\"customfield_10608\")\n",
    "\n",
    "    if estimate_hours is None:\n",
    "        estimate_hours = f.get(\"customfield_10016\")\n",
    "\n",
    "    if estimate_hours is None:\n",
    "        estimate_seconds = f.get(\"timetracking\", {}).get(\"originalEstimateSeconds\") or f.get(\"aggregatetimeoriginalestimate\")\n",
    "        estimate_hours = estimate_seconds / 3600 if estimate_seconds else 0\n",
    "    \n",
    "    issue_to_epic = {}\n",
    "    for ekey, edata in epic_due_lookup.items():\n",
    "        for t in edata.get(\"tasks\", []):\n",
    "            k = t.get(\"key\")\n",
    "            if k:\n",
    "                issue_to_epic[k] = ekey\n",
    "    \n",
    "    epic_key = get_epic_key(f) or issue_to_epic.get(key)  # ğŸ‘ˆ fallback desde lookup\n",
    "    epic_obj = epic_due_lookup.get(epic_key) if epic_key else None\n",
    "    epic_due_str = (epic_obj or {}).get(\"due_date\")\n",
    "\n",
    "    # Prefiere due del issue; si no hay, usa el de la Ã©pica\n",
    "    due_str = f.get(\"duedate\") or epic_due_str\n",
    "    try:\n",
    "        due_date = datetime.strptime(due_str, \"%Y-%m-%d\") if due_str else datetime(2100, 1, 1)\n",
    "    except:\n",
    "        due_date = datetime(2100, 1, 1)\n",
    "\n",
    "    epic_name = (epic_obj or {}).get(\"summary\", \"â€” Sin Ã©pica â€”\")\n",
    "\n",
    "    cf10442_raw = f.get(\"customfield_10442\") or []\n",
    "    cf10442_names = [u.get(\"displayName\") for u in cf10442_raw if u.get(\"displayName\")]\n",
    "    suggested_devs = MODULE_DEVS.get(module_value, []) if module_value else []\n",
    "    suggested_users = list(set(suggested_devs + cf10442_names))\n",
    "\n",
    "    if dev in suggested_users:\n",
    "        suggested_users.remove(dev)\n",
    "\n",
    "    can_be_delegated = dev not in suggested_users and bool(suggested_users)\n",
    "    delegation_note = f\"ğŸš¨ Puede derivarse a: {', '.join(suggested_users)}\" if can_be_delegated else \"\"\n",
    "\n",
    "\n",
    "\n",
    "    cf10209_value = get_cf10209_from_sd_outward(\n",
    "        f_fields=f,\n",
    "        only_link_type=\"Problem/Incident\"  # o None si no querÃ©s filtrar por tipo\n",
    "    )\n",
    "    \n",
    "    task = {\n",
    "        \"key\": key,\n",
    "        \"summary\": summary,\n",
    "        \"estimate_hours\": estimate_hours,\n",
    "        \"due_date\": due_date,\n",
    "        \"assignee\": dev,\n",
    "        \"status\": status,\n",
    "        \"due_reason\": None,\n",
    "        \"module\": module_value,\n",
    "        \"suggested_users\": suggested_users,\n",
    "        \"has_epic\": bool(epic_key),\n",
    "        \"epic_name\": epic_name, \n",
    "        \"reporter\": reporter,\n",
    "        \"cf10209\": cf10209_value\n",
    "    }\n",
    "    # ğŸ”§ Nuevo: guardar claves de tareas que bloquean esta\n",
    "    \n",
    "    issue_map[key] = task\n",
    "\n",
    "    VALID_STATUSES_BT = {\"Por Hacer\"}\n",
    "    # print(f\"DEBUG {issue['key']} raw status={status}\")\n",
    "    if status in VALID_STATUSES_BT:\n",
    "        # print(f\"DEBUG {issue['key']} status={status}\")\n",
    "        tasks_by_dev.setdefault(dev, []).append(task)\n",
    "    graph.add_node(key)\n",
    "    \n",
    "\n",
    "    # for key, task in issue_map.items():\n",
    "    #     blocker_due_dates = [\n",
    "    #         issue_map[b][\"due_date\"]\n",
    "    #         for b in graph.predecessors(key)\n",
    "    #         if b in issue_map and issue_map[b][\"due_date\"]\n",
    "    #     ]\n",
    "\n",
    "    #     if blocker_due_dates:\n",
    "    #         max_blocker_due = min(blocker_due_dates)\n",
    "    #         if task[\"due_date\"] < max_blocker_due:\n",
    "    #             task[\"due_date_original\"] = task[\"due_date\"]\n",
    "    #             task[\"due_date\"] = max_blocker_due\n",
    "\n",
    "    for link in f.get(\"issuelinks\", []):\n",
    "        if \"inwardIssue\" in link and link[\"type\"][\"name\"] == \"Blocks\":\n",
    "            graph.add_edge(link[\"inwardIssue\"][\"key\"], key)\n",
    "        elif \"outwardIssue\" in link and link[\"type\"][\"name\"] == \"Blocks\":\n",
    "            graph.add_edge(key, link[\"outwardIssue\"][\"key\"])\n",
    "\n",
    "    blockers = [src for src, tgt in graph.edges() if tgt == key]\n",
    "    task[\"blockers\"] = blockers\n",
    "\n",
    "for key, task in issue_map.items():\n",
    "    # Para cada tarea, mirar a quiÃ©n bloquea\n",
    "    blocked_keys = list(graph.successors(key))\n",
    "    \n",
    "    blocked_due_dates = [\n",
    "        issue_map[b][\"due_date\"]\n",
    "        for b in blocked_keys\n",
    "        if b in issue_map and issue_map[b][\"due_date\"]\n",
    "    ]\n",
    "\n",
    "    blocker_key = [issue_map[b][\"key\"] for b in blocked_keys if b in issue_map and issue_map[b][\"key\"]]\n",
    "\n",
    "    if blocked_due_dates:\n",
    "        min_blocked_due = min(blocked_due_dates)\n",
    "        suggested_due = min_blocked_due - timedelta(days=1)\n",
    "        task[\"note\"] = (\n",
    "            f\"ğŸ•“ Fecha de vencimiento {'ajustada' if task['due_date'] > suggested_due else 'ya correcta'} \"\n",
    "            f\"por bloqueo a tarjeta {blocker_key} que vence el: {suggested_due.strftime('%Y-%m-%d')}\"\n",
    "        )\n",
    "        if task[\"due_date\"] > suggested_due:\n",
    "            task[\"due_date_original\"] = task[\"due_date\"]\n",
    "            task[\"due_date\"] = suggested_due\n",
    "            task[\"note\"] = f\"ğŸ•“ Fecha de vencimiento ajustada por bloqueo a tarjeta {blocker_key} que vence el: {suggested_due.strftime('%Y-%m-%d')}\"\n",
    "\n",
    "\n",
    "# BLOQUES POR DEV (simulados)\n",
    "bloques_por_dev = bloques\n",
    "MINIMUM_SLOT_HOURS = 0.25\n",
    "# === PLANIFICADOR POR DESARROLLADOR ===\n",
    "def to_naive(dt):\n",
    "    return dt.replace(tzinfo=None) if dt.tzinfo else dt\n",
    "\n",
    "def planificar_tareas_para_dev(dev, tasks, bloques_ocupados):\n",
    "    current_time = datetime.combine(DEFAULT_START_DATE.date(), datetime.strptime(\"08:30\", \"%H:%M\").time())\n",
    "    hours_per_day = DAILY_BT_HOURS.get(dev, DAILY_BT_HOURS[\"Default\"])\n",
    "    schedule = {}\n",
    "    plan = []\n",
    "\n",
    "    try:\n",
    "        sorted_keys = list(nx.topological_sort(graph.subgraph([t[\"key\"] for t in tasks])))\n",
    "    except nx.NetworkXUnfeasible:\n",
    "        sorted_keys = [t[\"key\"] for t in tasks]\n",
    "    sorted_keys.sort(key=lambda k: issue_map[k][\"due_date\"])\n",
    "\n",
    "    def to_naive(dt):\n",
    "        return dt.replace(tzinfo=None) if dt.tzinfo else dt\n",
    "    \n",
    "    for start, end in sorted(bloques_ocupados):\n",
    "            plan.append({\n",
    "                \"developer\": dev,\n",
    "                \"key\": f\"REUNION-{start.strftime('%Y%m%d%H%M')}\",\n",
    "                \"summary\": \"â›” ReuniÃ³n\",\n",
    "                \"has_epic\": False,\n",
    "                \"due_date\": start.date(),  # o end.date()\n",
    "                \"start\": to_naive(start),\n",
    "                \"end\": to_naive(end),\n",
    "                \"duration_hours\": (to_naive(end) - to_naive(start)).total_seconds() / 3600,\n",
    "                \"type\": \"reunion\"\n",
    "            })\n",
    "\n",
    "    for key in sorted_keys:\n",
    "        task = issue_map[key]\n",
    "        hours_left = task[\"estimate_hours\"]\n",
    "        start_time = None\n",
    "       \n",
    "\n",
    "        \n",
    "\n",
    "        while hours_left > 0:\n",
    "            date_str = current_time.strftime('%Y-%m-%d')\n",
    "            used_today = schedule.get(date_str, 0)\n",
    "\n",
    "            end_of_day = datetime.combine(current_time.date(), datetime.strptime(\"17:30\", \"%H:%M\").time())\n",
    "            available_time = (end_of_day - current_time).total_seconds() / 3600\n",
    "            time_slot = min(available_time, hours_per_day - used_today, hours_left)\n",
    "\n",
    "             # ğŸ”§ NUEVO BLOQUE: limitar time_slot al hueco libre real antes del prÃ³ximo conflicto\n",
    "            next_conflict_start = None\n",
    "            for start, end in sorted(bloques_ocupados):\n",
    "                if to_naive(start) > to_naive(current_time):\n",
    "                    next_conflict_start = to_naive(start)\n",
    "                    break\n",
    "\n",
    "            if next_conflict_start:\n",
    "                gap_hours = (next_conflict_start - current_time).total_seconds() / 3600\n",
    "                if gap_hours > 0:\n",
    "                    time_slot = min(time_slot, gap_hours)\n",
    "\n",
    "            if time_slot <= 0:\n",
    "                next_day = current_time.date() + timedelta(days=1)\n",
    "                while next_day.weekday() in [5, 6]:\n",
    "                    next_day += timedelta(days=1)\n",
    "                current_time = datetime.combine(next_day, datetime.strptime(\"08:30\", \"%H:%M\").time())\n",
    "                continue\n",
    "\n",
    "            proposed_end = current_time + timedelta(hours=time_slot)\n",
    "\n",
    "            bloque_conflictivo = any(\n",
    "                to_naive(start) < to_naive(proposed_end) and to_naive(end) > to_naive(current_time)\n",
    "                for start, end in bloques_ocupados\n",
    "            )\n",
    "\n",
    "            if bloque_conflictivo:\n",
    "                conflictos = [\n",
    "                    (start, end) for start, end in bloques_ocupados\n",
    "                    if to_naive(start) < to_naive(proposed_end) and to_naive(end) > to_naive(current_time)\n",
    "                ]\n",
    "                conflictos.sort(key=lambda x: to_naive(x[0]))\n",
    "                next_start = to_naive(conflictos[0][1])\n",
    "                current_time = next_start\n",
    "                continue\n",
    "\n",
    "            if start_time is None:\n",
    "                start_time = current_time\n",
    "\n",
    "            if bloque_conflictivo:\n",
    "                conflictos = [\n",
    "                    (start, end) for start, end in bloques_ocupados\n",
    "                    if to_naive(start) < to_naive(proposed_end) and to_naive(end) > to_naive(current_time)\n",
    "                ]\n",
    "                conflictos.sort(key=lambda x: to_naive(x[0]))\n",
    "                next_start = to_naive(conflictos[0][1])\n",
    "                current_time = next_start\n",
    "                continue\n",
    "\n",
    "            if start_time is None:\n",
    "                start_time = current_time\n",
    "\n",
    "            end_time = current_time + timedelta(hours=time_slot)\n",
    "            plan.append({\n",
    "                \"developer\": dev,\n",
    "                \"key\": key,\n",
    "                \"summary\": task[\"summary\"],\n",
    "                \"has_epic\": task[\"has_epic\"],\n",
    "                \"epic_name\": task[\"epic_name\"],\n",
    "                \"due_date\": task[\"due_date\"],\n",
    "                \"start\": current_time,\n",
    "                \"end\": end_time,\n",
    "                \"duration_hours\": time_slot,\n",
    "                \"suggested_users\": task.get(\"suggested_users\", []),\n",
    "                \"blockers\": task.get(\"blockers\", []),\n",
    "                \"note\": task.get(\"note\", \"\"),\n",
    "                \"reporter\": task.get(\"reporter\", \"\"),\n",
    "                \"cf10209\": task.get(\"cf10209\")\n",
    "            })\n",
    "            \n",
    "\n",
    "            schedule[date_str] = used_today + time_slot\n",
    "            hours_left -= time_slot\n",
    "            current_time = end_time\n",
    "\n",
    "    return plan\n",
    "\n",
    "# === PLANIFICACIÃ“N INICIAL ===\n",
    "# for dev in tasks_by_dev:\n",
    "#     scheduled += planificar_tareas_para_dev(dev, tasks_by_dev[dev], bloques_por_dev[dev])\n",
    "\n",
    "# === REBALANCEO ===\n",
    "planned_hours_by_dev = defaultdict(float)\n",
    "project_hours_by_dev = defaultdict(float)\n",
    "\n",
    "for s in scheduled:\n",
    "    if s.get(\"type\") == \"reunion\":\n",
    "        continue\n",
    "    planned_hours_by_dev[s[\"developer\"]] += s[\"duration_hours\"]\n",
    "    if issue_map[s[\"key\"]][\"has_epic\"]:\n",
    "        project_hours_by_dev[s[\"developer\"]] += s[\"duration_hours\"]\n",
    "\n",
    "for dev in tasks_by_dev:\n",
    "    all_tasks = tasks_by_dev[dev]\n",
    "    \n",
    "    within_range = [t for t in all_tasks if DEFAULT_START_DATE <= t[\"due_date\"] <= DEFAULT_END_DATE]\n",
    "    epic_tasks_in_range = sorted([t for t in within_range if t[\"has_epic\"]], key=lambda t: t[\"due_date\"])\n",
    "    non_epic_tasks_in_range = sorted([t for t in within_range if not t[\"has_epic\"]], key=lambda t: t[\"due_date\"], reverse=True)\n",
    "    epic_tasks_out_of_range = sorted(\n",
    "        [t for t in all_tasks if t[\"has_epic\"] and t not in within_range],\n",
    "        key=lambda t: t[\"due_date\"]\n",
    "    )\n",
    "\n",
    "    total_in_range = sum(t[\"estimate_hours\"] for t in within_range)\n",
    "    current_epic = sum(t[\"estimate_hours\"] for t in epic_tasks_in_range)\n",
    "    non_epic_hours = sum(t[\"estimate_hours\"] for t in non_epic_tasks_in_range)\n",
    "    min_ratio = MIN_BT_PROJECT_RATIO.get(dev, MIN_BT_PROJECT_RATIO[\"Default\"])\n",
    "\n",
    "    print(f\"\\nğŸ” {dev}:\")\n",
    "    print(f\"  ğŸ¯ Epic target: {min_ratio * 100:.1f}%\")\n",
    "    print(f\"  ğŸ“Š Total in range: {total_in_range:.1f} h | Epic in range: {current_epic:.1f} h\")\n",
    "    print(f\"  ğŸ” Epic tasks out of range: {len(epic_tasks_out_of_range)}\")\n",
    "    for t in epic_tasks_out_of_range:\n",
    "        print(f\"    - {t['key']} ({t['estimate_hours']} h) due {t['due_date'].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    # ğŸŸ¨ Forzar tareas con Ã©pica fuera de rango hasta cumplir el mÃ­nimo\n",
    "    # horas_planificables_en_rango = (\n",
    "    #         sum(t[\"estimate_hours\"] for t in epic_tasks_in_range) +\n",
    "    #         sum(t[\"estimate_hours\"] for t in non_epic_tasks_in_range) +\n",
    "    #         sum(t[\"estimate_hours\"] for t in epic_tasks_out_of_range)\n",
    "    #     )\n",
    "    \n",
    "    dias_laborables = contar_dias_laborables(DEFAULT_START_DATE, DEFAULT_END_DATE)\n",
    "    horas_por_dia = DAILY_BT_HOURS.get(dev, DAILY_BT_HOURS[\"Default\"])\n",
    "    horas_planificables_en_rango = dias_laborables * horas_por_dia\n",
    "    while epic_tasks_out_of_range:\n",
    "        task = epic_tasks_out_of_range.pop(0)\n",
    "        task_estimate = task[\"estimate_hours\"]\n",
    "\n",
    "        # Moverla dentro del rango\n",
    "        task[\"due_date_original\"] = task[\"due_date\"]\n",
    "        print(f\" modificando {task['key']} due {t['due_date'].strftime('%Y-%m-%d')}\")\n",
    "        task[\"due_date\"] = DEFAULT_START_DATE\n",
    "        epic_tasks_in_range.append(task)\n",
    "        current_epic += task_estimate\n",
    "\n",
    "        # Recalcular ratio despuÃ©s de agregarla\n",
    "        ratio_actual = current_epic / horas_planificables_en_rango if horas_planificables_en_rango > 0 else 0\n",
    "        print(f\"âœ”ï¸ Ratio tras forzar {task['key']}: {current_epic:.1f} / ({horas_planificables_en_rango:.1f}) = {ratio_actual * 100:.1f}%\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        if ratio_actual >= min_ratio:\n",
    "            break\n",
    "\n",
    "    # âŒ Eliminar tareas sin Ã©pica si sigue sin cumplirse el mÃ­nimo\n",
    "    ratio_actual = current_epic / (current_epic + non_epic_hours) if (current_epic + non_epic_hours) > 0 else 0\n",
    "    while non_epic_tasks_in_range and ratio_actual < min_ratio:\n",
    "        removed = non_epic_tasks_in_range.pop()\n",
    "        non_epic_hours -= removed[\"estimate_hours\"]\n",
    "        ratio_actual = current_epic / (current_epic + non_epic_hours) if (current_epic + non_epic_hours) > 0 else 0\n",
    "\n",
    "    # ğŸ”„ Reordenar: primero Ã©picas, luego tareas normales\n",
    "    balanced_tasks = sorted(epic_tasks_in_range, key=lambda t: t[\"due_date\"]) + \\\n",
    "                     sorted(non_epic_tasks_in_range, key=lambda t: t[\"due_date\"])\n",
    "    leftovers = [t for t in all_tasks if t not in balanced_tasks]\n",
    "    tasks_by_dev[dev] = balanced_tasks + leftovers\n",
    "\n",
    "    # ğŸ” Replanificar solo ese desarrollador\n",
    "    scheduled = [s for s in scheduled if s[\"developer\"] != dev]\n",
    "\n",
    "    if dev not in bloques_por_dev:\n",
    "        print(f\"â­ï¸ Skipping {dev} (sin bloques definidos)\")\n",
    "        continue\n",
    "    scheduled += planificar_tareas_para_dev(dev, tasks_by_dev[dev], bloques_por_dev[dev])\n",
    "\n",
    "\n",
    "# === RESUMEN FINAL ===\n",
    "scheduled_by_dev_and_key = defaultdict(lambda: defaultdict(list))\n",
    "for s in scheduled:\n",
    "    scheduled_by_dev_and_key[s[\"developer\"]][s[\"key\"]].append(s)\n",
    "\n",
    "print(\"\\nğŸ“ Developer Task Schedule Summary:\\n\")\n",
    "for dev, tasks in tasks_by_dev.items():\n",
    "    print(f\"ğŸ‘¨â€ğŸ’» Developer: {dev}\")\n",
    "    try:\n",
    "        sorted_keys = list(nx.topological_sort(graph.subgraph([t[\"key\"] for t in tasks])))\n",
    "    except nx.NetworkXUnfeasible:\n",
    "        sorted_keys = [t[\"key\"] for t in tasks]\n",
    "    sorted_keys.sort(key=lambda k: issue_map[k][\"due_date\"])\n",
    "    for key in sorted_keys:\n",
    "        task = issue_map[key]\n",
    "        scheds = sorted(scheduled_by_dev_and_key[dev].get(key, []), key=lambda x: x[\"start\"])\n",
    "        if not scheds:\n",
    "            continue\n",
    "        start_time = scheds[0][\"start\"]\n",
    "        end_time = scheds[-1][\"end\"]\n",
    "        total_hours = sum(s[\"duration_hours\"] for s in scheds)\n",
    "        note_lines = []\n",
    "        if \"note\" in task and task[\"note\"]:\n",
    "            note_lines.append(task[\"note\"])\n",
    "\n",
    "        # ğŸš¨ Sugerencias de derivaciÃ³n\n",
    "        if task.get(\"suggested_users\"):\n",
    "            note_lines.append(f\"ğŸš¨ Puede derivarse a: {', '.join(task['suggested_users'])}\")\n",
    "\n",
    "        # ğŸ“› Bloqueadores\n",
    "        if task.get(\"blockers\"):\n",
    "            blocker_msgs = []\n",
    "            for blocker_key in task[\"blockers\"]:\n",
    "                blocker = issue_map.get(blocker_key)\n",
    "                if blocker:\n",
    "                    blocker_msgs.append(f\"{blocker_key}: {blocker['summary']} ({blocker['assignee']}, Due: {blocker['due_date'].strftime('%Y-%m-%d')})\")\n",
    "                else:\n",
    "                    blocker_msgs.append(blocker_key)\n",
    "            note_lines.append(f\"ğŸ“› Debido a bloqueo de: \" + \" | \".join(blocker_msgs))\n",
    "\n",
    "         # Agregar nota personalizada si existe\n",
    "        if \"note\" in task and task[\"note\"]:\n",
    "            note_lines.append(task[\"note\"])\n",
    "\n",
    "        note = \"\\n     \" + \"\\n     \".join(note_lines) if note_lines else \"\"\n",
    "        print(\n",
    "            f\"   ğŸ”¹ {key}: {round(total_hours, 1)}h â†’ Due: {task['due_date'].strftime('%Y-%m-%d')} | \"\n",
    "            f\"Finish: Start: {start_time.strftime('%Y-%m-%d %H:%M')} | End: {end_time.strftime('%Y-%m-%d %H:%M')}{note}\"\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfff08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"planificacion_bt.json\", \"w\") as f:\n",
    "    json.dump(scheduled, f, default=str, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
