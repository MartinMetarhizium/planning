import os
import re
import json
import base64
import platform
import shutil
from io import BytesIO
from typing import List, Dict

import streamlit as st
from openai import OpenAI
from PIL import Image


import pytesseract
import platform
import os

def _configure_tesseract_path():
    """Detecta y configura la ruta de Tesseract en Windows si no est√° en PATH."""
    if platform.system() == "Windows":
        if not os.environ.get("PATH") or "tesseract" not in os.environ.get("PATH", "").lower():
            possible_paths = [
                r"C:\Program Files\Tesseract-OCR\tesseract.exe",
                r"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe"
            ]
            for p in possible_paths:
                if os.path.exists(p):
                    pytesseract.pytesseract.tesseract_cmd = p
                    break

# Llamar siempre al inicio
_configure_tesseract_path()

import shutil, platform
diag_msgs = []

# pdf2image
try:
    from pdf2image import convert_from_bytes
    diag_msgs.append("‚úÖ pdf2image import OK")
except Exception as e:
    st.error(f"‚ùå pdf2image import FAIL: {e}")

# pytesseract + versi√≥n + idiomas
try:
    import pytesseract as pt
    ver = pt.get_tesseract_version()
    langs = []
    try:
        langs = pt.get_languages(config="")
    except Exception:
        pass
    diag_msgs.append(f"‚úÖ pytesseract import OK ‚Äî Tesseract {ver}")
    if langs:
        diag_msgs.append(f"‚ÑπÔ∏è Idiomas instalados: {', '.join(langs)}")
except Exception as e:
    st.error(f"‚ùå pytesseract import FAIL: {e}")

# Poppler (pdftoppm) en PATH
pdftoppm_path = shutil.which("pdftoppm")
diag_msgs.append(f"{'‚úÖ' if pdftoppm_path else '‚ùå'} pdftoppm en PATH: {pdftoppm_path or 'NO ENCONTRADO'}")

# Tesseract en PATH (solo info; en Windows pod√©s setear tesseract_cmd si no est√°)
tesseract_path = shutil.which("tesseract")
diag_msgs.append(f"{'‚úÖ' if tesseract_path else '‚ùå'} tesseract en PATH: {tesseract_path or 'NO ENCONTRADO'}")

st.markdown("**Diagn√≥stico:**")
for m in diag_msgs:
    st.write(m)

def _discover_poppler_path() -> str:
    if platform.system() != "Windows":
        return ""  # en Linux/Mac no lo uses (pdf2image lo encuentra en PATH)
    # 1) Si est√° en PATH del sistema:
    if shutil.which("pdftoppm"):
        return ""  # no hace falta path expl√≠cito
    # 2) Si est√°s en conda, suele estar en <CONDA_PREFIX>\Library\bin
    conda_prefix = os.environ.get("CONDA_PREFIX") or os.environ.get("PREFIX")
    if conda_prefix:
        cand = os.path.join(conda_prefix, "Library", "bin")
        if os.path.exists(os.path.join(cand, "pdftoppm.exe")):
            return cand
    # 3) Tus rutas conocidas (ajusta si hace falta)
    candidates = [
        r"C:\Users\Martin\anaconda3\Library\bin",
        r"C:\Users\Martin\anaconda3\pkgs\poppler-23.12.0-hc2f3c52_0\Library\bin",
        r"C:\Program Files\poppler\Library\bin",
        r"C:\Program Files\poppler-24.07.0\Library\bin",
    ]
    for cand in candidates:
        if os.path.exists(os.path.join(cand, "pdftoppm.exe")):
            return cand
    return ""  # si no encontramos nada, pdf2image tirar√° un error √∫til

POPPLER_PATH = _discover_poppler_path()

API_KEY = "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"

# ---------- 3) Par√°metros de API (OpenRouter mediante cliente de OpenAI) ----------
# Guard√° tu clave como secreto OPENROUTER_API_KEY en .streamlit/secrets.toml o variable de entorno.
# API_KEY = st.secrets.get("OPENROUTER_API_KEY") or os.getenv("OPENROUTER_API_KEY")
HTTP_REFERER = "https://planning-carestino.streamlit.app/"
X_TITLE =  "CarestinoApp"

# # Poppler (para pdf2image). En Linux con packages.txt no hace falta setearlo.

# def need_api_key() -> bool:
#     if not API_KEY:
#         st.error("Falta `OPENROUTER_API_KEY` en **.streamlit/secrets.toml** o variable de entorno.")
#         return True
#     return False


# # =============================
# # Poppler autodiscovery (Windows)
# # =============================
# def _discover_poppler_path() -> str:
#     if platform.system() != "Windows":
#         return ""  # en Linux/Mac no lo uses (pdf2image lo encuentra en PATH)
#     if shutil.which("pdftoppm"):
#         return ""  # ya est√° en PATH
#     conda_prefix = os.environ.get("CONDA_PREFIX") or os.environ.get("PREFIX")
#     if conda_prefix:
#         cand = os.path.join(conda_prefix, "Library", "bin")
#         if os.path.exists(os.path.join(cand, "pdftoppm.exe")):
#             return cand
#     candidates = [
#         r"C:\Users\Martin\anaconda3\Library\bin",
#         r"C:\Users\Martin\anaconda3\pkgs\poppler-23.12.0-hc2f3c52_0\Library\bin",
#         r"C:\Program Files\poppler\Library\bin",
#         r"C:\Program Files\poppler-24.07.0\Library\bin",
#     ]
#     for cand in candidates:
#         if os.path.exists(os.path.join(cand, "pdftoppm.exe")):
#             return cand
#     return ""

# POPPLER_PATH = _discover_poppler_path()


# # =============================
# # P√°gina
# # =============================
# st.set_page_config(page_title="Consulta de carreras", page_icon="üéì", layout="wide")
# st.title("üéì Consulta de carreras en archivos (visi√≥n + OCR con IA)")

# st.caption(
#     "Seleccion√° una carrera, sub√≠ uno o m√°s **PDF/imagenes**. "
#     "Primero verificamos si la carrera aparece. Luego **extraemos el texto** del/los PDF usando el propio modelo de visi√≥n."
# )

# # ---------- 1) Selector de carrera ----------
# CARRERAS = [
#     "Ingenier√≠a en Sistemas", "Ciencia de Datos", "Ingenier√≠a Industrial", "Administraci√≥n de Empresas",
#     "Contador P√∫blico", "Econom√≠a", "Marketing", "Recursos Humanos",
#     "Dise√±o Gr√°fico", "Dise√±o UX/UI", "Comunicaci√≥n Social",
#     "Psicolog√≠a", "Abogac√≠a (Derecho)", "Arquitectura", "Ingenier√≠a Agron√≥mica",
#     "Medicina", "Enfermer√≠a", "Farmacia", "Bioqu√≠mica",
#     "Ingenier√≠a Civil", "Ingenier√≠a Electr√≥nica", "Ingenier√≠a Mec√°nica",
#     "Ingenier√≠a en Inform√°tica",
# ]
# col_a, col_b = st.columns([1.2, 1])
# with col_a:
#     carrera = st.selectbox("Carrera a buscar", CARRERAS, index=0)
# with col_b:
#     # Modelos con visi√≥n (sugeridos). Evitamos modelos texto-solo para no disparar 404.
#     VISION_MODELS = {
#         "deepseek/deepseek-chat-v3.1:free": "deepseek free",
#         # "openai/gpt-4o-mini": "GPT-4o mini (visi√≥n)",
#         # "google/gemini-1.5-flash-001": "Gemini 1.5 Flash (visi√≥n)",
#         # Podr√≠as a√±adir otros aqu√≠ si tu cuenta los soporta en visi√≥n
#     }
#     modelo = st.selectbox(
#         "Modelo de visi√≥n",
#         list(VISION_MODELS.keys()),
#         index=0,
#         format_func=lambda k: VISION_MODELS[k],
#     )

# # ---------- 2) Subida de archivos ----------
# st.markdown("#### Archivos")
# st.caption("Formatos soportados: **.pdf**, **.png**, **.jpg**, **.jpeg**, **.webp**")
# uploads = st.file_uploader(
#     "Arrastr√° o eleg√≠ archivos",
#     type=["pdf", "png", "jpg", "jpeg", "webp"],
#     accept_multiple_files=True,
# )

# # ---------- 3) Opciones de conversi√≥n ----------
# col1, col2, col3 = st.columns([1, 1, 2])
# with col1:
#     max_pages_per_file = st.number_input("M√°x. p√°ginas por archivo", min_value=1, max_value=20, value=6, step=1)
# with col2:
#     dpi = st.number_input("DPI (PDF‚Üíimagen)", min_value=100, max_value=300, value=150, step=25)
# with col3:
#     preview = st.toggle("Previsualizar primeras im√°genes", value=False)

# # Extra: toggle para ejecutar OCR con el modelo (adem√°s de la verificaci√≥n)
# do_ocr = st.toggle("Extraer texto (OCR con el mismo modelo)", value=True)

# st.divider()


# # =============================
# # Utilidades de conversi√≥n
# # =============================
# def pdf_to_b64_images(file_bytes: bytes, dpi: int = 150, max_pages: int = 6) -> List[str]:
#     """Convierte PDF a data URLs (PNG) para ser enviadas a un modelo con visi√≥n."""
#     try:
#         from pdf2image import convert_from_bytes
#     except Exception:
#         st.error("Falta la dependencia `pdf2image`. Agregala en requirements.txt.")
#         raise

#     if POPPLER_PATH:
#         pages = convert_from_bytes(file_bytes, dpi=dpi, poppler_path=POPPLER_PATH)
#     else:
#         pages = convert_from_bytes(file_bytes, dpi=dpi)

#     urls = []
#     for im in pages[:max_pages]:
#         buf = BytesIO()
#         im.save(buf, format="PNG")
#         b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
#         urls.append(f"data:image/png;base64,{b64}")
#     return urls


# def image_file_to_data_url(upload) -> str:
#     """Convierte una imagen subida a data URL (PNG)."""
#     img = Image.open(upload)
#     buf = BytesIO()
#     img.convert("RGB").save(buf, format="PNG")
#     b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
#     return f"data:image/png;base64,{b64}"


# # =============================
# # Prompts / Mensajes
# # =============================
# def build_prompt_vision(carrera: str) -> str:
#     alias_map = {
#         "ingenier√≠a en sistemas": [
#             "ingenieria en sistemas", "ingenier√≠a en inform√°tica", "ingenieria en informatica",
#             "ingenier√≠a en computaci√≥n", "ingenieria en computacion",
#             "ingenier√≠a en sistemas de informaci√≥n", "ingenier√≠a de sistemas",
#             "ing. en sistemas", "ing sistemas", "ing en informatica",
#             "computer engineering",
#         ],
#         "ingenier√≠a en inform√°tica": [
#             "ingenier√≠a inform√°tica", "ingenieria informatica", "ingenier√≠a en sistemas",
#             "ingenier√≠a en computaci√≥n", "computer engineering",
#         ],
#         "ciencia de datos": [
#             "data science", "ciencias de datos", "anal√≠tica de datos", "data analytics",
#         ],
#     }
#     base = carrera.strip().lower()
#     sinonimos = alias_map.get(base, [])
#     sinonimos_str = ", ".join(f"\"{s}\"" for s in sinonimos)

#     return f"""
# Actu√° como verificador. Deb√©s responder si la carrera pedida aparece en el documento (texto embebido en im√°genes, PDFs escaneados, etc.).

# CARRERA_BASE: "{carrera}"
# TRATAR COMO SIN√ìNIMOS EQUIVALENTES: [{sinonimos_str}]

# Reglas:
# - Compar√° sin sensibilidad a may√∫sculas, tildes, guiones y saltos de l√≠nea.
# - Acept√° variantes obvias (p.ej. "Ingenier√≠a en Sistemas de Informaci√≥n" cuenta para "Ingenier√≠a en Sistemas").
# - Si hay coincidencia parcial clara (Ingenier* + {{sistem, inform, comput}}) en una misma l√≠nea/p√°rrafo, marc√° encontrada=true.
# - Devolv√© **solo** JSON (nada de texto extra) con el siguiente esquema:
#   {{
#     "encontrada": true/false,
#     "alias_detectado": "<string|null>",
#     "evidencia": "<frase o l√≠nea exacta>",
#     "motivo": "<si aplica>"
#   }}
# """.strip()


# def build_messages_for_verification(carrera: str, image_urls: List[str]):
#     intro = build_prompt_vision(carrera)
#     parts = [{"type": "text", "text": intro}]
#     for url in image_urls:
#         parts.append({"type": "image_url", "image_url": {"url": url}})
#     parts.append({"type": "text", "text": "Respond√© SOLO el JSON solicitado."})
#     return [
#         {"role": "system", "content": "Eres un verificador muy preciso y conciso."},
#         {"role": "user", "content": parts},
#     ]


# def build_messages_for_ocr(image_urls: List[str]):
#     # Prompt de OCR: pedimos TEXTO PLANO sin explicaci√≥n
#     parts = [
#         {"type": "text", "text": "Extra√© TODO el texto legible. Devolv√© **solo** texto plano en espa√±ol, sin comentarios."}
#     ]
#     for url in image_urls:
#         parts.append({"type": "image_url", "image_url": {"url": url}})
#     return [
#         {"role": "system", "content": "Eres un excelente OCR. Devuelves √∫nicamente texto plano."},
#         {"role": "user", "content": parts},
#     ]


# def parse_json_safely(text: str):
#     try:
#         return json.loads(text), None
#     except Exception:
#         pass
#     m = re.search(r"\{[\s\S]*\}", text)
#     if m:
#         try:
#             return json.loads(m.group(0)), None
#         except Exception as e:
#             return None, f"No se pudo parsear JSON: {e}"
#     return None, "No se encontr√≥ JSON en la respuesta."


# def _call_chat_completion(client: OpenAI, model: str, messages: list):
#     return client.chat.completions.create(
#         model=model,
#         temperature=0.0,
#         extra_headers={"HTTP-Referer": HTTP_REFERER, "X-Title": X_TITLE},
#         messages=messages,
#     )


# def _vision_call_with_fallback(client: OpenAI, model: str, messages: list):
#     """Llama al modelo; si da 404 'no soporta im√°genes', cae a Qwen VL."""
#     try:
#         return _call_chat_completion(client, model, messages)
#     except Exception as e:
#         msg = str(e)
#         if "No endpoints found that support image input" in msg or "support image input" in msg:
#             fallback = "deepseek/deepseek-chat-v3.1:free"
#             st.warning(f"El modelo seleccionado no acepta im√°genes en tu cuenta. Reintentando con {fallback}‚Ä¶")
#             return _call_chat_completion(client, fallback, messages)
#         raise


# # =============================
# # Acciones
# # =============================
# col_run1, col_run2 = st.columns([1, 1])
# with col_run1:
#     run = st.button("üîé Verificar + (opcional) OCR", type="primary", use_container_width=True)
# with col_run2:
#     clear = st.button("Limpiar", use_container_width=True)

# if clear:
#     st.rerun()

# if run:
#     if need_api_key():
#         st.stop()
#     if not uploads:
#         st.warning("Sub√≠ al menos un archivo PDF o imagen.")
#         st.stop()

#     # 1) Convertir a im√°genes y conservar por archivo
#     file_imgs: Dict[str, List[str]] = {}
#     all_imgs: List[str] = []

#     with st.spinner("Procesando archivos a im√°genes‚Ä¶"):
#         for up in uploads:
#             name = (up.name or "").lower()
#             if name.endswith(".pdf"):
#                 try:
#                     file_bytes = up.getvalue()
#                     urls = pdf_to_b64_images(file_bytes, dpi=dpi, max_pages=max_pages_per_file)
#                     file_imgs[up.name] = urls
#                     all_imgs.extend(urls)
#                 except Exception as e:
#                     st.error(f"Error convirtiendo {up.name}: {e}")
#             elif any(name.endswith(ext) for ext in (".png", ".jpg", ".jpeg", ".webp")):
#                 try:
#                     url = image_file_to_data_url(up)
#                     file_imgs[up.name] = [url]
#                     all_imgs.append(url)
#                 except Exception as e:
#                     st.error(f"No se pudo procesar imagen {up.name}: {e}")
#             else:
#                 st.warning(f"Formato no soportado para visi√≥n directa: {up.name}")

#     if not all_imgs:
#         st.warning("No se generaron im√°genes para enviar al modelo.")
#         st.stop()

#     if preview:
#         st.markdown("**Previsualizaci√≥n (primeras im√°genes):**")
#         for url in all_imgs[:min(4, len(all_imgs))]:
#             st.image(url, use_container_width=True)

#     client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=API_KEY)

#     # 2) Verificaci√≥n (¬øaparece la carrera?)
#     st.subheader("Resultado de verificaci√≥n de carrera")
#     verif_messages = build_messages_for_verification(carrera, all_imgs)
#     try:
#         with st.spinner(f"Consultando modelo de visi√≥n ({VISION_MODELS.get(modelo, modelo)})‚Ä¶"):
#             completion = _vision_call_with_fallback(client, modelo, verif_messages)
#         raw = completion.choices[0].message.content or ""
#     except Exception as e:
#         st.error(f"Error llamando a la API: {e}")
#         st.stop()

#     data, err = parse_json_safely(raw)
#     if data:
#         colr1, colr2 = st.columns([1, 2])
#         with colr1:
#             ok = bool(data.get("encontrada"))
#             st.metric("Encontrada", "S√≠ ‚úÖ" if ok else "No ‚ùå")
#             st.caption(f"Alias: {data.get('alias_detectado')}")
#         with colr2:
#             st.markdown("**Evidencia**")
#             st.info(data.get("evidencia") or "‚Äî")
#             if data.get("motivo"):
#                 st.markdown("**Motivo**")
#                 st.write(data.get("motivo"))
#         with st.expander("JSON devuelto por el modelo"):
#             st.code(json.dumps(data, ensure_ascii=False, indent=2), language="json")
#     else:
#         st.warning(err or "No se pudo interpretar la salida como JSON.")
#         with st.expander("Salida cruda del modelo"):
#             st.code(raw)

#     # 3) (Opcional) OCR con el mismo modelo ‚Äî por archivo
#     if do_ocr:
#         st.subheader("Texto extra√≠do (OCR con IA)")
#         ocr_zip_parts: List[bytes] = []
#         for fname, imgs in file_imgs.items():
#             st.markdown(f"**‚Ä¢ {fname}**")
#             ocr_messages = build_messages_for_ocr(imgs)
#             try:
#                 with st.spinner(f"OCR de {fname}‚Ä¶"):
#                     ocr_completion = _vision_call_with_fallback(client, modelo, ocr_messages)
#                 ocr_text = (ocr_completion.choices[0].message.content or "").strip()
#             except Exception as e:
#                 st.error(f"OCR fall√≥ en {fname}: {e}")
#                 continue

#             # Mostrar y preparar descarga
#             st.text_area("Texto extra√≠do", value=ocr_text, height=200, key=f"ocr_{fname}")
#             st.download_button(
#                 "‚¨áÔ∏è Descargar texto",
#                 data=ocr_text.encode("utf-8"),
#                 file_name=f"{os.path.splitext(fname)[0]}_ocr.txt",
#                 mime="text/plain",
#                 key=f"dl_{fname}",
#             )















def need_api_key() -> bool:
    if not API_KEY:
        st.error("Falta `OPENROUTER_API_KEY` (secrets.toml o variable de entorno).")
        return True
    return False

# =============================
# Poppler (Windows) para pdf2image
# =============================
def _discover_poppler_path() -> str:
    if platform.system() != "Windows":
        return ""
    if shutil.which("pdftoppm"):
        return ""
    conda_prefix = os.environ.get("CONDA_PREFIX") or os.environ.get("PREFIX")
    if conda_prefix:
        cand = os.path.join(conda_prefix, "Library", "bin")
        if os.path.exists(os.path.join(cand, "pdftoppm.exe")):
            return cand
    candidates = [
        r"C:\Users\Martin\anaconda3\Library\bin",
        r"C:\Users\Martin\anaconda3\pkgs\poppler-23.12.0-hc2f3c52_0\Library\bin",
        r"C:\Program Files\poppler\Library\bin",
        r"C:\Program Files\poppler-24.07.0\Library\bin",
    ]
    for cand in candidates:
        if os.path.exists(os.path.join(cand, "pdftoppm.exe")):
            return cand
    return ""

POPPLER_PATH = _discover_poppler_path()

# =============================
# P√°gina
# =============================
st.set_page_config(page_title="Consulta de carreras", page_icon="üéì", layout="wide")
st.title("üéì Consulta de carreras en archivos (visi√≥n con fallback a texto)")

CARRERAS = [
    "Ingenier√≠a en Sistemas", "Ciencia de Datos", "Ingenier√≠a Industrial", "Administraci√≥n de Empresas",
    "Contador P√∫blico", "Econom√≠a", "Marketing", "Recursos Humanos",
    "Dise√±o Gr√°fico", "Dise√±o UX/UI", "Comunicaci√≥n Social",
    "Psicolog√≠a", "Abogac√≠a (Derecho)", "Arquitectura", "Ingenier√≠a Agron√≥mica",
    "Medicina", "Enfermer√≠a", "Farmacia", "Bioqu√≠mica",
    "Ingenier√≠a Civil", "Ingenier√≠a Electr√≥nica", "Ingenier√≠a Mec√°nica",
    "Ingenier√≠a en Inform√°tica",
]
col_a, col_b = st.columns([1.3, 1])
with col_a:
    carrera = st.selectbox("Carrera a buscar", CARRERAS, index=0)
with col_b:
    VISION_MODELS = {
        "deepseek/deepseek-chat-v3.1:free": "deepseek free",
        # "qwen/qwen2.5-vl-7b-instruct":  "Qwen2.5-VL 7B (visi√≥n)",
        # "meta-llama/llama-3.2-11b-vision-instruct:free": "Llama 3.2 11B Vision (free)",
        # "openai/gpt-4o-mini": "GPT-4o mini (visi√≥n)",
    }
    modelo_vision = st.selectbox(
        "Modelo de visi√≥n (primero intenta con esto)",
        list(VISION_MODELS.keys()),
        index=0,
        format_func=lambda k: VISION_MODELS[k],
    )

# Modelo texto-solo de fallback
TEXT_FALLBACK_MODEL = st.selectbox(
    "Modelo texto (fallback)",
    ["deepseek/deepseek-chat-v3.1:free", 
    #  "openai/gpt-4o-mini"
     ],  # gpt-4o-mini tambi√©n sirve como texto
    index=0,
)

st.markdown("#### Archivos")
st.caption("Soportado: **.pdf**, **.png**, **.jpg**, **.jpeg**, **.webp**, **.docx**, **.txt**, **.md**, **.csv**")
uploads = st.file_uploader(
    "Arrastr√° o eleg√≠ archivos",
    type=["pdf", "png", "jpg", "jpeg", "webp", "docx", "txt", "md", "csv"],
    accept_multiple_files=True,
)

col1, col2, col3 = st.columns([1, 1, 2])
with col1:
    max_pages_per_file = st.number_input("M√°x. p√°ginas por archivo (PDF/Imagen‚Üívisi√≥n)", 1, 20, 6, 1)
with col2:
    dpi = st.number_input("DPI (PDF‚Üíimagen)", 100, 300, 150, 25)
with col3:
    preview = st.toggle("Previsualizar primeras im√°genes", value=False)

st.divider()

# =============================
# Utilidades (visi√≥n)
# =============================
def pdf_to_b64_images(file_bytes: bytes, dpi: int = 150, max_pages: int = 6) -> List[str]:
    try:
        from pdf2image import convert_from_bytes
    except Exception:
        st.error("Falta `pdf2image` (pip install pdf2image).")
        raise
    if POPPLER_PATH:
        pages = convert_from_bytes(file_bytes, dpi=dpi, poppler_path=POPPLER_PATH)
    else:
        pages = convert_from_bytes(file_bytes, dpi=dpi)
    urls = []
    for im in pages[:max_pages]:
        buf = BytesIO()
        im.save(buf, format="PNG")
        b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
        urls.append(f"data:image/png;base64,{b64}")
    return urls

def image_file_to_data_url(upload) -> str:
    img = Image.open(upload)
    buf = BytesIO()
    img.convert("RGB").save(buf, format="PNG")
    b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
    return f"data:image/png;base64,{b64}"

# =============================
# Utilidades (texto)
# =============================
def read_text_from_upload(upload) -> str:
    """Extrae texto de TXT, DOCX, PDF o usa OCR para im√°genes/PDF escaneados."""
    name = (upload.name or "").lower()
    data = upload.read()
    upload.seek(0)

    # TXT / CSV
    if name.endswith((".txt", ".md", ".csv")):
        return data.decode("utf-8", errors="ignore")

    # DOCX
    if name.endswith(".docx"):
        from docx import Document
        doc = Document(BytesIO(data))
        return "\n".join(p.text for p in doc.paragraphs)

    # PDF: primero intentar texto embebido
    if name.endswith(".pdf"):
        try:
            from pypdf import PdfReader
            reader = PdfReader(BytesIO(data))
            pages = [p.extract_text() or "" for p in reader.pages]
            text = "\n".join(pages).strip()
            if text:
                return text
        except Exception:
            pass

        # Si no hay texto ‚Üí OCR con pdf2image + pytesseract
        from pdf2image import convert_from_bytes
        import pytesseract

        pages = convert_from_bytes(data, dpi=150, poppler_path=POPPLER_PATH)
        texts = []
        for im in pages:
            txt = pytesseract.image_to_string(im, lang="spa+eng")  # pod√©s cambiar idiomas
            if txt.strip():
                texts.append(txt)
        return "\n".join(texts).strip()

    # Imagen ‚Üí OCR directo
    if any(name.endswith(ext) for ext in (".png", ".jpg", ".jpeg", ".webp")):
        import pytesseract
        img = Image.open(BytesIO(data))
        return pytesseract.image_to_string(img, lang="spa+eng")

    return ""

def have_tesseract() -> bool:
    try:
        import pytesseract  # noqa
    except Exception:
        return False
    # En Windows pod√©s configurar ruta si no est√° en PATH:
    if platform.system() == "Windows":
        import pytesseract as pt
        if not shutil.which("tesseract"):
            guesses = [
                r"C:\Program Files\Tesseract-OCR\tesseract.exe",
                r"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe",
            ]
            for g in guesses:
                if os.path.exists(g):
                    pt.pytesseract.tesseract_cmd = g
                    return True
            return False
    return True

def ocr_images_locally(image_urls: List[str]) -> str:
    """OCR con pytesseract si est√° disponible. image_urls = data URLs PNG."""
    try:
        import pytesseract
    except Exception:
        return ""  # no hay OCR local
    texts = []
    for url in image_urls:
        if not url.startswith("data:image/"):
            continue
        b64 = url.split(",", 1)[1]
        img = Image.open(BytesIO(base64.b64decode(b64)))
        try:
            txt = pytesseract.image_to_string(img)  # (opcional) lang='spa'
        except Exception:
            txt = ""
        if txt and txt.strip():
            texts.append(txt)
    return "\n".join(texts).strip()

# =============================
# Prompts / mensajes
# =============================
def build_prompt_vision(carrera: str) -> str:
    alias_map = {
        "ingenier√≠a en sistemas": [
            "ingenieria en sistemas", "ingenier√≠a en inform√°tica", "ingenieria en informatica",
            "ingenier√≠a en computaci√≥n", "ingenieria en computacion",
            "ingenier√≠a en sistemas de informaci√≥n", "ingenier√≠a de sistemas",
            "ing. en sistemas", "ing sistemas", "ing en informatica",
            "computer engineering",
        ],
        "ingenier√≠a en inform√°tica": [
            "ingenier√≠a inform√°tica", "ingenieria informatica", "ingenier√≠a en sistemas",
            "ingenier√≠a en computaci√≥n", "computer engineering",
        ],
        "ciencia de datos": [
            "data science", "ciencias de datos", "anal√≠tica de datos", "data analytics",
        ],
    }
    sinonimos = alias_map.get(carrera.strip().lower(), [])
    sinonimos_str = ", ".join(f"\"{s}\"" for s in sinonimos)
    return f"""
Actu√° como verificador. ¬øAparece la carrera pedida en el documento (incluso escaneado)?
CARRERA_BASE: "{carrera}"
TRATAR COMO SIN√ìNIMOS EQUIVALENTES: [{sinonimos_str}]
Devolv√© SOLO JSON:
{{"encontrada": true/false, "alias_detectado": "<string|null>", "evidencia": "<frase>", "motivo": "<opcional>"}}
""".strip()

def build_messages_for_verification(carrera: str, image_urls: List[str]):
    parts = [{"type": "text", "text": build_prompt_vision(carrera)}]
    for url in image_urls:
        parts.append({"type": "image_url", "image_url": {"url": url}})
    parts.append({"type": "text", "text": "Respond√© SOLO el JSON solicitado."})
    return [
        {"role": "system", "content": "Eres un verificador muy preciso y conciso."},
        {"role": "user", "content": parts},
    ]

def build_text_prompt(carrera: str, texts: List[str]) -> str:
    joined = "\n\n---\n\n".join(texts)
    if len(joined) > 120_000:
        joined = joined[:120_000] + "\n\n[TRUNCADO]\n"
    return f"""
Analiz√° el/los texto(s) (extra√≠dos de archivos subidos).
¬øAparece "{carrera}" (o sin√≥nimos obvios) como carrera/t√≠tulo/programa?
Devolv√© SOLO JSON:
{{"encontrada": true/false, "evidencia": "<l√≠nea o frase>", "motivo": "<opcional>"}}

Textos:
{joined}
""".strip()

def parse_json_safely(text: str):
    text = text.strip()
    if text.startswith("```"):
        text = re.sub(r"^```(?:json)?\s*", "", text)
        text = re.sub(r"\s*```$", "", text)
    try:
        return json.loads(text), None
    except Exception:
        m = re.search(r"\{[\s\S]*\}", text)
        if m:
            try:
                return json.loads(m.group(0)), None
            except Exception as e:
                return None, f"No se pudo parsear JSON: {e}"
    return None, "No se encontr√≥ JSON en la respuesta."

# =============================
# Llamadas API y fallback
# =============================
def call_chat(client: OpenAI, model: str, messages: list):
    return client.chat.completions.create(
        model=model,
        temperature=0.0,
        extra_headers={"HTTP-Referer": HTTP_REFERER, "X-Title": X_TITLE},
        messages=messages,
    )

def try_vision_then_text(
    client: OpenAI,
    modelo_vision: str,
    image_urls: List[str],
    carrera: str,
    text_fallback_model: str,
    uploads_for_text: List
):
    """Primero intenta VISI√ìN; si falla/no soporta im√°genes ‚Üí convierte a texto y usa modelo TEXT."""
    # 1) VISI√ìN
    try:
        messages_v = build_messages_for_verification(carrera, image_urls)
        completion = call_chat(client, modelo_vision, messages_v)
        raw = completion.choices[0].message.content or ""
        data, err = parse_json_safely(raw)
        return ("vision", data, err, raw)
    except Exception as e:
        msg = str(e)
        # T√≠pico en OpenRouter cuando no acepta imagen para tu cuenta:
        if ("No endpoints found that support image input" in msg) or ("does not support image input" in msg):
            st.warning(f"El modelo de visi√≥n '{modelo_vision}' no acepta im√°genes en tu cuenta. Fallback a texto‚Ä¶")
        else:
            st.info(f"Fallo visi√≥n: {e}. Fallback a texto‚Ä¶")

    # 2) TEXTO (fallback): extraer texto localmente
    texts = []
    for up in uploads_for_text:
        name = (up.name or "").lower()
        if any(name.endswith(ext) for ext in (".png", ".jpg", ".jpeg", ".webp")):
            # intentar OCR local si existe
            txt_ocr = ocr_images_locally([image_file_to_data_url(up)])
            if txt_ocr:
                texts.append(f"[{up.name}]\n{txt_ocr}")
            else:
                texts.append(f"[{up.name}] (sin texto legible; instala Tesseract+pytesseract para OCR local)")
        else:
            t = read_text_from_upload(up)
            if t.strip():
                texts.append(f"[{up.name}]\n{t}")
            else:
                # √∫ltimo recurso: si es PDF escaneado sin OCR local, avisar
                texts.append(f"[{up.name}] (sin texto extra√≠ble)")

    if not texts:
        return ("text", None, "No se pudo obtener texto para el fallback.", "")

    prompt_txt = build_text_prompt(carrera, texts)
    try:
        completion_t = call_chat(client, text_fallback_model, [{"role": "user", "content": prompt_txt}])
        raw_t = completion_t.choices[0].message.content or ""
        data_t, err_t = parse_json_safely(raw_t)
        return ("text", data_t, err_t, raw_t)
    except Exception as e2:
        return ("text", None, f"Error en fallback de texto: {e2}", "")

# =============================
# Acciones
# =============================
col_run1, col_run2 = st.columns([1, 1])
with col_run1:
    run = st.button("üîé Verificar (visi√≥n ‚Üí texto)", type="primary", use_container_width=True)
with col_run2:
    clear = st.button("Limpiar", use_container_width=True)

if clear:
    st.rerun()

if run:
    if need_api_key():
        st.stop()
    if not uploads:
        st.warning("Sub√≠ al menos un archivo.")
        st.stop()

    # Preparar im√°genes para VISI√ìN
    all_imgs: List[str] = []
    with st.spinner("Preparando entradas para visi√≥n‚Ä¶"):
        for up in uploads:
            name = (up.name or "").lower()
            if name.endswith(".pdf"):
                try:
                    urls = pdf_to_b64_images(up.getvalue(), dpi=dpi, max_pages=max_pages_per_file)
                    all_imgs.extend(urls)
                except Exception as e:
                    st.error(f"Error convirtiendo {up.name}: {e}")
            elif any(name.endswith(ext) for ext in (".png", ".jpg", ".jpeg", ".webp")):
                try:
                    all_imgs.append(image_file_to_data_url(up))
                except Exception as e:
                    st.error(f"No se pudo procesar imagen {up.name}: {e}")
            # docx/txt/md/csv solo van al fallback de texto

    if preview and all_imgs:
        st.markdown("**Previsualizaci√≥n (primeras im√°genes):**")
        for url in all_imgs[:min(4, len(all_imgs))]:
            st.image(url, use_container_width=True)

    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=API_KEY)

    mode, data, err, raw = try_vision_then_text(
        client=client,
        modelo_vision=modelo_vision,
        image_urls=all_imgs,
        carrera=carrera,
        text_fallback_model=TEXT_FALLBACK_MODEL,
        uploads_for_text=uploads,
    )

    st.subheader("Resultado")
    st.caption(f"Ruta usada: **{('Visi√≥n' if mode=='vision' else 'Texto (fallback)')}**")

    if data:
        colr1, colr2 = st.columns([1, 2])
        with colr1:
            ok = bool(data.get("encontrada"))
            st.metric("Encontrada", "S√≠ ‚úÖ" if ok else "No ‚ùå")
            if "alias_detectado" in data:
                st.caption(f"Alias: {data.get('alias_detectado')}")
        with colr2:
            st.markdown("**Evidencia**")
            st.info(data.get("evidencia") or "‚Äî")
            if data.get("motivo"):
                st.markdown("**Motivo**")
                st.write(data.get("motivo"))
        with st.expander("JSON devuelto"):
            st.code(json.dumps(data, ensure_ascii=False, indent=2), language="json")
    else:
        st.warning(err or "No se pudo interpretar la salida.")
        if raw:
            with st.expander("Salida cruda"):
                st.code(raw)