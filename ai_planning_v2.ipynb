{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27158e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import JQL, FIELDS, BASE_URL, JIRA_DOMAIN,EMAIL, MAX_RESULTS, MODULE_DEVS, VALID_STATUSES, MAIL_MAP, DAILY_HOURS,MIN_PROJECT_RATIO,PROJECT_MAP, DEFAULT_END_DATE, DEFAULT_END_DATE_with_timezone, DEFAULT_START_DATE,DEFAULT_START_DATE_with_timezone\n",
    "from token_hidden import API_TOKEN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "942e7ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Linked keys found: 5419\n",
      "üíæ JSON enriched saved: jira_it_issues.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "from typing import List, Dict, Any, Set\n",
    "\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "# ========= Config =========\n",
    "\n",
    "\n",
    "AUTH = HTTPBasicAuth(EMAIL, API_TOKEN)\n",
    "HEADERS = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "\n",
    "# JQL principal (ajustar a lo que uses)\n",
    "JQL = \"\"\"\n",
    "project = IT\n",
    "AND issuetype NOT IN (Epic, Sub-task, Subtarea)\n",
    "ORDER BY priority DESC, duedate ASC\n",
    "\"\"\".strip()\n",
    "\n",
    "# Campos que quer√©s en los issues \"base\"\n",
    "MAIN_FIELDS = [\n",
    "    \"summary\",\n",
    "    \"project\",\n",
    "    \"reporter\",\n",
    "    \"assignee\",\n",
    "    \"status\",\n",
    "    \"priority\",\n",
    "    \"issuetype\",\n",
    "    \"timetracking\",\n",
    "    \"duedate\",\n",
    "    \"customfield_10016\",  # Story Points\n",
    "    \"customfield_10212\",  # M√≥dulo (ejemplo)\n",
    "    \"customfield_10214\",\n",
    "    \"customfield_10442\",\n",
    "    \"customfield_10608\",\n",
    "    \"issuelinks\"          # ¬°necesario para ver v√≠nculos!\n",
    "]\n",
    "\n",
    "# Campos que quer√©s traer del issue vinculado (adem√°s de summary/status/priority, etc.)\n",
    "WANTED_FIELDS = [\n",
    "    \"customfield_10209\",\n",
    "]\n",
    "\n",
    "MAX_RESULTS = 100\n",
    "CHUNK_LINKED = 50  # tama√±o de lote para buscar issues vinculados\n",
    "OUT_JSON = \"jira_it_issues.json\"\n",
    "  # opcional\n",
    "JIRA_API_ROOT = \"https://team-1583163151751.atlassian.net/rest/api/3\"\n",
    "SEARCH_JQL_URL = f\"{JIRA_API_ROOT}/search/jql\"  \n",
    "\n",
    "# ========= Funciones utilitarias =========\n",
    "def fetch_issues_paged(jql: str, fields: list[str]) -> list[dict]:\n",
    "    all_issues = []\n",
    "    next_token = None\n",
    "    while True:\n",
    "        payload = {\n",
    "            \"jql\": jql,\n",
    "            \"fields\": fields,          # lista (inclu√≠ siempre 'issuelinks')\n",
    "            \"maxResults\": MAX_RESULTS, # mismo nombre\n",
    "        }\n",
    "        if next_token:\n",
    "            payload[\"nextPageToken\"] = next_token\n",
    "\n",
    "        resp = requests.post(SEARCH_JQL_URL, headers=HEADERS, auth=AUTH, json=payload, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "\n",
    "        issues = data.get(\"issues\", [])\n",
    "        all_issues.extend(issues)\n",
    "\n",
    "        # Nueva paginaci√≥n\n",
    "        if data.get(\"isLast\", False):\n",
    "            break\n",
    "        next_token = data.get(\"nextPageToken\")\n",
    "        if not next_token:  # fallback defensivo\n",
    "            break\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    return all_issues\n",
    "\n",
    "\n",
    "def collect_linked_issue_keys(issues: List[Dict[str, Any]], only_types: List[str] = None) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Recolecta todas las keys de inward/outward de issuelinks.\n",
    "    only_types: si lo pas√°s, filtr√°s por nombre de tipo de v√≠nculo (p.ej. [\"Problem/Incident\"])\n",
    "    \"\"\"\n",
    "    keys: Set[str] = set()\n",
    "    for it in issues:\n",
    "        links = it.get(\"fields\", {}).get(\"issuelinks\", []) or []\n",
    "        for link in links:\n",
    "            if only_types and link.get(\"type\", {}).get(\"name\") not in only_types:\n",
    "                continue\n",
    "            for side in (\"outwardIssue\", \"inwardIssue\"):\n",
    "                if side in link and \"key\" in link[side]:\n",
    "                    keys.add(link[side][\"key\"])\n",
    "    print(f\"üîó Linked keys found: {len(keys)}\")\n",
    "    return keys\n",
    "\n",
    "\n",
    "def fetch_issues_by_keys(keys: list[str], fields: list[str], chunk: int = CHUNK_LINKED) -> dict[str, dict]:\n",
    "    out = {}\n",
    "    for i in range(0, len(keys), chunk):\n",
    "        slice_keys = keys[i:i+chunk]\n",
    "        jql = f\"issuekey in ({','.join(slice_keys)})\"\n",
    "\n",
    "        next_token = None\n",
    "        while True:\n",
    "            payload = {\n",
    "                \"jql\": jql,\n",
    "                \"fields\": fields,\n",
    "                \"maxResults\": 100,\n",
    "            }\n",
    "            if next_token:\n",
    "                payload[\"nextPageToken\"] = next_token\n",
    "\n",
    "            resp = requests.post(SEARCH_JQL_URL, headers=HEADERS, auth=AUTH, json=payload, timeout=30)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "\n",
    "            for issue in data.get(\"issues\", []):\n",
    "                out[issue[\"key\"]] = issue\n",
    "\n",
    "            if data.get(\"isLast\", False):\n",
    "                break\n",
    "            next_token = data.get(\"nextPageToken\")\n",
    "            if not next_token:\n",
    "                break\n",
    "            time.sleep(0.2)\n",
    "    return out\n",
    "\n",
    "def enrich_issue_links_with_fields(issues: List[Dict[str, Any]],\n",
    "                                   linked_map: Dict[str, Dict[str, Any]],\n",
    "                                   fields_to_copy: List[str]) -> None:\n",
    "    \"\"\"Inyecta 'fields_to_copy' dentro de outward/inwardIssue.fields si NO existen a√∫n en el issue base.\"\"\"\n",
    "    for it in issues:\n",
    "        links = it.get(\"fields\", {}).get(\"issuelinks\", []) or []\n",
    "        for link in links:\n",
    "            for side in (\"outwardIssue\", \"inwardIssue\"):\n",
    "                if side in link and \"key\" in link[side]:\n",
    "                    k = link[side][\"key\"]\n",
    "                    if k in linked_map:\n",
    "                        link[side].setdefault(\"fields\", {})\n",
    "                        src_fields = linked_map[k].get(\"fields\", {})\n",
    "                        for f in fields_to_copy:\n",
    "                            # ‚õîÔ∏è Solo insertar si NO estaba definido antes\n",
    "                            if f not in link[side][\"fields\"]:\n",
    "                                link[side][\"fields\"][f] = src_fields.get(f)\n",
    "\n",
    "def check_links_integrity(before: List[Dict[str, Any]], after: List[Dict[str, Any]]) -> None:\n",
    "    \"\"\"Verifica que los v√≠nculos cr√≠ticos como 'Blocks' no se hayan perdido tras enriquecer.\"\"\"\n",
    "    for b_issue, a_issue in zip(before, after):\n",
    "        b_links = b_issue.get(\"fields\", {}).get(\"issuelinks\", [])\n",
    "        a_links = a_issue.get(\"fields\", {}).get(\"issuelinks\", [])\n",
    "        b_blocks = {(l.get(\"type\", {}).get(\"name\"), l.get(\"outwardIssue\", {}).get(\"key\"), l.get(\"inwardIssue\", {}).get(\"key\")) for l in b_links if l.get(\"type\", {}).get(\"name\") == \"Blocks\"}\n",
    "        a_blocks = {(l.get(\"type\", {}).get(\"name\"), l.get(\"outwardIssue\", {}).get(\"key\"), l.get(\"inwardIssue\", {}).get(\"key\")) for l in a_links if l.get(\"type\", {}).get(\"name\") == \"Blocks\"}\n",
    "\n",
    "        if b_blocks != a_blocks:\n",
    "            print(f\"üö® WARNING: Issue {b_issue['key']} had Blocks links altered!\")\n",
    "\n",
    "def flatten_links_to_csv(issues: List[Dict[str, Any]],\n",
    "                         csv_path: str,\n",
    "                         sides: List[str] = (\"outwardIssue\", \"inwardIssue\"),\n",
    "                         fields_for_flat: List[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Aplana v√≠nculos a CSV: una fila por (issue base, v√≠nculo).\n",
    "    fields_for_flat: columnas a sacar del vinculado (adem√°s de key y type).\n",
    "    \"\"\"\n",
    "    if fields_for_flat is None:\n",
    "        fields_for_flat = [\"summary\", \"status\", \"priority\", \"duedate\", \"customfield_10016\"]\n",
    "\n",
    "    rows = []\n",
    "    for it in issues:\n",
    "        base_key = it.get(\"key\")\n",
    "        base_summary = it.get(\"fields\", {}).get(\"summary\")\n",
    "        links = it.get(\"fields\", {}).get(\"issuelinks\", []) or []\n",
    "        for link in links:\n",
    "            link_type = link.get(\"type\", {}).get(\"name\")\n",
    "            for side in sides:\n",
    "                linked = link.get(side)\n",
    "                if not linked:\n",
    "                    continue\n",
    "                lkey = linked.get(\"key\")\n",
    "                lf = (linked.get(\"fields\") or {})\n",
    "                row = {\n",
    "                    \"base_issue\": base_key,\n",
    "                    \"base_summary\": base_summary,\n",
    "                    \"link_type\": link_type or \"\",\n",
    "                    \"link_side\": side,\n",
    "                    \"linked_issue\": lkey,\n",
    "                }\n",
    "                # Agregar columnas pedidas\n",
    "                # status/priority vienen como objetos; sacar el \"name\" si existe\n",
    "                for col in fields_for_flat:\n",
    "                    val = lf.get(col)\n",
    "                    if isinstance(val, dict) and \"name\" in val:\n",
    "                        val = val[\"name\"]\n",
    "                    row[col] = val\n",
    "                rows.append(row)\n",
    "\n",
    "    # Escribir CSV\n",
    "    fieldnames = [\"base_issue\", \"base_summary\", \"link_type\", \"link_side\", \"linked_issue\"] + fields_for_flat\n",
    "    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "    print(f\"üìÑ Links CSV saved: {csv_path} ({len(rows)} rows)\")\n",
    "\n",
    "\n",
    "# ========= Main =========\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Descargar issues base (con issuelinks)\n",
    "    base_issues = fetch_issues_paged(JQL, MAIN_FIELDS)\n",
    "\n",
    "    # 2) Recolectar keys de issues vinculados\n",
    "    linked_keys = collect_linked_issue_keys(base_issues, only_types=None)  # pod√©s filtrar por tipo si quer√©s\n",
    "\n",
    "    # 3) Traer info de issues vinculados (campos personalizados deseados)\n",
    "    linked_map = {}\n",
    "    if linked_keys:\n",
    "        linked_map = fetch_issues_by_keys(\n",
    "            list(linked_keys),\n",
    "            fields=WANTED_FIELDS,\n",
    "        )\n",
    "\n",
    "    # 4) Enriquecer los v√≠nculos en la estructura original\n",
    "    base_issues_before = base_issues\n",
    "    if linked_map:\n",
    "        enrich_issue_links_with_fields(base_issues, linked_map, WANTED_FIELDS)\n",
    "\n",
    "    check_links_integrity(base_issues_before, base_issues)\n",
    "    # 5) Guardar JSON enriquecido\n",
    "    with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"issues\": base_issues}, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"üíæ JSON enriched saved: {OUT_JSON}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Download epics\n",
    "def fetch_epics():\n",
    "    all_epics = {}\n",
    "\n",
    "    # Epics del proyecto\n",
    "    jql_epics = 'project = IT AND issuetype = Epic'\n",
    "    for_epics = {\"jql\": jql_epics, \"fields\": [\"key\",\"duedate\",\"summary\"], \"maxResults\": 100}\n",
    "\n",
    "    next_token = None\n",
    "    while True:\n",
    "        payload = dict(for_epics, **({\"nextPageToken\": next_token} if next_token else {}))\n",
    "        r = requests.post(SEARCH_JQL_URL, headers=HEADERS, auth=AUTH, json=payload, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "\n",
    "        for issue in data.get(\"issues\", []):\n",
    "            epic_key = issue[\"key\"]\n",
    "            f = issue.get(\"fields\", {}) or {}\n",
    "            all_epics[epic_key] = {\n",
    "                \"due_date\": f.get(\"duedate\"),\n",
    "                \"summary\": f.get(\"summary\", \"\"),\n",
    "                \"tasks\": []\n",
    "            }\n",
    "\n",
    "            # Historias de esa √©pica\n",
    "            jql_stories = f'\"Epic Link\" = {epic_key}'\n",
    "            next_story = None\n",
    "            while True:\n",
    "                story_payload = {\n",
    "                    \"jql\": jql_stories,\n",
    "                    \"fields\": [\"key\",\"customfield_10016\",\"status\"],\n",
    "                    \"maxResults\": 100\n",
    "                }\n",
    "                if next_story:\n",
    "                    story_payload[\"nextPageToken\"] = next_story\n",
    "\n",
    "                sr = requests.post(SEARCH_JQL_URL, headers=HEADERS, auth=AUTH, json=story_payload, timeout=30)\n",
    "                sr.raise_for_status()\n",
    "                sd = sr.json()\n",
    "\n",
    "                for st in sd.get(\"issues\", []):\n",
    "                    sf = st.get(\"fields\", {}) or {}\n",
    "                    all_epics[epic_key][\"tasks\"].append({\n",
    "                        \"key\": st[\"key\"],\n",
    "                        \"story_points\": sf.get(\"customfield_10016\"),\n",
    "                        \"status\": (sf.get(\"status\") or {}).get(\"name\", \"Sin estado\")\n",
    "                    })\n",
    "\n",
    "                if sd.get(\"isLast\", False):\n",
    "                    break\n",
    "                next_story = sd.get(\"nextPageToken\")\n",
    "                if not next_story:\n",
    "                    break\n",
    "\n",
    "        if data.get(\"isLast\", False):\n",
    "            break\n",
    "        next_token = data.get(\"nextPageToken\")\n",
    "        if not next_token:\n",
    "            break\n",
    "\n",
    "    return all_epics\n",
    "\n",
    "epics = fetch_epics()\n",
    "\n",
    "# Guardar en archivo si lo deseas\n",
    "with open(\"epics_due_lookup.json\", \"w\") as f:\n",
    "    json.dump(epics, f, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7e65b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = '346436483896-non6bmg405eh4avr5saql5m1r0r37rim.apps.googleusercontent.com'\n",
    "client_secret = '346436483896-non6bmg405eh4avr5saql5m1r0r37rim.apps.googleusercontent.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "711b5556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Consultando reuniones de Luis Uran (luisuran@biamex.com)...\n",
      "üîé Consultando reuniones de Diego Martin Gogorza (diegogogorza@biamex.com)...\n",
      "üîé Consultando reuniones de Nicolas Pardo (nicolaspardo@biamex.com)...\n",
      "üîé Consultando reuniones de Martin Horn (martinhorn@biamex.com)...\n",
      "üîé Consultando reuniones de Facundo Capua (facundocapua@biamex.com)...\n",
      "üîé Consultando reuniones de Franco Lorenzo (francolorenzo@biamex.com)...\n",
      "üîé Consultando reuniones de Alan Mori - Carestino (alanmori@biamex.com)...\n",
      "üîé Consultando reuniones de Gast√≥n Ojeda (gastonojeda@biamex.com)...\n",
      "üîé Consultando reuniones de Miguel Armentano (miguelarmentano@biamex.com)...\n",
      "üîé Consultando reuniones de Juan Ignacio Morelis - Carestino (juanmorelis@biamex.com)...\n",
      "üìÖ Luis Uran: 10 bloque(s) ocupado(s)\n",
      "   üïì 2025-10-27 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-28 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-29 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-29 09:00 ‚Üí 09:30\n",
      "   üïì 2025-10-30 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-31 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-03 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-04 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-05 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-06 08:30 ‚Üí 09:00\n",
      "üìÖ Diego Martin Gogorza: 25 bloque(s) ocupado(s)\n",
      "   üïì 2025-10-27 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-27 11:00 ‚Üí 12:00\n",
      "   üïì 2025-10-28 07:30 ‚Üí 08:30\n",
      "   üïì 2025-10-28 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-28 14:30 ‚Üí 15:00\n",
      "   üïì 2025-10-28 16:00 ‚Üí 16:30\n",
      "   üïì 2025-10-29 08:00 ‚Üí 08:30\n",
      "   üïì 2025-10-29 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-29 09:00 ‚Üí 09:30\n",
      "   üïì 2025-10-29 10:00 ‚Üí 12:00\n",
      "   üïì 2025-10-29 11:00 ‚Üí 12:00\n",
      "   üïì 2025-10-30 07:30 ‚Üí 08:30\n",
      "   üïì 2025-10-30 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-31 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-03 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-03 11:00 ‚Üí 12:00\n",
      "   üïì 2025-11-03 14:30 ‚Üí 15:00\n",
      "   üïì 2025-11-04 07:30 ‚Üí 08:30\n",
      "   üïì 2025-11-04 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-04 14:30 ‚Üí 15:00\n",
      "   üïì 2025-11-05 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-05 10:00 ‚Üí 12:00\n",
      "   üïì 2025-11-05 11:00 ‚Üí 12:00\n",
      "   üïì 2025-11-06 07:30 ‚Üí 08:30\n",
      "   üïì 2025-11-06 08:30 ‚Üí 09:00\n",
      "üìÖ Nicolas Pardo: 30 bloque(s) ocupado(s)\n",
      "   üïì 2025-10-27 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-27 09:00 ‚Üí 10:00\n",
      "   üïì 2025-10-27 10:30 ‚Üí 11:00\n",
      "   üïì 2025-10-27 11:00 ‚Üí 12:00\n",
      "   üïì 2025-10-28 07:30 ‚Üí 08:30\n",
      "   üïì 2025-10-28 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-29 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-29 09:00 ‚Üí 09:30\n",
      "   üïì 2025-10-29 09:30 ‚Üí 10:00\n",
      "   üïì 2025-10-29 10:00 ‚Üí 12:00\n",
      "   üïì 2025-10-29 11:00 ‚Üí 12:00\n",
      "   üïì 2025-10-29 13:00 ‚Üí 14:00\n",
      "   üïì 2025-10-30 07:30 ‚Üí 08:30\n",
      "   üïì 2025-10-30 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-30 09:00 ‚Üí 10:00\n",
      "   üïì 2025-10-31 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-03 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-03 09:00 ‚Üí 10:00\n",
      "   üïì 2025-11-03 10:30 ‚Üí 11:00\n",
      "   üïì 2025-11-03 11:00 ‚Üí 12:00\n",
      "   üïì 2025-11-04 07:30 ‚Üí 08:30\n",
      "   üïì 2025-11-04 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-05 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-05 09:30 ‚Üí 10:00\n",
      "   üïì 2025-11-05 10:00 ‚Üí 12:00\n",
      "   üïì 2025-11-05 11:00 ‚Üí 12:00\n",
      "   üïì 2025-11-05 13:00 ‚Üí 14:00\n",
      "   üïì 2025-11-06 07:30 ‚Üí 08:30\n",
      "   üïì 2025-11-06 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-06 09:00 ‚Üí 10:00\n",
      "üìÖ Martin Horn: 54 bloque(s) ocupado(s)\n",
      "   üïì 2025-10-27 08:30 ‚Üí 08:35\n",
      "   üïì 2025-10-27 09:15 ‚Üí 09:25\n",
      "   üïì 2025-10-27 10:00 ‚Üí 10:30\n",
      "   üïì 2025-10-27 11:30 ‚Üí 12:30\n",
      "   üïì 2025-10-27 15:00 ‚Üí 15:30\n",
      "   üïì 2025-10-27 16:30 ‚Üí 17:00\n",
      "   üïì 2025-10-27 19:00 ‚Üí 21:00\n",
      "   üïì 2025-10-28 06:00 ‚Üí 08:00\n",
      "   üïì 2025-10-28 10:00 ‚Üí 11:00\n",
      "   üïì 2025-10-28 14:30 ‚Üí 15:00\n",
      "   üïì 2025-10-28 15:00 ‚Üí 15:30\n",
      "   üïì 2025-10-28 16:00 ‚Üí 16:30\n",
      "   üïì 2025-10-28 19:00 ‚Üí 21:00\n",
      "   üïì 2025-10-29 10:00 ‚Üí 12:00\n",
      "   üïì 2025-10-29 14:00 ‚Üí 14:45\n",
      "   üïì 2025-10-29 15:00 ‚Üí 15:45\n",
      "   üïì 2025-10-29 16:30 ‚Üí 17:00\n",
      "   üïì 2025-10-29 17:00 ‚Üí 17:30\n",
      "   üïì 2025-10-30 06:00 ‚Üí 08:00\n",
      "   üïì 2025-10-30 09:30 ‚Üí 10:00\n",
      "   üïì 2025-10-30 10:30 ‚Üí 11:00\n",
      "   üïì 2025-10-30 13:00 ‚Üí 14:00\n",
      "   üïì 2025-10-30 14:00 ‚Üí 15:00\n",
      "   üïì 2025-10-30 16:00 ‚Üí 16:45\n",
      "   üïì 2025-10-30 19:00 ‚Üí 21:00\n",
      "   üïì 2025-10-31 15:00 ‚Üí 16:00\n",
      "   üïì 2025-10-31 19:00 ‚Üí 22:00\n",
      "   üïì 2025-11-03 09:15 ‚Üí 09:25\n",
      "   üïì 2025-11-03 10:00 ‚Üí 10:30\n",
      "   üïì 2025-11-03 11:30 ‚Üí 12:30\n",
      "   üïì 2025-11-03 14:30 ‚Üí 15:00\n",
      "   üïì 2025-11-03 15:00 ‚Üí 15:30\n",
      "   üïì 2025-11-03 16:30 ‚Üí 17:00\n",
      "   üïì 2025-11-03 19:00 ‚Üí 21:00\n",
      "   üïì 2025-11-04 06:00 ‚Üí 08:00\n",
      "   üïì 2025-11-04 10:00 ‚Üí 11:00\n",
      "   üïì 2025-11-04 14:30 ‚Üí 15:00\n",
      "   üïì 2025-11-04 15:00 ‚Üí 15:30\n",
      "   üïì 2025-11-04 19:00 ‚Üí 21:00\n",
      "   üïì 2025-11-05 08:30 ‚Üí 08:31\n",
      "   üïì 2025-11-05 10:00 ‚Üí 12:00\n",
      "   üïì 2025-11-05 14:00 ‚Üí 14:45\n",
      "   üïì 2025-11-05 15:00 ‚Üí 15:45\n",
      "   üïì 2025-11-05 16:30 ‚Üí 17:00\n",
      "   üïì 2025-11-05 17:00 ‚Üí 17:30\n",
      "   üïì 2025-11-05 17:30 ‚Üí 19:00\n",
      "   üïì 2025-11-06 05:30 ‚Üí 08:30\n",
      "   üïì 2025-11-06 06:00 ‚Üí 08:00\n",
      "   üïì 2025-11-06 09:30 ‚Üí 10:00\n",
      "   üïì 2025-11-06 10:30 ‚Üí 11:00\n",
      "   üïì 2025-11-06 13:00 ‚Üí 14:00\n",
      "   üïì 2025-11-06 14:00 ‚Üí 15:00\n",
      "   üïì 2025-11-06 16:00 ‚Üí 16:45\n",
      "   üïì 2025-11-06 19:00 ‚Üí 21:00\n",
      "üìÖ Facundo Capua: 0 bloque(s) ocupado(s)\n",
      "üìÖ Franco Lorenzo: 27 bloque(s) ocupado(s)\n",
      "   üïì 2025-10-27 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-27 10:00 ‚Üí 10:50\n",
      "   üïì 2025-10-27 13:00 ‚Üí 14:00\n",
      "   üïì 2025-10-28 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-28 09:00 ‚Üí 09:40\n",
      "   üïì 2025-10-28 13:00 ‚Üí 14:00\n",
      "   üïì 2025-10-29 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-29 09:00 ‚Üí 09:30\n",
      "   üïì 2025-10-29 10:00 ‚Üí 10:50\n",
      "   üïì 2025-10-29 13:00 ‚Üí 14:00\n",
      "   üïì 2025-10-30 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-30 09:00 ‚Üí 09:40\n",
      "   üïì 2025-10-30 13:00 ‚Üí 14:00\n",
      "   üïì 2025-10-31 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-31 13:00 ‚Üí 14:00\n",
      "   üïì 2025-11-03 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-03 10:00 ‚Üí 10:50\n",
      "   üïì 2025-11-03 13:00 ‚Üí 14:00\n",
      "   üïì 2025-11-04 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-04 09:00 ‚Üí 09:40\n",
      "   üïì 2025-11-04 13:00 ‚Üí 14:00\n",
      "   üïì 2025-11-05 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-05 10:00 ‚Üí 10:50\n",
      "   üïì 2025-11-05 13:00 ‚Üí 14:00\n",
      "   üïì 2025-11-06 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-06 09:00 ‚Üí 09:40\n",
      "   üïì 2025-11-06 13:00 ‚Üí 14:00\n",
      "üìÖ Alan Mori - Carestino: 19 bloque(s) ocupado(s)\n",
      "   üïì 2025-10-27 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-27 10:30 ‚Üí 10:35\n",
      "   üïì 2025-10-28 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-28 10:30 ‚Üí 10:35\n",
      "   üïì 2025-10-29 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-29 09:00 ‚Üí 09:30\n",
      "   üïì 2025-10-29 10:30 ‚Üí 10:35\n",
      "   üïì 2025-10-30 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-30 10:30 ‚Üí 10:35\n",
      "   üïì 2025-10-31 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-31 10:30 ‚Üí 10:35\n",
      "   üïì 2025-11-03 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-03 10:30 ‚Üí 10:35\n",
      "   üïì 2025-11-04 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-04 10:30 ‚Üí 10:35\n",
      "   üïì 2025-11-05 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-05 10:30 ‚Üí 10:35\n",
      "   üïì 2025-11-06 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-06 10:30 ‚Üí 10:35\n",
      "üìÖ Gast√≥n Ojeda: 29 bloque(s) ocupado(s)\n",
      "   üïì 2025-10-27 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-27 11:00 ‚Üí 12:00\n",
      "   üïì 2025-10-27 12:00 ‚Üí 13:00\n",
      "   üïì 2025-10-28 07:30 ‚Üí 08:30\n",
      "   üïì 2025-10-28 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-28 12:00 ‚Üí 13:00\n",
      "   üïì 2025-10-28 14:30 ‚Üí 15:00\n",
      "   üïì 2025-10-29 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-29 09:00 ‚Üí 09:30\n",
      "   üïì 2025-10-29 11:00 ‚Üí 12:00\n",
      "   üïì 2025-10-29 12:00 ‚Üí 13:00\n",
      "   üïì 2025-10-30 07:30 ‚Üí 08:30\n",
      "   üïì 2025-10-30 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-30 12:00 ‚Üí 13:00\n",
      "   üïì 2025-10-31 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-31 12:00 ‚Üí 13:00\n",
      "   üïì 2025-11-03 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-03 11:00 ‚Üí 12:00\n",
      "   üïì 2025-11-03 12:00 ‚Üí 13:00\n",
      "   üïì 2025-11-04 07:30 ‚Üí 08:30\n",
      "   üïì 2025-11-04 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-04 12:00 ‚Üí 13:00\n",
      "   üïì 2025-11-04 14:30 ‚Üí 15:00\n",
      "   üïì 2025-11-05 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-05 11:00 ‚Üí 12:00\n",
      "   üïì 2025-11-05 12:00 ‚Üí 13:00\n",
      "   üïì 2025-11-06 07:30 ‚Üí 08:30\n",
      "   üïì 2025-11-06 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-06 12:00 ‚Üí 13:00\n",
      "üìÖ Miguel Armentano: 19 bloque(s) ocupado(s)\n",
      "   üïì 2025-10-27 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-27 12:00 ‚Üí 13:00\n",
      "   üïì 2025-10-28 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-28 12:00 ‚Üí 13:00\n",
      "   üïì 2025-10-29 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-29 09:00 ‚Üí 09:30\n",
      "   üïì 2025-10-29 12:00 ‚Üí 13:00\n",
      "   üïì 2025-10-30 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-30 12:00 ‚Üí 13:00\n",
      "   üïì 2025-10-31 08:30 ‚Üí 09:00\n",
      "   üïì 2025-10-31 12:00 ‚Üí 13:00\n",
      "   üïì 2025-11-03 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-03 12:00 ‚Üí 13:00\n",
      "   üïì 2025-11-04 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-04 12:00 ‚Üí 13:00\n",
      "   üïì 2025-11-05 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-05 12:00 ‚Üí 13:00\n",
      "   üïì 2025-11-06 08:30 ‚Üí 09:00\n",
      "   üïì 2025-11-06 12:00 ‚Üí 13:00\n",
      "üìÖ Juan Ignacio Morelis - Carestino: 17 bloque(s) ocupado(s)\n",
      "   üïì 2025-10-27 13:00 ‚Üí 14:00\n",
      "   üïì 2025-10-28 13:00 ‚Üí 14:00\n",
      "   üïì 2025-10-29 10:00 ‚Üí 12:00\n",
      "   üïì 2025-10-29 13:00 ‚Üí 14:00\n",
      "   üïì 2025-10-29 14:00 ‚Üí 14:45\n",
      "   üïì 2025-10-30 13:00 ‚Üí 14:00\n",
      "   üïì 2025-10-30 14:00 ‚Üí 15:00\n",
      "   üïì 2025-10-31 13:00 ‚Üí 14:00\n",
      "   üïì 2025-11-01 13:00 ‚Üí 14:00\n",
      "   üïì 2025-11-02 13:00 ‚Üí 14:00\n",
      "   üïì 2025-11-03 13:00 ‚Üí 14:00\n",
      "   üïì 2025-11-04 13:00 ‚Üí 14:00\n",
      "   üïì 2025-11-05 10:00 ‚Üí 12:00\n",
      "   üïì 2025-11-05 13:00 ‚Üí 14:00\n",
      "   üïì 2025-11-05 14:00 ‚Üí 14:45\n",
      "   üïì 2025-11-06 13:00 ‚Üí 14:00\n",
      "   üïì 2025-11-06 14:00 ‚Üí 15:00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "from collections import defaultdict\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "# üìå Permisos necesarios: lectura del calendario\n",
    "SCOPES = ['https://www.googleapis.com/auth/calendar.readonly']\n",
    "\n",
    "# üìÇ Archivos de autenticaci√≥n\n",
    "CREDENTIALS_PATH = 'client_secret.json'\n",
    "TOKEN_PATH = 'token.json'\n",
    "\n",
    "\n",
    "\n",
    "def obtener_credenciales():\n",
    "    creds = None\n",
    "    if os.path.exists(TOKEN_PATH):\n",
    "        creds = Credentials.from_authorized_user_file(TOKEN_PATH, SCOPES)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(CREDENTIALS_PATH, SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open(TOKEN_PATH, 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return creds\n",
    "\n",
    "def obtener_bloques_ocupados(email, creds, start_dt, end_dt):\n",
    "    service = build('calendar', 'v3', credentials=creds)\n",
    "    eventos_resultado = service.events().list(\n",
    "        calendarId=email,\n",
    "        timeMin=start_dt.isoformat(),\n",
    "        timeMax=end_dt.isoformat(),\n",
    "        singleEvents=True,\n",
    "        orderBy=\"startTime\"\n",
    "    ).execute()\n",
    "\n",
    "    eventos = eventos_resultado.get('items', [])\n",
    "    bloques_ocupados = []\n",
    "\n",
    "    for evento in eventos:\n",
    "        start_str = evento['start'].get('dateTime')\n",
    "        end_str = evento['end'].get('dateTime')\n",
    "        if not start_str or not end_str:\n",
    "            continue  # Omitir eventos de todo el d√≠a\n",
    "\n",
    "        start_time = datetime.datetime.fromisoformat(start_str)\n",
    "        end_time = datetime.datetime.fromisoformat(end_str)\n",
    "        bloques_ocupados.append((start_time, end_time))\n",
    "\n",
    "    return bloques_ocupados\n",
    "\n",
    "def obtener_bloques_por_dev():\n",
    "    creds = obtener_credenciales()\n",
    "    bloques_por_dev = {}\n",
    "\n",
    "    for dev, email in MAIL_MAP.items():\n",
    "        print(f\"üîé Consultando reuniones de {dev} ({email})...\")\n",
    "        try:\n",
    "            bloques = obtener_bloques_ocupados(email, creds, DEFAULT_START_DATE_with_timezone, DEFAULT_END_DATE_with_timezone)\n",
    "            bloques_por_dev[dev] = bloques\n",
    "            #print(f\"   ‚úÖ {len(bloques)} reuniones encontradas.\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error consultando {email}: {str(e)}\\n\")\n",
    "            bloques_por_dev[dev] = []\n",
    "\n",
    "    return bloques_por_dev\n",
    "\n",
    "# Para usar de forma aislada:\n",
    "if __name__ == \"__main__\":\n",
    "    bloques = obtener_bloques_por_dev()\n",
    "    for dev, bloques_list in bloques.items():\n",
    "        print(f\"üìÖ {dev}: {len(bloques_list)} bloque(s) ocupado(s)\")\n",
    "        for start, end in bloques_list:\n",
    "            print(f\"   üïì {start.strftime('%Y-%m-%d %H:%M')} ‚Üí {end.strftime('%H:%M')}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "761eeca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Miguel Armentano:\n",
      "  üéØ Epic target: 50.0%\n",
      "  üìä Total in range: 19.0 h | Epic in range: 0.0 h\n",
      "  üîç Epic tasks out of range: 6\n",
      "    - IT-21393 (5.0 h) due 2025-09-30\n",
      "    - IT-20942 (8.0 h) due 2025-10-17\n",
      "    - IT-20578 (44.0 h) due 2026-02-20\n",
      "    - IT-20577 (64.0 h) due 2026-02-20\n",
      "    - IT-11523 (8.0 h) due 2026-02-20\n",
      "    - IT-11789 (2.0 h) due 2100-01-01\n",
      " modificando IT-21393 due 2100-01-01\n",
      "‚úîÔ∏è Ratio tras forzar IT-21393: 5.0 / (50.0) = 10.0%\n",
      " modificando IT-20942 due 2100-01-01\n",
      "‚úîÔ∏è Ratio tras forzar IT-20942: 13.0 / (50.0) = 26.0%\n",
      " modificando IT-20578 due 2100-01-01\n",
      "‚úîÔ∏è Ratio tras forzar IT-20578: 57.0 / (50.0) = 114.0%\n",
      "\n",
      "üîé Alan Mori - Carestino:\n",
      "  üéØ Epic target: 70.0%\n",
      "  üìä Total in range: 1.0 h | Epic in range: 0.0 h\n",
      "  üîç Epic tasks out of range: 19\n",
      "    - IT-21935 (12.0 h) due 2025-10-16\n",
      "    - IT-21571 (8.0 h) due 2025-10-17\n",
      "    - IT-21786 (1.0 h) due 2025-11-19\n",
      "    - IT-20630 (12.0 h) due 2025-12-05\n",
      "    - IT-20655 (32.0 h) due 2025-12-26\n",
      "    - IT-21987 (6.0 h) due 2026-03-09\n",
      "    - IT-21452 (16.0 h) due 2026-03-09\n",
      "    - IT-21391 (16.0 h) due 2026-03-09\n",
      "    - IT-21330 (8.0 h) due 2026-03-09\n",
      "    - IT-21847 (24.0 h) due 2026-03-09\n",
      "    - IT-21778 (24.0 h) due 2026-03-09\n",
      "    - IT-21510 (8.0 h) due 2026-03-09\n",
      "    - IT-21342 (16.0 h) due 2026-03-09\n",
      "    - IT-21326 (2.0 h) due 2026-03-09\n",
      "    - IT-21197 (8.0 h) due 2026-03-09\n",
      "    - IT-20531 (24.0 h) due 2026-03-09\n",
      "    - IT-21450 (4.0 h) due 2026-03-09\n",
      "    - IT-21013 (16.0 h) due 2026-03-09\n",
      "    - IT-20781 (18.0 h) due 2026-03-09\n",
      " modificando IT-21935 due 2026-03-09\n",
      "‚úîÔ∏è Ratio tras forzar IT-21935: 12.0 / (55.0) = 21.8%\n",
      " modificando IT-21571 due 2026-03-09\n",
      "‚úîÔ∏è Ratio tras forzar IT-21571: 20.0 / (55.0) = 36.4%\n",
      " modificando IT-21786 due 2026-03-09\n",
      "‚úîÔ∏è Ratio tras forzar IT-21786: 21.0 / (55.0) = 38.2%\n",
      " modificando IT-20630 due 2026-03-09\n",
      "‚úîÔ∏è Ratio tras forzar IT-20630: 33.0 / (55.0) = 60.0%\n",
      " modificando IT-20655 due 2026-03-09\n",
      "‚úîÔ∏è Ratio tras forzar IT-20655: 65.0 / (55.0) = 118.2%\n",
      "\n",
      "üîé Gast√≥n Ojeda:\n",
      "  üéØ Epic target: 0.0%\n",
      "  üìä Total in range: 18.0 h | Epic in range: 0.0 h\n",
      "  üîç Epic tasks out of range: 12\n",
      "    - IT-15010 (16.0 h) due 2024-09-13\n",
      "    - IT-21844 (2.0 h) due 2025-09-30\n",
      "    - IT-20386 (8.0 h) due 2025-11-28\n",
      "    - IT-14961 (16.0 h) due 2025-11-30\n",
      "    - IT-15941 (6.0 h) due 2100-01-01\n",
      "    - IT-15936 (4.0 h) due 2100-01-01\n",
      "    - IT-15935 (8.0 h) due 2100-01-01\n",
      "    - IT-15932 (5.0 h) due 2100-01-01\n",
      "    - IT-15931 (1.0 h) due 2100-01-01\n",
      "    - IT-15929 (5.0 h) due 2100-01-01\n",
      "    - IT-15927 (5.0 h) due 2100-01-01\n",
      "    - IT-15922 (16.0 h) due 2100-01-01\n",
      " modificando IT-15010 due 2100-01-01\n",
      "‚úîÔ∏è Ratio tras forzar IT-15010: 16.0 / (50.0) = 32.0%\n",
      "\n",
      "üîé Franco Lorenzo:\n",
      "  üéØ Epic target: 50.0%\n",
      "  üìä Total in range: 0.0 h | Epic in range: 0.0 h\n",
      "  üîç Epic tasks out of range: 3\n",
      "    - IT-20114 (34.0 h) due 2025-07-02\n",
      "    - IT-20697 (20.0 h) due 2025-12-26\n",
      "    - IT-20880 (24.0 h) due 2100-01-01\n",
      " modificando IT-20114 due 2100-01-01\n",
      "‚úîÔ∏è Ratio tras forzar IT-20114: 34.0 / (50.0) = 68.0%\n",
      "\n",
      "üîé Facundo Capua:\n",
      "  üéØ Epic target: 10.0%\n",
      "  üìä Total in range: 0.0 h | Epic in range: 0.0 h\n",
      "  üîç Epic tasks out of range: 21\n",
      "    - IT-20033 (2.0 h) due 2100-01-01\n",
      "    - IT-20032 (4.0 h) due 2100-01-01\n",
      "    - IT-20031 (4.0 h) due 2100-01-01\n",
      "    - IT-20030 (2.0 h) due 2100-01-01\n",
      "    - IT-20029 (5.0 h) due 2100-01-01\n",
      "    - IT-20028 (3.0 h) due 2100-01-01\n",
      "    - IT-20027 (3.0 h) due 2100-01-01\n",
      "    - IT-20026 (4.0 h) due 2100-01-01\n",
      "    - IT-20025 (4.0 h) due 2100-01-01\n",
      "    - IT-20024 (3.0 h) due 2100-01-01\n",
      "    - IT-20023 (3.0 h) due 2100-01-01\n",
      "    - IT-20022 (4.0 h) due 2100-01-01\n",
      "    - IT-20021 (2.0 h) due 2100-01-01\n",
      "    - IT-20020 (3.0 h) due 2100-01-01\n",
      "    - IT-20019 (3.0 h) due 2100-01-01\n",
      "    - IT-20018 (8.0 h) due 2100-01-01\n",
      "    - IT-20017 (2.0 h) due 2100-01-01\n",
      "    - IT-20016 (8.0 h) due 2100-01-01\n",
      "    - IT-20015 (3.0 h) due 2100-01-01\n",
      "    - IT-20011 (2.0 h) due 2100-01-01\n",
      "    - IT-20010 (2.0 h) due 2100-01-01\n",
      " modificando IT-20033 due 2100-01-01\n",
      "‚úîÔ∏è Ratio tras forzar IT-20033: 2.0 / (80.0) = 2.5%\n",
      " modificando IT-20032 due 2100-01-01\n",
      "‚úîÔ∏è Ratio tras forzar IT-20032: 6.0 / (80.0) = 7.5%\n",
      " modificando IT-20031 due 2100-01-01\n",
      "‚úîÔ∏è Ratio tras forzar IT-20031: 10.0 / (80.0) = 12.5%\n",
      "\n",
      "üîé Nicolas Pardo:\n",
      "  üéØ Epic target: 10.0%\n",
      "  üìä Total in range: 20.0 h | Epic in range: 0.0 h\n",
      "  üîç Epic tasks out of range: 1\n",
      "    - IT-21773 (4.0 h) due 2025-10-14\n",
      " modificando IT-21773 due 2025-10-14\n",
      "‚úîÔ∏è Ratio tras forzar IT-21773: 4.0 / (80.0) = 5.0%\n",
      "\n",
      "üîé Luis Uran:\n",
      "  üéØ Epic target: 50.0%\n",
      "  üìä Total in range: 0.0 h | Epic in range: 0.0 h\n",
      "  üîç Epic tasks out of range: 16\n",
      "    - IT-21873 (5.0 h) due 2025-11-14\n",
      "    - IT-16644 (2.0 h) due 2025-12-31\n",
      "    - IT-16643 (2.0 h) due 2025-12-31\n",
      "    - IT-16642 (4.0 h) due 2025-12-31\n",
      "    - IT-16641 (3.0 h) due 2025-12-31\n",
      "    - IT-16640 (4.0 h) due 2025-12-31\n",
      "    - IT-16639 (3.0 h) due 2025-12-31\n",
      "    - IT-16638 (7.0 h) due 2025-12-31\n",
      "    - IT-16635 (3.0 h) due 2025-12-31\n",
      "    - IT-16634 (6.0 h) due 2025-12-31\n",
      "    - IT-16633 (5.0 h) due 2025-12-31\n",
      "    - IT-16632 (3.0 h) due 2025-12-31\n",
      "    - IT-16525 (4.0 h) due 2025-12-31\n",
      "    - IT-16524 (2.0 h) due 2025-12-31\n",
      "    - IT-16523 (3.0 h) due 2025-12-31\n",
      "    - IT-16521 (4.0 h) due 2025-12-31\n",
      " modificando IT-21873 due 2025-12-31\n",
      "‚úîÔ∏è Ratio tras forzar IT-21873: 5.0 / (60.0) = 8.3%\n",
      " modificando IT-16644 due 2025-12-31\n",
      "‚úîÔ∏è Ratio tras forzar IT-16644: 7.0 / (60.0) = 11.7%\n",
      " modificando IT-16643 due 2025-12-31\n",
      "‚úîÔ∏è Ratio tras forzar IT-16643: 9.0 / (60.0) = 15.0%\n",
      " modificando IT-16642 due 2025-12-31\n",
      "‚úîÔ∏è Ratio tras forzar IT-16642: 13.0 / (60.0) = 21.7%\n",
      " modificando IT-16641 due 2025-12-31\n",
      "‚úîÔ∏è Ratio tras forzar IT-16641: 16.0 / (60.0) = 26.7%\n",
      " modificando IT-16640 due 2025-12-31\n",
      "‚úîÔ∏è Ratio tras forzar IT-16640: 20.0 / (60.0) = 33.3%\n",
      " modificando IT-16639 due 2025-12-31\n",
      "‚úîÔ∏è Ratio tras forzar IT-16639: 23.0 / (60.0) = 38.3%\n",
      " modificando IT-16638 due 2025-12-31\n",
      "‚úîÔ∏è Ratio tras forzar IT-16638: 30.0 / (60.0) = 50.0%\n",
      "\n",
      "üîé Diego Martin Gogorza:\n",
      "  üéØ Epic target: 10.0%\n",
      "  üìä Total in range: 0.0 h | Epic in range: 0.0 h\n",
      "  üîç Epic tasks out of range: 2\n",
      "    - IT-16252 (0 h) due 2020-06-30\n",
      "    - IT-16305 (0 h) due 2100-01-01\n",
      " modificando IT-16252 due 2100-01-01\n",
      "‚úîÔ∏è Ratio tras forzar IT-16252: 0.0 / (60.0) = 0.0%\n",
      " modificando IT-16305 due 2100-01-01\n",
      "‚úîÔ∏è Ratio tras forzar IT-16305: 0.0 / (60.0) = 0.0%\n",
      "\n",
      "üìù Developer Task Schedule Summary:\n",
      "\n",
      "üë®‚Äçüíª Developer: Miguel Armentano\n",
      "   üîπ IT-21102: 6.0h ‚Üí Due: 2025-09-18 | Finish: Start: 2025-10-27 09:00 | End: 2025-10-28 10:00\n",
      "   üîπ IT-21536: 6.0h ‚Üí Due: 2025-09-23 | Finish: Start: 2025-10-28 10:00 | End: 2025-10-29 11:30\n",
      "     üö® Puede derivarse a: Luis Uran\n",
      "   üîπ IT-21541: 10.0h ‚Üí Due: 2025-09-30 | Finish: Start: 2025-10-29 11:30 | End: 2025-10-31 11:00\n",
      "   üîπ IT-21539: 14.0h ‚Üí Due: 2025-09-30 | Finish: Start: 2025-10-31 11:00 | End: 2025-11-05 10:00\n",
      "   üîπ IT-21437: 8.0h ‚Üí Due: 2025-10-14 | Finish: Start: 2025-11-05 10:00 | End: 2025-11-06 14:00\n",
      "   üîπ IT-21669: 4.0h ‚Üí Due: 2025-10-16 | Finish: Start: 2025-11-06 14:00 | End: 2025-11-07 11:30\n",
      "   üîπ IT-21740: 4.0h ‚Üí Due: 2025-10-21 | Finish: Start: 2025-11-07 11:30 | End: 2025-11-10 10:30\n",
      "   üîπ IT-21671: 5.0h ‚Üí Due: 2025-10-23 | Finish: Start: 2025-11-10 10:30 | End: 2025-11-11 10:30\n",
      "   üîπ IT-21548: 8.0h ‚Üí Due: 2025-10-24 | Finish: Start: 2025-11-11 10:30 | End: 2025-11-12 13:30\n",
      "   üîπ IT-21393: 5h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-11-13 08:30 | End: 2025-11-13 13:30\n",
      "     üö® Puede derivarse a: Alan Mori - Carestino\n",
      "   üîπ IT-20942: 8.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-11-14 08:30 | End: 2025-11-17 11:30\n",
      "   üîπ IT-20578: 44.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-11-17 11:30 | End: 2025-11-28 10:30\n",
      "   üîπ IT-21672: 8.0h ‚Üí Due: 2025-10-29 | Finish: Start: 2025-11-28 10:30 | End: 2025-12-01 13:30\n",
      "   üîπ IT-22043: 8.0h ‚Üí Due: 2025-10-31 | Finish: Start: 2025-12-02 08:30 | End: 2025-12-03 11:30\n",
      "   üîπ IT-21962: 3.0h ‚Üí Due: 2025-11-06 | Finish: Start: 2025-12-03 11:30 | End: 2025-12-04 09:30\n",
      "   üîπ IT-11523: 8.0h ‚Üí Due: 2026-02-20 | Finish: Start: 2025-12-04 09:30 | End: 2025-12-05 12:30\n",
      "   üîπ IT-20577: 64.0h ‚Üí Due: 2026-02-20 | Finish: Start: 2025-12-05 12:30 | End: 2025-12-24 11:30\n",
      "     üìõ Debido a bloqueo de: IT-20576: Expense / Reemplazo Sofia / Solicitudes de modificaci√≥n de Otros proveedores (Miguel Armentano, Due: 2026-02-19)\n",
      "   üîπ IT-11789: 2.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-12-24 11:30 | End: 2025-12-24 13:30\n",
      "\n",
      "üë®‚Äçüíª Developer: Alan Mori - Carestino\n",
      "   üîπ IT-21933: 21.0h ‚Üí Due: 2025-09-25 | Finish: Start: 2025-10-27 09:00 | End: 2025-10-30 13:35\n",
      "   üîπ IT-21985: 4.0h ‚Üí Due: 2025-10-14 | Finish: Start: 2025-10-30 13:35 | End: 2025-10-31 12:05\n",
      "     üö® Puede derivarse a: Gast√≥n Ojeda\n",
      "   üîπ IT-20819: 8.0h ‚Üí Due: 2025-10-17 | Finish: Start: 2025-10-31 12:05 | End: 2025-11-03 14:35\n",
      "   üîπ IT-21786: 1.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-11-04 09:00 | End: 2025-11-04 10:00\n",
      "     üïì Fecha de vencimiento ajustada por bloqueo a tarjeta ['IT-21781'] que vence el: 2025-11-19\n",
      "     üïì Fecha de vencimiento ajustada por bloqueo a tarjeta ['IT-21781'] que vence el: 2025-11-19\n",
      "   üîπ IT-20630: 12.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-11-04 10:00 | End: 2025-11-06 11:05\n",
      "   üîπ IT-20655: 32.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-11-06 11:05 | End: 2025-11-14 09:30\n",
      "   üîπ IT-21571: 8.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-11-14 09:30 | End: 2025-11-17 12:00\n",
      "   üîπ IT-21935: 12.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-11-17 12:00 | End: 2025-11-19 13:00\n",
      "   üîπ IT-21983: 1.0h ‚Üí Due: 2025-11-06 | Finish: Start: 2025-11-19 13:00 | End: 2025-11-19 14:00\n",
      "   üîπ IT-22045: 2.0h ‚Üí Due: 2025-11-20 | Finish: Start: 2025-11-20 08:30 | End: 2025-11-20 10:30\n",
      "   üîπ IT-21847: 24.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2025-11-20 10:30 | End: 2025-11-26 12:30\n",
      "   üîπ IT-21391: 16.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2025-11-26 12:30 | End: 2025-12-01 12:00\n",
      "   üîπ IT-21765: 8.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2025-12-01 12:00 | End: 2025-12-03 09:00\n",
      "   üîπ IT-21342: 16.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2025-12-03 09:00 | End: 2025-12-05 14:00\n",
      "   üîπ IT-21452: 16.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2025-12-08 08:30 | End: 2025-12-10 13:30\n",
      "   üîπ IT-20531: 24.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2025-12-10 13:30 | End: 2025-12-17 10:00\n",
      "   üîπ IT-21778: 24.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2025-12-17 10:00 | End: 2025-12-23 12:00\n",
      "   üîπ IT-21197: 8.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2025-12-23 12:00 | End: 2025-12-25 09:00\n",
      "   üîπ IT-21510: 8.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2025-12-25 09:00 | End: 2025-12-26 11:30\n",
      "   üîπ IT-20640: 5.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2025-12-26 11:30 | End: 2025-12-29 11:00\n",
      "   üîπ IT-21987: 6.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2025-12-29 11:00 | End: 2025-12-30 11:30\n",
      "   üîπ IT-21330: 8.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2025-12-30 11:30 | End: 2025-12-31 14:00\n",
      "   üîπ IT-21450: 4.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2026-01-01 08:30 | End: 2026-01-01 12:30\n",
      "   üîπ IT-21326: 2.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2026-01-01 12:30 | End: 2026-01-02 09:00\n",
      "   üîπ IT-20781: 18.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2026-01-02 09:00 | End: 2026-01-07 10:30\n",
      "   üîπ IT-21013: 16.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2026-01-07 10:30 | End: 2026-01-12 10:00\n",
      "   üîπ IT-21734: 8.0h ‚Üí Due: 2026-03-09 | Finish: Start: 2026-01-12 10:00 | End: 2026-01-13 12:30\n",
      "\n",
      "üë®‚Äçüíª Developer: Gast√≥n Ojeda\n",
      "   üîπ IT-21305: 12.0h ‚Üí Due: 2025-05-07 | Finish: Start: 2025-10-27 09:00 | End: 2025-10-29 13:30\n",
      "     üïì Fecha de vencimiento ajustada por bloqueo a tarjeta ['IT-20391'] que vence el: 2025-05-07\n",
      "     üö® Puede derivarse a: Nicolas Pardo\n",
      "     üïì Fecha de vencimiento ajustada por bloqueo a tarjeta ['IT-20391'] que vence el: 2025-05-07\n",
      "   üîπ IT-21844: 2.0h ‚Üí Due: 2025-09-30 | Finish: Start: 2025-10-29 13:30 | End: 2025-10-29 15:30\n",
      "     üö® Puede derivarse a: Franco Lorenzo, Miguel Armentano, Alan Mori - Carestino, Luis Uran\n",
      "   üîπ IT-21443: 3.0h ‚Üí Due: 2025-09-30 | Finish: Start: 2025-10-29 15:30 | End: 2025-10-30 11:00\n",
      "     üö® Puede derivarse a: Alan Mori - Carestino\n",
      "     üìõ Debido a bloqueo de: IT-21880: Proveedores / Nuevo campo Nombre Corto (Gast√≥n Ojeda, Due: 2025-09-29)\n",
      "   üîπ IT-21493: 8.0h ‚Üí Due: 2025-10-03 | Finish: Start: 2025-10-30 11:00 | End: 2025-10-31 15:00\n",
      "     üö® Puede derivarse a: Alan Mori - Carestino\n",
      "   üîπ IT-20382: 6.0h ‚Üí Due: 2025-10-03 | Finish: Start: 2025-11-03 09:00 | End: 2025-11-04 10:00\n",
      "     üö® Puede derivarse a: Nicolas Pardo\n",
      "   üîπ IT-21806: 8.0h ‚Üí Due: 2025-10-14 | Finish: Start: 2025-11-04 10:00 | End: 2025-11-05 15:00\n",
      "     üö® Puede derivarse a: Nicolas Pardo\n",
      "   üîπ IT-21679: 7.0h ‚Üí Due: 2025-10-16 | Finish: Start: 2025-11-05 15:00 | End: 2025-11-07 09:30\n",
      "     üö® Puede derivarse a: Nicolas Pardo\n",
      "   üîπ IT-21320: 4.0h ‚Üí Due: 2025-10-17 | Finish: Start: 2025-11-07 09:30 | End: 2025-11-07 13:30\n",
      "     üö® Puede derivarse a: Franco Lorenzo\n",
      "   üîπ IT-21814: 8.0h ‚Üí Due: 2025-10-24 | Finish: Start: 2025-11-10 08:30 | End: 2025-11-11 11:30\n",
      "     üö® Puede derivarse a: Nicolas Pardo\n",
      "   üîπ IT-15010: 16.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-11-11 11:30 | End: 2025-11-14 12:30\n",
      "     üö® Puede derivarse a: Nicolas Pardo\n",
      "   üîπ IT-21978: 14.0h ‚Üí Due: 2025-10-28 | Finish: Start: 2025-11-14 12:30 | End: 2025-11-19 11:30\n",
      "     üö® Puede derivarse a: Alan Mori - Carestino\n",
      "   üîπ IT-21775: 4.0h ‚Üí Due: 2025-11-07 | Finish: Start: 2025-11-19 11:30 | End: 2025-11-20 10:30\n",
      "     üö® Puede derivarse a: Nicolas Pardo\n",
      "   üîπ IT-21625: 10.0h ‚Üí Due: 2025-11-11 | Finish: Start: 2025-11-20 10:30 | End: 2025-11-24 10:30\n",
      "     üö® Puede derivarse a: Alan Mori - Carestino\n",
      "   üîπ IT-21376: 10.0h ‚Üí Due: 2025-11-21 | Finish: Start: 2025-11-24 10:30 | End: 2025-11-26 10:30\n",
      "   üîπ IT-20473: 3.0h ‚Üí Due: 2025-11-21 | Finish: Start: 2025-11-26 10:30 | End: 2025-11-26 13:30\n",
      "     üö® Puede derivarse a: Alan Mori - Carestino, Luis Uran, Miguel Armentano, Nicolas Pardo\n",
      "   üîπ IT-20386: 8.0h ‚Üí Due: 2025-11-28 | Finish: Start: 2025-11-27 08:30 | End: 2025-11-28 11:30\n",
      "   üîπ IT-21981: 10.0h ‚Üí Due: 2025-11-28 | Finish: Start: 2025-11-28 11:30 | End: 2025-12-02 11:30\n",
      "     üö® Puede derivarse a: Nicolas Pardo\n",
      "   üîπ IT-14961: 16.0h ‚Üí Due: 2025-11-30 | Finish: Start: 2025-12-02 11:30 | End: 2025-12-05 12:30\n",
      "   üîπ IT-20379: 6.0h ‚Üí Due: 2025-12-05 | Finish: Start: 2025-12-05 12:30 | End: 2025-12-08 13:30\n",
      "     üö® Puede derivarse a: Miguel Armentano\n",
      "   üîπ IT-15936: 4.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-12-09 08:30 | End: 2025-12-09 12:30\n",
      "   üîπ IT-15927: 5.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-12-09 12:30 | End: 2025-12-10 12:30\n",
      "   üîπ IT-21993: 4.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-12-10 12:30 | End: 2025-12-11 11:30\n",
      "     üö® Puede derivarse a: Alan Mori - Carestino, Luis Uran, Miguel Armentano, Nicolas Pardo\n",
      "   üîπ IT-15941: 6.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-12-11 11:30 | End: 2025-12-12 12:30\n",
      "   üîπ IT-15922: 16.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-12-12 12:30 | End: 2025-12-17 13:30\n",
      "   üîπ IT-15935: 8.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-12-18 08:30 | End: 2025-12-19 11:30\n",
      "   üîπ IT-15932: 5.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-12-19 11:30 | End: 2025-12-22 11:30\n",
      "   üîπ IT-15929: 5.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-12-22 11:30 | End: 2025-12-23 11:30\n",
      "   üîπ IT-15931: 1.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-12-23 11:30 | End: 2025-12-23 12:30\n",
      "\n",
      "üë®‚Äçüíª Developer: Franco Lorenzo\n",
      "   üîπ IT-21887: 8.0h ‚Üí Due: 2025-10-01 | Finish: Start: 2025-10-27 09:00 | End: 2025-10-28 12:40\n",
      "   üîπ IT-21937: 6.0h ‚Üí Due: 2025-10-09 | Finish: Start: 2025-10-28 12:40 | End: 2025-10-29 15:20\n",
      "   üîπ IT-22119: 2.0h ‚Üí Due: 2025-10-24 | Finish: Start: 2025-10-29 15:20 | End: 2025-10-30 10:40\n",
      "   üîπ IT-20114: 34.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-10-30 10:40 | End: 2025-11-10 08:30\n",
      "     üö® Puede derivarse a: Nicolas Pardo, Gast√≥n Ojeda\n",
      "   üîπ IT-21989: 2.0h ‚Üí Due: 2025-11-15 | Finish: Start: 2025-11-10 08:30 | End: 2025-11-10 10:30\n",
      "     üö® Puede derivarse a: Alan Mori - Carestino, Gast√≥n Ojeda\n",
      "   üîπ IT-21781: 4.0h ‚Üí Due: 2025-11-20 | Finish: Start: 2025-11-10 10:30 | End: 2025-11-11 09:30\n",
      "     üö® Puede derivarse a: Alan Mori - Carestino\n",
      "     üìõ Debido a bloqueo de: IT-21786: Worpik / Backend / Mejorar doble scroll por el iframe (Alan Mori - Carestino, Due: 2025-10-27)\n",
      "   üîπ IT-20428: 6.0h ‚Üí Due: 2025-12-26 | Finish: Start: 2025-11-11 09:30 | End: 2025-11-12 10:30\n",
      "   üîπ IT-20697: 20.0h ‚Üí Due: 2025-12-26 | Finish: Start: 2025-11-12 10:30 | End: 2025-11-18 10:30\n",
      "   üîπ IT-20880: 24.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-18 10:30 | End: 2025-11-25 09:30\n",
      "\n",
      "üë®‚Äçüíª Developer: Facundo Capua\n",
      "   üîπ IT-21276: 3.0h ‚Üí Due: 2025-10-01 | Finish: Start: 2025-10-27 08:30 | End: 2025-10-27 11:30\n",
      "   üîπ IT-20032: 4.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-10-27 11:30 | End: 2025-10-27 15:30\n",
      "   üîπ IT-20033: 2.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-10-27 15:30 | End: 2025-10-28 09:30\n",
      "   üîπ IT-20031: 4.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-10-28 09:30 | End: 2025-10-28 13:30\n",
      "   üîπ IT-20022: 4.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-10-28 13:30 | End: 2025-10-29 09:30\n",
      "   üîπ IT-20026: 4.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-10-29 09:30 | End: 2025-10-29 13:30\n",
      "   üîπ IT-17544: 40.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-10-29 13:30 | End: 2025-11-05 13:30\n",
      "   üîπ IT-20023: 3.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-05 13:30 | End: 2025-11-05 16:30\n",
      "   üîπ IT-17531: 24h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-06 08:30 | End: 2025-11-10 16:30\n",
      "   üîπ IT-17538: 12.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-11 08:30 | End: 2025-11-12 12:30\n",
      "   üîπ IT-20028: 3.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-12 12:30 | End: 2025-11-12 15:30\n",
      "     üö® Puede derivarse a: Nicolas Pardo, Gast√≥n Ojeda\n",
      "   üîπ IT-20016: 8.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-12 15:30 | End: 2025-11-13 15:30\n",
      "   üîπ IT-20025: 4.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-13 15:30 | End: 2025-11-14 11:30\n",
      "   üîπ IT-20018: 8.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-14 11:30 | End: 2025-11-17 11:30\n",
      "   üîπ IT-20027: 3.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-17 11:30 | End: 2025-11-17 14:30\n",
      "   üîπ IT-20024: 3.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-17 14:30 | End: 2025-11-18 09:30\n",
      "   üîπ IT-20020: 3.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-18 09:30 | End: 2025-11-18 12:30\n",
      "   üîπ IT-20017: 2.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-18 12:30 | End: 2025-11-18 14:30\n",
      "   üîπ IT-20029: 5.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-18 14:30 | End: 2025-11-19 11:30\n",
      "   üîπ IT-20015: 3.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-19 11:30 | End: 2025-11-19 14:30\n",
      "   üîπ IT-20010: 2.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-19 14:30 | End: 2025-11-19 16:30\n",
      "   üîπ IT-20019: 3.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-20 08:30 | End: 2025-11-20 11:30\n",
      "   üîπ IT-20011: 2.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-20 11:30 | End: 2025-11-20 13:30\n",
      "   üîπ IT-17529: 12.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-20 13:30 | End: 2025-11-24 09:30\n",
      "   üîπ IT-20021: 2.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-24 09:30 | End: 2025-11-24 11:30\n",
      "   üîπ IT-20030: 2.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-24 11:30 | End: 2025-11-24 13:30\n",
      "\n",
      "üë®‚Äçüíª Developer: Nicolas Pardo\n",
      "   üîπ IT-21773: 4.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-10-27 10:00 | End: 2025-10-27 15:30\n",
      "     üö® Puede derivarse a: Gast√≥n Ojeda\n",
      "   üîπ IT-21860: 16.0h ‚Üí Due: 2025-10-28 | Finish: Start: 2025-10-27 15:30 | End: 2025-10-30 11:30\n",
      "     üö® Puede derivarse a: Luis Uran, Miguel Armentano\n",
      "   üîπ IT-21840: 4.0h ‚Üí Due: 2025-11-01 | Finish: Start: 2025-10-30 11:30 | End: 2025-10-30 15:30\n",
      "   üîπ IT-22041: 70.0h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-10-30 15:30 | End: 2025-11-13 10:00\n",
      "\n",
      "üë®‚Äçüíª Developer: Luis Uran\n",
      "   üîπ IT-21969: 5.0h ‚Üí Due: 2025-03-06 | Finish: Start: 2025-10-27 09:00 | End: 2025-10-27 14:00\n",
      "     üïì Fecha de vencimiento ajustada por bloqueo a tarjeta ['IT-21303'] que vence el: 2025-03-06\n",
      "     üö® Puede derivarse a: Nicolas Pardo, Gast√≥n Ojeda\n",
      "     üïì Fecha de vencimiento ajustada por bloqueo a tarjeta ['IT-21303'] que vence el: 2025-03-06\n",
      "   üîπ IT-21303: 4.0h ‚Üí Due: 2025-03-07 | Finish: Start: 2025-10-27 14:00 | End: 2025-10-28 12:00\n",
      "     üïì Fecha de vencimiento ya correcta por bloqueo a tarjeta ['IT-21882'] que vence el: 2025-11-12\n",
      "     üö® Puede derivarse a: Nicolas Pardo, Gast√≥n Ojeda\n",
      "     üìõ Debido a bloqueo de: IT-21969: Listado de ventas / Asociar comportamiento de impresi√≥n de etiquetas con filtro por Log√≠stica MercadoEnvios (Luis Uran, Due: 2025-03-06) | SD-7717\n",
      "     üïì Fecha de vencimiento ya correcta por bloqueo a tarjeta ['IT-21882'] que vence el: 2025-11-12\n",
      "   üîπ IT-22133: 8.0h ‚Üí Due: 2025-10-24 | Finish: Start: 2025-10-28 12:00 | End: 2025-10-29 14:30\n",
      "     üö® Puede derivarse a: Nicolas Pardo, Gast√≥n Ojeda\n",
      "   üîπ IT-16643: 2.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-10-29 14:30 | End: 2025-10-30 10:00\n",
      "   üîπ IT-16644: 2.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-10-30 10:00 | End: 2025-10-30 12:00\n",
      "   üîπ IT-16642: 4.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-10-30 12:00 | End: 2025-10-31 10:00\n",
      "   üîπ IT-16640: 4.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-10-31 10:00 | End: 2025-10-31 14:00\n",
      "   üîπ IT-21873: 5.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-10-31 14:00 | End: 2025-11-03 13:00\n",
      "     üö® Puede derivarse a: Miguel Armentano\n",
      "   üîπ IT-16641: 3.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-11-03 13:00 | End: 2025-11-04 10:00\n",
      "   üîπ IT-16638: 7.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-11-04 10:00 | End: 2025-11-05 11:00\n",
      "   üîπ IT-16639: 3.0h ‚Üí Due: 2025-10-27 | Finish: Start: 2025-11-05 11:00 | End: 2025-11-05 14:00\n",
      "   üîπ IT-21973: 4.0h ‚Üí Due: 2025-11-13 | Finish: Start: 2025-11-05 14:00 | End: 2025-11-06 12:00\n",
      "   üîπ IT-21965: 3.0h ‚Üí Due: 2025-11-13 | Finish: Start: 2025-11-06 12:00 | End: 2025-11-06 15:00\n",
      "     üö® Puede derivarse a: Miguel Armentano\n",
      "     üìõ Debido a bloqueo de: IT-21966: Numero de orden Falabella para conciliaci√≥n (OrderNumber) (Nicolas Pardo, Due: 2025-11-12)\n",
      "   üîπ IT-16523: 3.0h ‚Üí Due: 2025-12-31 | Finish: Start: 2025-11-07 08:30 | End: 2025-11-07 11:30\n",
      "   üîπ IT-16635: 3.0h ‚Üí Due: 2025-12-31 | Finish: Start: 2025-11-07 11:30 | End: 2025-11-07 14:30\n",
      "   üîπ IT-16525: 4.0h ‚Üí Due: 2025-12-31 | Finish: Start: 2025-11-10 08:30 | End: 2025-11-10 12:30\n",
      "   üîπ IT-16632: 3.0h ‚Üí Due: 2025-12-31 | Finish: Start: 2025-11-10 12:30 | End: 2025-11-11 09:30\n",
      "   üîπ IT-16634: 6.0h ‚Üí Due: 2025-12-31 | Finish: Start: 2025-11-11 09:30 | End: 2025-11-12 09:30\n",
      "   üîπ IT-16633: 5.0h ‚Üí Due: 2025-12-31 | Finish: Start: 2025-11-12 09:30 | End: 2025-11-12 14:30\n",
      "   üîπ IT-16521: 4.0h ‚Üí Due: 2025-12-31 | Finish: Start: 2025-11-13 08:30 | End: 2025-11-13 12:30\n",
      "   üîπ IT-16524: 2.0h ‚Üí Due: 2025-12-31 | Finish: Start: 2025-11-13 12:30 | End: 2025-11-13 14:30\n",
      "   üîπ IT-22138: 6h ‚Üí Due: 2100-01-01 | Finish: Start: 2025-11-14 08:30 | End: 2025-11-14 14:30\n",
      "\n",
      "üë®‚Äçüíª Developer: Diego Martin Gogorza\n",
      "   üîπ IT-21083: 6.0h ‚Üí Due: 2025-09-05 | Finish: Start: 2025-10-27 09:00 | End: 2025-10-27 16:00\n",
      "     üö® Puede derivarse a: Gast√≥n Ojeda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# === LOAD DATA ===\n",
    "with open(\"jira_it_issues.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    issues = json.load(f)[\"issues\"]\n",
    "\n",
    "with open(\"epics_due_lookup.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    epic_due_lookup = json.load(f)\n",
    "\n",
    "scheduled = []\n",
    "tasks_by_dev = {}\n",
    "issue_map = {}\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "def _opt_value(v):\n",
    "    \"\"\"Si es opci√≥n (dict), devuelve .value/.name; si es lista, lista de values; otro -> tal cual.\"\"\"\n",
    "    if isinstance(v, dict):\n",
    "        return v.get(\"value\") or v.get(\"name\")\n",
    "    if isinstance(v, list):\n",
    "        out = []\n",
    "        for x in v:\n",
    "            out.append(x.get(\"value\") or x.get(\"name\") if isinstance(x, dict) else x)\n",
    "        return out\n",
    "    return v\n",
    "\n",
    "def get_cf10209_from_sd_outward(f_fields, only_link_type=None):\n",
    "    \"\"\"\n",
    "    Busca en f_fields['issuelinks'] un outwardIssue cuya key empiece con 'SD-'\n",
    "    y devuelve customfield_10209 (normalizado). Si only_link_type se setea,\n",
    "    filtra por el nombre del tipo de v√≠nculo (p.ej. 'Problem/Incident').\n",
    "    \"\"\"\n",
    "    links = f_fields.get(\"issuelinks\") or []\n",
    "    for link in links:\n",
    "        if only_link_type and link.get(\"type\", {}).get(\"name\") != only_link_type:\n",
    "            continue\n",
    "        out = link.get(\"outwardIssue\")\n",
    "        if not out:\n",
    "            continue\n",
    "        if not str(out.get(\"key\", \"\")).startswith(\"SD-\"):\n",
    "            continue\n",
    "        lfields = (out.get(\"fields\") or {})\n",
    "        val = _opt_value(lfields.get(\"customfield_10209\"))\n",
    "        if val:\n",
    "            return val\n",
    "    return None\n",
    "\n",
    "def get_epic_key(fields):\n",
    "    \"\"\"\n",
    "    Devuelve la key de la √©pica asociada al issue (si existe), probando:\n",
    "    1) customfield_10008 (Epic Link) ‚Äì cl√°sico\n",
    "    2) parent.key si el parent es de tipo 'Epic' ‚Äì team-managed\n",
    "    3) fields['epic'] (algunas instancias Cloud)\n",
    "    \"\"\"\n",
    "    # 1) Epic Link cl√°sico\n",
    "    epic_link = fields.get(\"customfield_10008\")\n",
    "    if isinstance(epic_link, str) and epic_link:\n",
    "        return epic_link\n",
    "\n",
    "    # 2) parent -> Epic\n",
    "    p = fields.get(\"parent\")\n",
    "    if isinstance(p, dict):\n",
    "        p_issuetype = (p.get(\"fields\") or {}).get(\"issuetype\") or p.get(\"issuetype\") or {}\n",
    "        if str(p_issuetype.get(\"name\", \"\")).lower() == \"epic\":\n",
    "            return p.get(\"key\")\n",
    "\n",
    "    # 3) objeto 'epic'\n",
    "    e = fields.get(\"epic\")\n",
    "    if isinstance(e, dict):\n",
    "        return e.get(\"key\") or e.get(\"id\")\n",
    "\n",
    "    return None\n",
    "\n",
    "def contar_dias_laborables(start_date, end_date):\n",
    "    dias = 0\n",
    "    current = start_date\n",
    "    while current <= end_date:\n",
    "        if current.weekday() < 5:  # Lunes a Viernes\n",
    "            dias += 1\n",
    "        current += timedelta(days=1)\n",
    "    return dias\n",
    "\n",
    "for issue in issues:\n",
    "    f = issue[\"fields\"]\n",
    "    status = f.get(\"status\", {}).get(\"name\", \"\")\n",
    "    assignee = f.get(\"assignee\")\n",
    "    if not assignee:\n",
    "        continue\n",
    "    dev = assignee[\"displayName\"]\n",
    "    report = f.get(\"reporter\")\n",
    "    if not report:\n",
    "        continue\n",
    "    reporter = report[\"displayName\"]\n",
    "    key = issue[\"key\"]\n",
    "    summary = f.get(\"summary\", \"\")\n",
    "    module_info = f.get(\"customfield_10212\")\n",
    "    module_value = module_info[\"value\"] if module_info else None\n",
    "    estimate_hours = f.get(\"customfield_10608\")\n",
    "\n",
    "    if estimate_hours is None:\n",
    "        estimate_hours = f.get(\"customfield_10016\")\n",
    "\n",
    "    if estimate_hours is None:\n",
    "        estimate_seconds = f.get(\"timetracking\", {}).get(\"originalEstimateSeconds\") or f.get(\"aggregatetimeoriginalestimate\")\n",
    "        estimate_hours = estimate_seconds / 3600 if estimate_seconds else 0\n",
    "    \n",
    "    issue_to_epic = {}\n",
    "    for ekey, edata in epic_due_lookup.items():\n",
    "        for t in edata.get(\"tasks\", []):\n",
    "            k = t.get(\"key\")\n",
    "            if k:\n",
    "                issue_to_epic[k] = ekey\n",
    "    \n",
    "    epic_key = get_epic_key(f) or issue_to_epic.get(key)  # üëà fallback desde lookup\n",
    "    epic_obj = epic_due_lookup.get(epic_key) if epic_key else None\n",
    "    epic_due_str = (epic_obj or {}).get(\"due_date\")\n",
    "\n",
    "    # Prefiere due del issue; si no hay, usa el de la √©pica\n",
    "    due_str = f.get(\"duedate\") or epic_due_str\n",
    "    try:\n",
    "        due_date = datetime.strptime(due_str, \"%Y-%m-%d\") if due_str else datetime(2100, 1, 1)\n",
    "    except:\n",
    "        due_date = datetime(2100, 1, 1)\n",
    "\n",
    "    epic_name = (epic_obj or {}).get(\"summary\", \"‚Äî Sin √©pica ‚Äî\")\n",
    "\n",
    "    cf10442_raw = f.get(\"customfield_10442\") or []\n",
    "    cf10442_names = [u.get(\"displayName\") for u in cf10442_raw if u.get(\"displayName\")]\n",
    "    suggested_devs = MODULE_DEVS.get(module_value, []) if module_value else []\n",
    "    suggested_users = list(set(suggested_devs + cf10442_names))\n",
    "\n",
    "    if dev in suggested_users:\n",
    "        suggested_users.remove(dev)\n",
    "\n",
    "    can_be_delegated = dev not in suggested_users and bool(suggested_users)\n",
    "    delegation_note = f\"üö® Puede derivarse a: {', '.join(suggested_users)}\" if can_be_delegated else \"\"\n",
    "\n",
    "\n",
    "\n",
    "    cf10209_value = get_cf10209_from_sd_outward(\n",
    "        f_fields=f,\n",
    "        only_link_type=\"Problem/Incident\"  # o None si no quer√©s filtrar por tipo\n",
    "    )\n",
    "    \n",
    "    task = {\n",
    "        \"key\": key,\n",
    "        \"summary\": summary,\n",
    "        \"estimate_hours\": estimate_hours,\n",
    "        \"due_date\": due_date,\n",
    "        \"assignee\": dev,\n",
    "        \"status\": status,\n",
    "        \"due_reason\": None,\n",
    "        \"module\": module_value,\n",
    "        \"suggested_users\": suggested_users,\n",
    "        \"has_epic\": bool(epic_key),\n",
    "        \"epic_name\": epic_name, \n",
    "        \"reporter\": reporter,\n",
    "        \"cf10209\": cf10209_value\n",
    "    }\n",
    "    # üîß Nuevo: guardar claves de tareas que bloquean esta\n",
    "    \n",
    "    issue_map[key] = task\n",
    "\n",
    "    \n",
    "    if status in VALID_STATUSES:\n",
    "        tasks_by_dev.setdefault(dev, []).append(task)\n",
    "    graph.add_node(key)\n",
    "    \n",
    "\n",
    "    # for key, task in issue_map.items():\n",
    "    #     blocker_due_dates = [\n",
    "    #         issue_map[b][\"due_date\"]\n",
    "    #         for b in graph.predecessors(key)\n",
    "    #         if b in issue_map and issue_map[b][\"due_date\"]\n",
    "    #     ]\n",
    "\n",
    "    #     if blocker_due_dates:\n",
    "    #         max_blocker_due = min(blocker_due_dates)\n",
    "    #         if task[\"due_date\"] < max_blocker_due:\n",
    "    #             task[\"due_date_original\"] = task[\"due_date\"]\n",
    "    #             task[\"due_date\"] = max_blocker_due\n",
    "\n",
    "    for link in f.get(\"issuelinks\", []):\n",
    "        if \"inwardIssue\" in link and link[\"type\"][\"name\"] == \"Blocks\":\n",
    "            graph.add_edge(link[\"inwardIssue\"][\"key\"], key)\n",
    "        elif \"outwardIssue\" in link and link[\"type\"][\"name\"] == \"Blocks\":\n",
    "            graph.add_edge(key, link[\"outwardIssue\"][\"key\"])\n",
    "\n",
    "    blockers = [src for src, tgt in graph.edges() if tgt == key]\n",
    "    task[\"blockers\"] = blockers\n",
    "\n",
    "for key, task in issue_map.items():\n",
    "    # Para cada tarea, mirar a qui√©n bloquea\n",
    "    blocked_keys = list(graph.successors(key))\n",
    "    \n",
    "    blocked_due_dates = [\n",
    "        issue_map[b][\"due_date\"]\n",
    "        for b in blocked_keys\n",
    "        if b in issue_map and issue_map[b][\"due_date\"]\n",
    "    ]\n",
    "\n",
    "    blocker_key = [issue_map[b][\"key\"] for b in blocked_keys if b in issue_map and issue_map[b][\"key\"]]\n",
    "\n",
    "    if blocked_due_dates:\n",
    "        min_blocked_due = min(blocked_due_dates)\n",
    "        suggested_due = min_blocked_due - timedelta(days=1)\n",
    "        task[\"note\"] = (\n",
    "            f\"üïì Fecha de vencimiento {'ajustada' if task['due_date'] > suggested_due else 'ya correcta'} \"\n",
    "            f\"por bloqueo a tarjeta {blocker_key} que vence el: {suggested_due.strftime('%Y-%m-%d')}\"\n",
    "        )\n",
    "        if task[\"due_date\"] > suggested_due:\n",
    "            task[\"due_date_original\"] = task[\"due_date\"]\n",
    "            task[\"due_date\"] = suggested_due\n",
    "            task[\"note\"] = f\"üïì Fecha de vencimiento ajustada por bloqueo a tarjeta {blocker_key} que vence el: {suggested_due.strftime('%Y-%m-%d')}\"\n",
    "\n",
    "\n",
    "# BLOQUES POR DEV (simulados)\n",
    "bloques_por_dev = bloques\n",
    "MINIMUM_SLOT_HOURS = 0.25\n",
    "# === PLANIFICADOR POR DESARROLLADOR ===\n",
    "def to_naive(dt):\n",
    "    return dt.replace(tzinfo=None) if dt.tzinfo else dt\n",
    "\n",
    "def planificar_tareas_para_dev(dev, tasks, bloques_ocupados):\n",
    "    current_time = datetime.combine(DEFAULT_START_DATE.date(), datetime.strptime(\"08:30\", \"%H:%M\").time())\n",
    "    hours_per_day = DAILY_HOURS.get(dev, DAILY_HOURS[\"Default\"])\n",
    "    schedule = {}\n",
    "    plan = []\n",
    "\n",
    "    try:\n",
    "        sorted_keys = list(nx.topological_sort(graph.subgraph([t[\"key\"] for t in tasks])))\n",
    "    except nx.NetworkXUnfeasible:\n",
    "        sorted_keys = [t[\"key\"] for t in tasks]\n",
    "    sorted_keys.sort(key=lambda k: issue_map[k][\"due_date\"])\n",
    "\n",
    "    def to_naive(dt):\n",
    "        return dt.replace(tzinfo=None) if dt.tzinfo else dt\n",
    "    \n",
    "    for start, end in sorted(bloques_ocupados):\n",
    "            plan.append({\n",
    "                \"developer\": dev,\n",
    "                \"key\": f\"REUNION-{start.strftime('%Y%m%d%H%M')}\",\n",
    "                \"summary\": \"‚õî Reuni√≥n\",\n",
    "                \"has_epic\": False,\n",
    "                \"due_date\": start.date(),  # o end.date()\n",
    "                \"start\": to_naive(start),\n",
    "                \"end\": to_naive(end),\n",
    "                \"duration_hours\": (to_naive(end) - to_naive(start)).total_seconds() / 3600,\n",
    "                \"type\": \"reunion\"\n",
    "            })\n",
    "\n",
    "    for key in sorted_keys:\n",
    "        task = issue_map[key]\n",
    "        hours_left = task[\"estimate_hours\"]\n",
    "        start_time = None\n",
    "       \n",
    "\n",
    "        \n",
    "\n",
    "        while hours_left > 0:\n",
    "            date_str = current_time.strftime('%Y-%m-%d')\n",
    "            used_today = schedule.get(date_str, 0)\n",
    "\n",
    "            end_of_day = datetime.combine(current_time.date(), datetime.strptime(\"17:30\", \"%H:%M\").time())\n",
    "            available_time = (end_of_day - current_time).total_seconds() / 3600\n",
    "            time_slot = min(available_time, hours_per_day - used_today, hours_left)\n",
    "\n",
    "             # üîß NUEVO BLOQUE: limitar time_slot al hueco libre real antes del pr√≥ximo conflicto\n",
    "            next_conflict_start = None\n",
    "            for start, end in sorted(bloques_ocupados):\n",
    "                if to_naive(start) > to_naive(current_time):\n",
    "                    next_conflict_start = to_naive(start)\n",
    "                    break\n",
    "\n",
    "            if next_conflict_start:\n",
    "                gap_hours = (next_conflict_start - current_time).total_seconds() / 3600\n",
    "                if gap_hours > 0:\n",
    "                    time_slot = min(time_slot, gap_hours)\n",
    "\n",
    "            if time_slot <= 0:\n",
    "                next_day = current_time.date() + timedelta(days=1)\n",
    "                while next_day.weekday() in [5, 6]:\n",
    "                    next_day += timedelta(days=1)\n",
    "                current_time = datetime.combine(next_day, datetime.strptime(\"08:30\", \"%H:%M\").time())\n",
    "                continue\n",
    "\n",
    "            proposed_end = current_time + timedelta(hours=time_slot)\n",
    "\n",
    "            bloque_conflictivo = any(\n",
    "                to_naive(start) < to_naive(proposed_end) and to_naive(end) > to_naive(current_time)\n",
    "                for start, end in bloques_ocupados\n",
    "            )\n",
    "\n",
    "            if bloque_conflictivo:\n",
    "                conflictos = [\n",
    "                    (start, end) for start, end in bloques_ocupados\n",
    "                    if to_naive(start) < to_naive(proposed_end) and to_naive(end) > to_naive(current_time)\n",
    "                ]\n",
    "                conflictos.sort(key=lambda x: to_naive(x[0]))\n",
    "                next_start = to_naive(conflictos[0][1])\n",
    "                current_time = next_start\n",
    "                continue\n",
    "\n",
    "            if start_time is None:\n",
    "                start_time = current_time\n",
    "\n",
    "            if bloque_conflictivo:\n",
    "                conflictos = [\n",
    "                    (start, end) for start, end in bloques_ocupados\n",
    "                    if to_naive(start) < to_naive(proposed_end) and to_naive(end) > to_naive(current_time)\n",
    "                ]\n",
    "                conflictos.sort(key=lambda x: to_naive(x[0]))\n",
    "                next_start = to_naive(conflictos[0][1])\n",
    "                current_time = next_start\n",
    "                continue\n",
    "\n",
    "            if start_time is None:\n",
    "                start_time = current_time\n",
    "\n",
    "            end_time = current_time + timedelta(hours=time_slot)\n",
    "            plan.append({\n",
    "                \"developer\": dev,\n",
    "                \"key\": key,\n",
    "                \"summary\": task[\"summary\"],\n",
    "                \"has_epic\": task[\"has_epic\"],\n",
    "                \"epic_name\": task[\"epic_name\"],\n",
    "                \"due_date\": task[\"due_date\"],\n",
    "                \"start\": current_time,\n",
    "                \"end\": end_time,\n",
    "                \"duration_hours\": time_slot,\n",
    "                \"suggested_users\": task.get(\"suggested_users\", []),\n",
    "                \"blockers\": task.get(\"blockers\", []),\n",
    "                \"note\": task.get(\"note\", \"\"),\n",
    "                \"reporter\": task.get(\"reporter\", \"\"),\n",
    "                \"cf10209\": task.get(\"cf10209\")\n",
    "            })\n",
    "            \n",
    "\n",
    "            schedule[date_str] = used_today + time_slot\n",
    "            hours_left -= time_slot\n",
    "            current_time = end_time\n",
    "\n",
    "    return plan\n",
    "\n",
    "# === PLANIFICACI√ìN INICIAL ===\n",
    "# for dev in tasks_by_dev:\n",
    "#     scheduled += planificar_tareas_para_dev(dev, tasks_by_dev[dev], bloques_por_dev[dev])\n",
    "\n",
    "# === REBALANCEO ===\n",
    "planned_hours_by_dev = defaultdict(float)\n",
    "project_hours_by_dev = defaultdict(float)\n",
    "\n",
    "for s in scheduled:\n",
    "    if s.get(\"type\") == \"reunion\":\n",
    "        continue\n",
    "    planned_hours_by_dev[s[\"developer\"]] += s[\"duration_hours\"]\n",
    "    if issue_map[s[\"key\"]][\"has_epic\"]:\n",
    "        project_hours_by_dev[s[\"developer\"]] += s[\"duration_hours\"]\n",
    "\n",
    "for dev in tasks_by_dev:\n",
    "    all_tasks = tasks_by_dev[dev]\n",
    "    \n",
    "    within_range = [t for t in all_tasks if DEFAULT_START_DATE <= t[\"due_date\"] <= DEFAULT_END_DATE]\n",
    "    epic_tasks_in_range = sorted([t for t in within_range if t[\"has_epic\"]], key=lambda t: t[\"due_date\"])\n",
    "    non_epic_tasks_in_range = sorted([t for t in within_range if not t[\"has_epic\"]], key=lambda t: t[\"due_date\"], reverse=True)\n",
    "    epic_tasks_out_of_range = sorted(\n",
    "        [t for t in all_tasks if t[\"has_epic\"] and t not in within_range],\n",
    "        key=lambda t: t[\"due_date\"]\n",
    "    )\n",
    "\n",
    "    total_in_range = sum(t[\"estimate_hours\"] for t in within_range)\n",
    "    current_epic = sum(t[\"estimate_hours\"] for t in epic_tasks_in_range)\n",
    "    non_epic_hours = sum(t[\"estimate_hours\"] for t in non_epic_tasks_in_range)\n",
    "    min_ratio = MIN_PROJECT_RATIO.get(dev, MIN_PROJECT_RATIO[\"Default\"])\n",
    "\n",
    "    print(f\"\\nüîé {dev}:\")\n",
    "    print(f\"  üéØ Epic target: {min_ratio * 100:.1f}%\")\n",
    "    print(f\"  üìä Total in range: {total_in_range:.1f} h | Epic in range: {current_epic:.1f} h\")\n",
    "    print(f\"  üîç Epic tasks out of range: {len(epic_tasks_out_of_range)}\")\n",
    "    for t in epic_tasks_out_of_range:\n",
    "        print(f\"    - {t['key']} ({t['estimate_hours']} h) due {t['due_date'].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    # üü® Forzar tareas con √©pica fuera de rango hasta cumplir el m√≠nimo\n",
    "    # horas_planificables_en_rango = (\n",
    "    #         sum(t[\"estimate_hours\"] for t in epic_tasks_in_range) +\n",
    "    #         sum(t[\"estimate_hours\"] for t in non_epic_tasks_in_range) +\n",
    "    #         sum(t[\"estimate_hours\"] for t in epic_tasks_out_of_range)\n",
    "    #     )\n",
    "    \n",
    "    dias_laborables = contar_dias_laborables(DEFAULT_START_DATE, DEFAULT_END_DATE)\n",
    "    horas_por_dia = DAILY_HOURS.get(dev, DAILY_HOURS[\"Default\"])\n",
    "    horas_planificables_en_rango = dias_laborables * horas_por_dia\n",
    "    while epic_tasks_out_of_range:\n",
    "        task = epic_tasks_out_of_range.pop(0)\n",
    "        task_estimate = task[\"estimate_hours\"]\n",
    "\n",
    "        # Moverla dentro del rango\n",
    "        task[\"due_date_original\"] = task[\"due_date\"]\n",
    "        print(f\" modificando {task['key']} due {t['due_date'].strftime('%Y-%m-%d')}\")\n",
    "        task[\"due_date\"] = DEFAULT_START_DATE\n",
    "        epic_tasks_in_range.append(task)\n",
    "        current_epic += task_estimate\n",
    "\n",
    "        # Recalcular ratio despu√©s de agregarla\n",
    "        ratio_actual = current_epic / horas_planificables_en_rango if horas_planificables_en_rango > 0 else 0\n",
    "        print(f\"‚úîÔ∏è Ratio tras forzar {task['key']}: {current_epic:.1f} / ({horas_planificables_en_rango:.1f}) = {ratio_actual * 100:.1f}%\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        if ratio_actual >= min_ratio:\n",
    "            break\n",
    "\n",
    "    # ‚ùå Eliminar tareas sin √©pica si sigue sin cumplirse el m√≠nimo\n",
    "    ratio_actual = current_epic / (current_epic + non_epic_hours) if (current_epic + non_epic_hours) > 0 else 0\n",
    "    while non_epic_tasks_in_range and ratio_actual < min_ratio:\n",
    "        removed = non_epic_tasks_in_range.pop()\n",
    "        non_epic_hours -= removed[\"estimate_hours\"]\n",
    "        ratio_actual = current_epic / (current_epic + non_epic_hours) if (current_epic + non_epic_hours) > 0 else 0\n",
    "\n",
    "    # üîÑ Reordenar: primero √©picas, luego tareas normales\n",
    "    balanced_tasks = sorted(epic_tasks_in_range, key=lambda t: t[\"due_date\"]) + \\\n",
    "                     sorted(non_epic_tasks_in_range, key=lambda t: t[\"due_date\"])\n",
    "    leftovers = [t for t in all_tasks if t not in balanced_tasks]\n",
    "    tasks_by_dev[dev] = balanced_tasks + leftovers\n",
    "\n",
    "    # üîÅ Replanificar solo ese desarrollador\n",
    "    scheduled = [s for s in scheduled if s[\"developer\"] != dev]\n",
    "    scheduled += planificar_tareas_para_dev(dev, tasks_by_dev[dev], bloques_por_dev[dev])\n",
    "\n",
    "\n",
    "# === RESUMEN FINAL ===\n",
    "scheduled_by_dev_and_key = defaultdict(lambda: defaultdict(list))\n",
    "for s in scheduled:\n",
    "    scheduled_by_dev_and_key[s[\"developer\"]][s[\"key\"]].append(s)\n",
    "\n",
    "print(\"\\nüìù Developer Task Schedule Summary:\\n\")\n",
    "for dev, tasks in tasks_by_dev.items():\n",
    "    print(f\"üë®‚Äçüíª Developer: {dev}\")\n",
    "    try:\n",
    "        sorted_keys = list(nx.topological_sort(graph.subgraph([t[\"key\"] for t in tasks])))\n",
    "    except nx.NetworkXUnfeasible:\n",
    "        sorted_keys = [t[\"key\"] for t in tasks]\n",
    "    sorted_keys.sort(key=lambda k: issue_map[k][\"due_date\"])\n",
    "    for key in sorted_keys:\n",
    "        task = issue_map[key]\n",
    "        scheds = sorted(scheduled_by_dev_and_key[dev].get(key, []), key=lambda x: x[\"start\"])\n",
    "        if not scheds:\n",
    "            continue\n",
    "        start_time = scheds[0][\"start\"]\n",
    "        end_time = scheds[-1][\"end\"]\n",
    "        total_hours = sum(s[\"duration_hours\"] for s in scheds)\n",
    "        note_lines = []\n",
    "        if \"note\" in task and task[\"note\"]:\n",
    "            note_lines.append(task[\"note\"])\n",
    "\n",
    "        # üö® Sugerencias de derivaci√≥n\n",
    "        if task.get(\"suggested_users\"):\n",
    "            note_lines.append(f\"üö® Puede derivarse a: {', '.join(task['suggested_users'])}\")\n",
    "\n",
    "        # üìõ Bloqueadores\n",
    "        if task.get(\"blockers\"):\n",
    "            blocker_msgs = []\n",
    "            for blocker_key in task[\"blockers\"]:\n",
    "                blocker = issue_map.get(blocker_key)\n",
    "                if blocker:\n",
    "                    blocker_msgs.append(f\"{blocker_key}: {blocker['summary']} ({blocker['assignee']}, Due: {blocker['due_date'].strftime('%Y-%m-%d')})\")\n",
    "                else:\n",
    "                    blocker_msgs.append(blocker_key)\n",
    "            note_lines.append(f\"üìõ Debido a bloqueo de: \" + \" | \".join(blocker_msgs))\n",
    "\n",
    "         # Agregar nota personalizada si existe\n",
    "        if \"note\" in task and task[\"note\"]:\n",
    "            note_lines.append(task[\"note\"])\n",
    "\n",
    "        note = \"\\n     \" + \"\\n     \".join(note_lines) if note_lines else \"\"\n",
    "        print(\n",
    "            f\"   üîπ {key}: {round(total_hours, 1)}h ‚Üí Due: {task['due_date'].strftime('%Y-%m-%d')} | \"\n",
    "            f\"Finish: Start: {start_time.strftime('%Y-%m-%d %H:%M')} | End: {end_time.strftime('%Y-%m-%d %H:%M')}{note}\"\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfff08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"planificacion.json\", \"w\") as f:\n",
    "    json.dump(scheduled, f, default=str, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d38d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"planificacion.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "light = [\n",
    "    {\n",
    "        \"developer\": d.get(\"developer\"),\n",
    "        \"key\": d.get(\"key\"),\n",
    "        \"summary\": d.get(\"summary\"),\n",
    "        \"start\": d.get(\"start\"),\n",
    "        \"end\": d.get(\"end\"),\n",
    "        \"duration_hours\": d.get(\"duration_hours\"),\n",
    "        \"cf10209\": d.get(\"cf10209\"),\n",
    "    }\n",
    "    for d in data\n",
    "]\n",
    "\n",
    "with open(\"public/planificacion_light.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(light, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
