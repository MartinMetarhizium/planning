{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27158e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import JQL, FIELDS, BASE_URL, JIRA_DOMAIN,EMAIL, MAX_RESULTS, MODULE_DEVS, VALID_STATUSES, MAIL_MAP, DAILY_HOURS,MIN_PROJECT_RATIO,PROJECT_MAP, DEFAULT_END_DATE, DEFAULT_END_DATE_with_timezone, DEFAULT_START_DATE,DEFAULT_START_DATE_with_timezone\n",
    "from token_hidden import API_TOKEN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "942e7ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Fetched 100 issues (startAt=0)\n",
      "🔄 Fetched 100 issues (startAt=100)\n",
      "🔄 Fetched 100 issues (startAt=200)\n",
      "🔄 Fetched 100 issues (startAt=300)\n",
      "🔄 Fetched 100 issues (startAt=400)\n",
      "🔄 Fetched 100 issues (startAt=500)\n",
      "🔄 Fetched 100 issues (startAt=600)\n",
      "🔄 Fetched 100 issues (startAt=700)\n",
      "🔄 Fetched 100 issues (startAt=800)\n",
      "🔄 Fetched 100 issues (startAt=900)\n",
      "🔄 Fetched 100 issues (startAt=1000)\n",
      "🔄 Fetched 100 issues (startAt=1100)\n",
      "🔄 Fetched 100 issues (startAt=1200)\n",
      "🔄 Fetched 100 issues (startAt=1300)\n",
      "🔄 Fetched 100 issues (startAt=1400)\n",
      "🔄 Fetched 100 issues (startAt=1500)\n",
      "🔄 Fetched 100 issues (startAt=1600)\n",
      "🔄 Fetched 100 issues (startAt=1700)\n",
      "🔄 Fetched 100 issues (startAt=1800)\n",
      "🔄 Fetched 100 issues (startAt=1900)\n",
      "🔄 Fetched 100 issues (startAt=2000)\n",
      "🔄 Fetched 100 issues (startAt=2100)\n",
      "🔄 Fetched 100 issues (startAt=2200)\n",
      "🔄 Fetched 100 issues (startAt=2300)\n",
      "🔄 Fetched 100 issues (startAt=2400)\n",
      "🔄 Fetched 100 issues (startAt=2500)\n",
      "🔄 Fetched 100 issues (startAt=2600)\n",
      "🔄 Fetched 100 issues (startAt=2700)\n",
      "🔄 Fetched 100 issues (startAt=2800)\n",
      "🔄 Fetched 100 issues (startAt=2900)\n",
      "🔄 Fetched 100 issues (startAt=3000)\n",
      "🔄 Fetched 100 issues (startAt=3100)\n",
      "🔄 Fetched 100 issues (startAt=3200)\n",
      "🔄 Fetched 100 issues (startAt=3300)\n",
      "🔄 Fetched 100 issues (startAt=3400)\n",
      "🔄 Fetched 100 issues (startAt=3500)\n",
      "🔄 Fetched 100 issues (startAt=3600)\n",
      "🔄 Fetched 100 issues (startAt=3700)\n",
      "🔄 Fetched 100 issues (startAt=3800)\n",
      "🔄 Fetched 100 issues (startAt=3900)\n",
      "🔄 Fetched 100 issues (startAt=4000)\n",
      "🔄 Fetched 100 issues (startAt=4100)\n",
      "🔄 Fetched 100 issues (startAt=4200)\n",
      "🔄 Fetched 100 issues (startAt=4300)\n",
      "🔄 Fetched 100 issues (startAt=4400)\n",
      "🔄 Fetched 100 issues (startAt=4500)\n",
      "🔄 Fetched 100 issues (startAt=4600)\n",
      "🔄 Fetched 100 issues (startAt=4700)\n",
      "🔄 Fetched 100 issues (startAt=4800)\n",
      "🔄 Fetched 100 issues (startAt=4900)\n",
      "🔄 Fetched 100 issues (startAt=5000)\n",
      "🔄 Fetched 100 issues (startAt=5100)\n",
      "🔄 Fetched 100 issues (startAt=5200)\n",
      "🔄 Fetched 100 issues (startAt=5300)\n",
      "🔄 Fetched 100 issues (startAt=5400)\n",
      "🔄 Fetched 100 issues (startAt=5500)\n",
      "🔄 Fetched 100 issues (startAt=5600)\n",
      "🔄 Fetched 100 issues (startAt=5700)\n",
      "🔄 Fetched 100 issues (startAt=5800)\n",
      "🔄 Fetched 100 issues (startAt=5900)\n",
      "🔄 Fetched 100 issues (startAt=6000)\n",
      "🔄 Fetched 100 issues (startAt=6100)\n",
      "🔄 Fetched 100 issues (startAt=6200)\n",
      "🔄 Fetched 100 issues (startAt=6300)\n",
      "🔄 Fetched 100 issues (startAt=6400)\n",
      "🔄 Fetched 100 issues (startAt=6500)\n",
      "🔄 Fetched 100 issues (startAt=6600)\n",
      "🔄 Fetched 100 issues (startAt=6700)\n",
      "🔄 Fetched 100 issues (startAt=6800)\n",
      "🔄 Fetched 100 issues (startAt=6900)\n",
      "🔄 Fetched 100 issues (startAt=7000)\n",
      "🔄 Fetched 100 issues (startAt=7100)\n",
      "🔄 Fetched 100 issues (startAt=7200)\n",
      "🔄 Fetched 100 issues (startAt=7300)\n",
      "🔄 Fetched 100 issues (startAt=7400)\n",
      "🔄 Fetched 100 issues (startAt=7500)\n",
      "🔄 Fetched 100 issues (startAt=7600)\n",
      "🔄 Fetched 100 issues (startAt=7700)\n",
      "🔄 Fetched 100 issues (startAt=7800)\n",
      "🔄 Fetched 100 issues (startAt=7900)\n",
      "🔄 Fetched 100 issues (startAt=8000)\n",
      "🔄 Fetched 100 issues (startAt=8100)\n",
      "🔄 Fetched 100 issues (startAt=8200)\n",
      "🔄 Fetched 100 issues (startAt=8300)\n",
      "🔄 Fetched 100 issues (startAt=8400)\n",
      "🔄 Fetched 100 issues (startAt=8500)\n",
      "🔄 Fetched 100 issues (startAt=8600)\n",
      "🔄 Fetched 59 issues (startAt=8700)\n",
      "✅ Total base issues: 8759\n",
      "🔗 Linked keys found: 5143\n",
      "📦 Enriched batch: 50 (keys 1-50)\n",
      "📦 Enriched batch: 50 (keys 51-100)\n",
      "📦 Enriched batch: 50 (keys 101-150)\n",
      "📦 Enriched batch: 50 (keys 151-200)\n",
      "📦 Enriched batch: 50 (keys 201-250)\n",
      "📦 Enriched batch: 50 (keys 251-300)\n",
      "📦 Enriched batch: 50 (keys 301-350)\n",
      "📦 Enriched batch: 50 (keys 351-400)\n",
      "📦 Enriched batch: 50 (keys 401-450)\n",
      "📦 Enriched batch: 50 (keys 451-500)\n",
      "📦 Enriched batch: 50 (keys 501-550)\n",
      "📦 Enriched batch: 50 (keys 551-600)\n",
      "📦 Enriched batch: 50 (keys 601-650)\n",
      "📦 Enriched batch: 50 (keys 651-700)\n",
      "📦 Enriched batch: 50 (keys 701-750)\n",
      "📦 Enriched batch: 50 (keys 751-800)\n",
      "📦 Enriched batch: 50 (keys 801-850)\n",
      "📦 Enriched batch: 50 (keys 851-900)\n",
      "📦 Enriched batch: 50 (keys 901-950)\n",
      "📦 Enriched batch: 50 (keys 951-1000)\n",
      "📦 Enriched batch: 50 (keys 1001-1050)\n",
      "📦 Enriched batch: 50 (keys 1051-1100)\n",
      "📦 Enriched batch: 50 (keys 1101-1150)\n",
      "📦 Enriched batch: 50 (keys 1151-1200)\n",
      "📦 Enriched batch: 50 (keys 1201-1250)\n",
      "📦 Enriched batch: 50 (keys 1251-1300)\n",
      "📦 Enriched batch: 50 (keys 1301-1350)\n",
      "📦 Enriched batch: 50 (keys 1351-1400)\n",
      "📦 Enriched batch: 50 (keys 1401-1450)\n",
      "📦 Enriched batch: 50 (keys 1451-1500)\n",
      "📦 Enriched batch: 50 (keys 1501-1550)\n",
      "📦 Enriched batch: 50 (keys 1551-1600)\n",
      "📦 Enriched batch: 50 (keys 1601-1650)\n",
      "📦 Enriched batch: 50 (keys 1651-1700)\n",
      "📦 Enriched batch: 50 (keys 1701-1750)\n",
      "📦 Enriched batch: 50 (keys 1751-1800)\n",
      "📦 Enriched batch: 50 (keys 1801-1850)\n",
      "📦 Enriched batch: 50 (keys 1851-1900)\n",
      "📦 Enriched batch: 50 (keys 1901-1950)\n",
      "📦 Enriched batch: 50 (keys 1951-2000)\n",
      "📦 Enriched batch: 50 (keys 2001-2050)\n",
      "📦 Enriched batch: 50 (keys 2051-2100)\n",
      "📦 Enriched batch: 50 (keys 2101-2150)\n",
      "📦 Enriched batch: 50 (keys 2151-2200)\n",
      "📦 Enriched batch: 50 (keys 2201-2250)\n",
      "📦 Enriched batch: 50 (keys 2251-2300)\n",
      "📦 Enriched batch: 50 (keys 2301-2350)\n",
      "📦 Enriched batch: 50 (keys 2351-2400)\n",
      "📦 Enriched batch: 50 (keys 2401-2450)\n",
      "📦 Enriched batch: 50 (keys 2451-2500)\n",
      "📦 Enriched batch: 50 (keys 2501-2550)\n",
      "📦 Enriched batch: 50 (keys 2551-2600)\n",
      "📦 Enriched batch: 50 (keys 2601-2650)\n",
      "📦 Enriched batch: 50 (keys 2651-2700)\n",
      "📦 Enriched batch: 50 (keys 2701-2750)\n",
      "📦 Enriched batch: 50 (keys 2751-2800)\n",
      "📦 Enriched batch: 50 (keys 2801-2850)\n",
      "📦 Enriched batch: 50 (keys 2851-2900)\n",
      "📦 Enriched batch: 50 (keys 2901-2950)\n",
      "📦 Enriched batch: 50 (keys 2951-3000)\n",
      "📦 Enriched batch: 50 (keys 3001-3050)\n",
      "📦 Enriched batch: 50 (keys 3051-3100)\n",
      "📦 Enriched batch: 50 (keys 3101-3150)\n",
      "📦 Enriched batch: 50 (keys 3151-3200)\n",
      "📦 Enriched batch: 50 (keys 3201-3250)\n",
      "📦 Enriched batch: 50 (keys 3251-3300)\n",
      "📦 Enriched batch: 50 (keys 3301-3350)\n",
      "📦 Enriched batch: 50 (keys 3351-3400)\n",
      "📦 Enriched batch: 50 (keys 3401-3450)\n",
      "📦 Enriched batch: 50 (keys 3451-3500)\n",
      "📦 Enriched batch: 50 (keys 3501-3550)\n",
      "📦 Enriched batch: 50 (keys 3551-3600)\n",
      "📦 Enriched batch: 50 (keys 3601-3650)\n",
      "📦 Enriched batch: 50 (keys 3651-3700)\n",
      "📦 Enriched batch: 50 (keys 3701-3750)\n",
      "📦 Enriched batch: 50 (keys 3751-3800)\n",
      "📦 Enriched batch: 50 (keys 3801-3850)\n",
      "📦 Enriched batch: 50 (keys 3851-3900)\n",
      "📦 Enriched batch: 50 (keys 3901-3950)\n",
      "📦 Enriched batch: 50 (keys 3951-4000)\n",
      "📦 Enriched batch: 50 (keys 4001-4050)\n",
      "📦 Enriched batch: 50 (keys 4051-4100)\n",
      "📦 Enriched batch: 50 (keys 4101-4150)\n",
      "📦 Enriched batch: 50 (keys 4151-4200)\n",
      "📦 Enriched batch: 50 (keys 4201-4250)\n",
      "📦 Enriched batch: 50 (keys 4251-4300)\n",
      "📦 Enriched batch: 50 (keys 4301-4350)\n",
      "📦 Enriched batch: 50 (keys 4351-4400)\n",
      "📦 Enriched batch: 50 (keys 4401-4450)\n",
      "📦 Enriched batch: 50 (keys 4451-4500)\n",
      "📦 Enriched batch: 50 (keys 4501-4550)\n",
      "📦 Enriched batch: 50 (keys 4551-4600)\n",
      "📦 Enriched batch: 50 (keys 4601-4650)\n",
      "📦 Enriched batch: 50 (keys 4651-4700)\n",
      "📦 Enriched batch: 50 (keys 4701-4750)\n",
      "📦 Enriched batch: 50 (keys 4751-4800)\n",
      "📦 Enriched batch: 50 (keys 4801-4850)\n",
      "📦 Enriched batch: 50 (keys 4851-4900)\n",
      "📦 Enriched batch: 50 (keys 4901-4950)\n",
      "📦 Enriched batch: 50 (keys 4951-5000)\n",
      "📦 Enriched batch: 50 (keys 5001-5050)\n",
      "📦 Enriched batch: 50 (keys 5051-5100)\n",
      "📦 Enriched batch: 43 (keys 5101-5143)\n",
      "✅ Total linked issues fetched: 5143\n",
      "💾 JSON enriched saved: jira_it_issues.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "from typing import List, Dict, Any, Set\n",
    "\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "# ========= Config =========\n",
    "\n",
    "\n",
    "AUTH = HTTPBasicAuth(EMAIL, API_TOKEN)\n",
    "HEADERS = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "\n",
    "# JQL principal (ajustar a lo que uses)\n",
    "JQL = \"\"\"\n",
    "project = IT\n",
    "AND issuetype NOT IN (Epic, Sub-task, Subtarea)\n",
    "ORDER BY priority DESC, duedate ASC\n",
    "\"\"\".strip()\n",
    "\n",
    "# Campos que querés en los issues \"base\"\n",
    "MAIN_FIELDS = [\n",
    "    \"summary\",\n",
    "    \"project\",\n",
    "    \"reporter\",\n",
    "    \"assignee\",\n",
    "    \"status\",\n",
    "    \"priority\",\n",
    "    \"issuetype\",\n",
    "    \"timetracking\",\n",
    "    \"duedate\",\n",
    "    \"customfield_10016\",  # Story Points\n",
    "    \"customfield_10212\",  # Módulo (ejemplo)\n",
    "    \"customfield_10214\",\n",
    "    \"customfield_10442\",\n",
    "    \"customfield_10608\",\n",
    "    \"issuelinks\"          # ¡necesario para ver vínculos!\n",
    "]\n",
    "\n",
    "# Campos que querés traer del issue vinculado (además de summary/status/priority, etc.)\n",
    "WANTED_FIELDS = [\n",
    "    \"customfield_10209\",\n",
    "]\n",
    "\n",
    "MAX_RESULTS = 100\n",
    "CHUNK_LINKED = 50  # tamaño de lote para buscar issues vinculados\n",
    "OUT_JSON = \"jira_it_issues.json\"\n",
    "  # opcional\n",
    "\n",
    "\n",
    "# ========= Funciones utilitarias =========\n",
    "def fetch_issues_paged(jql: str, fields: List[str]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Descarga issues con paginación.\"\"\"\n",
    "    start_at = 0\n",
    "    all_issues: List[Dict[str, Any]] = []\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"jql\": jql,\n",
    "            \"maxResults\": MAX_RESULTS,\n",
    "            \"startAt\": start_at,\n",
    "            \"fields\": \",\".join(fields),\n",
    "        }\n",
    "        resp = requests.get(BASE_URL, headers=HEADERS, params=params, auth=AUTH)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "\n",
    "        issues = data.get(\"issues\", [])\n",
    "        all_issues.extend(issues)\n",
    "        print(f\"🔄 Fetched {len(issues)} issues (startAt={start_at})\")\n",
    "\n",
    "        if len(issues) < MAX_RESULTS:\n",
    "            break\n",
    "        start_at += MAX_RESULTS\n",
    "        # Evitar golpear el rate limit\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    print(f\"✅ Total base issues: {len(all_issues)}\")\n",
    "    return all_issues\n",
    "\n",
    "\n",
    "def collect_linked_issue_keys(issues: List[Dict[str, Any]], only_types: List[str] = None) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Recolecta todas las keys de inward/outward de issuelinks.\n",
    "    only_types: si lo pasás, filtrás por nombre de tipo de vínculo (p.ej. [\"Problem/Incident\"])\n",
    "    \"\"\"\n",
    "    keys: Set[str] = set()\n",
    "    for it in issues:\n",
    "        links = it.get(\"fields\", {}).get(\"issuelinks\", []) or []\n",
    "        for link in links:\n",
    "            if only_types and link.get(\"type\", {}).get(\"name\") not in only_types:\n",
    "                continue\n",
    "            for side in (\"outwardIssue\", \"inwardIssue\"):\n",
    "                if side in link and \"key\" in link[side]:\n",
    "                    keys.add(link[side][\"key\"])\n",
    "    print(f\"🔗 Linked keys found: {len(keys)}\")\n",
    "    return keys\n",
    "\n",
    "\n",
    "def fetch_issues_by_keys(keys: List[str], fields: List[str], chunk: int = CHUNK_LINKED) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"Trae issues por key en lotes y devuelve un map {key: issue_json} con los fields solicitados.\"\"\"\n",
    "    out: Dict[str, Dict[str, Any]] = {}\n",
    "    keys = list(keys)\n",
    "\n",
    "    for i in range(0, len(keys), chunk):\n",
    "        slice_keys = keys[i:i + chunk]\n",
    "        jql = f\"issuekey in ({','.join(slice_keys)})\"\n",
    "        params = {\n",
    "            \"jql\": jql,\n",
    "            \"maxResults\": 100,\n",
    "            \"fields\": \",\".join(fields)\n",
    "        }\n",
    "        resp = requests.get(BASE_URL, headers=HEADERS, params=params, auth=AUTH)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        for issue in data.get(\"issues\", []):\n",
    "            out[issue[\"key\"]] = issue\n",
    "        print(f\"📦 Enriched batch: {len(data.get('issues', []))} (keys {i+1}-{i+len(slice_keys)})\")\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    print(f\"✅ Total linked issues fetched: {len(out)}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def enrich_issue_links_with_fields(issues: List[Dict[str, Any]],\n",
    "                                   linked_map: Dict[str, Dict[str, Any]],\n",
    "                                   fields_to_copy: List[str]) -> None:\n",
    "    \"\"\"Inyecta 'fields_to_copy' dentro de outward/inwardIssue.fields si NO existen aún en el issue base.\"\"\"\n",
    "    for it in issues:\n",
    "        links = it.get(\"fields\", {}).get(\"issuelinks\", []) or []\n",
    "        for link in links:\n",
    "            for side in (\"outwardIssue\", \"inwardIssue\"):\n",
    "                if side in link and \"key\" in link[side]:\n",
    "                    k = link[side][\"key\"]\n",
    "                    if k in linked_map:\n",
    "                        link[side].setdefault(\"fields\", {})\n",
    "                        src_fields = linked_map[k].get(\"fields\", {})\n",
    "                        for f in fields_to_copy:\n",
    "                            # ⛔️ Solo insertar si NO estaba definido antes\n",
    "                            if f not in link[side][\"fields\"]:\n",
    "                                link[side][\"fields\"][f] = src_fields.get(f)\n",
    "\n",
    "def check_links_integrity(before: List[Dict[str, Any]], after: List[Dict[str, Any]]) -> None:\n",
    "    \"\"\"Verifica que los vínculos críticos como 'Blocks' no se hayan perdido tras enriquecer.\"\"\"\n",
    "    for b_issue, a_issue in zip(before, after):\n",
    "        b_links = b_issue.get(\"fields\", {}).get(\"issuelinks\", [])\n",
    "        a_links = a_issue.get(\"fields\", {}).get(\"issuelinks\", [])\n",
    "        b_blocks = {(l.get(\"type\", {}).get(\"name\"), l.get(\"outwardIssue\", {}).get(\"key\"), l.get(\"inwardIssue\", {}).get(\"key\")) for l in b_links if l.get(\"type\", {}).get(\"name\") == \"Blocks\"}\n",
    "        a_blocks = {(l.get(\"type\", {}).get(\"name\"), l.get(\"outwardIssue\", {}).get(\"key\"), l.get(\"inwardIssue\", {}).get(\"key\")) for l in a_links if l.get(\"type\", {}).get(\"name\") == \"Blocks\"}\n",
    "\n",
    "        if b_blocks != a_blocks:\n",
    "            print(f\"🚨 WARNING: Issue {b_issue['key']} had Blocks links altered!\")\n",
    "\n",
    "def flatten_links_to_csv(issues: List[Dict[str, Any]],\n",
    "                         csv_path: str,\n",
    "                         sides: List[str] = (\"outwardIssue\", \"inwardIssue\"),\n",
    "                         fields_for_flat: List[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Aplana vínculos a CSV: una fila por (issue base, vínculo).\n",
    "    fields_for_flat: columnas a sacar del vinculado (además de key y type).\n",
    "    \"\"\"\n",
    "    if fields_for_flat is None:\n",
    "        fields_for_flat = [\"summary\", \"status\", \"priority\", \"duedate\", \"customfield_10016\"]\n",
    "\n",
    "    rows = []\n",
    "    for it in issues:\n",
    "        base_key = it.get(\"key\")\n",
    "        base_summary = it.get(\"fields\", {}).get(\"summary\")\n",
    "        links = it.get(\"fields\", {}).get(\"issuelinks\", []) or []\n",
    "        for link in links:\n",
    "            link_type = link.get(\"type\", {}).get(\"name\")\n",
    "            for side in sides:\n",
    "                linked = link.get(side)\n",
    "                if not linked:\n",
    "                    continue\n",
    "                lkey = linked.get(\"key\")\n",
    "                lf = (linked.get(\"fields\") or {})\n",
    "                row = {\n",
    "                    \"base_issue\": base_key,\n",
    "                    \"base_summary\": base_summary,\n",
    "                    \"link_type\": link_type or \"\",\n",
    "                    \"link_side\": side,\n",
    "                    \"linked_issue\": lkey,\n",
    "                }\n",
    "                # Agregar columnas pedidas\n",
    "                # status/priority vienen como objetos; sacar el \"name\" si existe\n",
    "                for col in fields_for_flat:\n",
    "                    val = lf.get(col)\n",
    "                    if isinstance(val, dict) and \"name\" in val:\n",
    "                        val = val[\"name\"]\n",
    "                    row[col] = val\n",
    "                rows.append(row)\n",
    "\n",
    "    # Escribir CSV\n",
    "    fieldnames = [\"base_issue\", \"base_summary\", \"link_type\", \"link_side\", \"linked_issue\"] + fields_for_flat\n",
    "    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "    print(f\"📄 Links CSV saved: {csv_path} ({len(rows)} rows)\")\n",
    "\n",
    "\n",
    "# ========= Main =========\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Descargar issues base (con issuelinks)\n",
    "    base_issues = fetch_issues_paged(JQL, MAIN_FIELDS)\n",
    "\n",
    "    # 2) Recolectar keys de issues vinculados\n",
    "    linked_keys = collect_linked_issue_keys(base_issues, only_types=None)  # podés filtrar por tipo si querés\n",
    "\n",
    "    # 3) Traer info de issues vinculados (campos personalizados deseados)\n",
    "    linked_map = {}\n",
    "    if linked_keys:\n",
    "        linked_map = fetch_issues_by_keys(\n",
    "            list(linked_keys),\n",
    "            fields=WANTED_FIELDS,\n",
    "        )\n",
    "\n",
    "    # 4) Enriquecer los vínculos en la estructura original\n",
    "    base_issues_before = base_issues\n",
    "    if linked_map:\n",
    "        enrich_issue_links_with_fields(base_issues, linked_map, WANTED_FIELDS)\n",
    "\n",
    "    check_links_integrity(base_issues_before, base_issues)\n",
    "    # 5) Guardar JSON enriquecido\n",
    "    with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"issues\": base_issues}, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"💾 JSON enriched saved: {OUT_JSON}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Download epics\n",
    "def fetch_epics():\n",
    "    start_at = 0\n",
    "    all_epics = {}\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"jql\": \"project = IT AND issuetype = Epic\",\n",
    "            \"maxResults\": 100,\n",
    "            \"startAt\": start_at,\n",
    "            \"fields\": \"key,duedate,summary\"\n",
    "        }\n",
    "\n",
    "        response = requests.get(BASE_URL, headers=HEADERS, params=params, auth=AUTH)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        for issue in data[\"issues\"]:\n",
    "            epic_key = issue[\"key\"]\n",
    "            due = issue[\"fields\"].get(\"duedate\")\n",
    "            summary = issue[\"fields\"].get(\"summary\", \"\")\n",
    "            \n",
    "            # Inicializar con datos del epic\n",
    "            all_epics[epic_key] = {\n",
    "                \"due_date\": due,\n",
    "                \"summary\": summary,\n",
    "                \"tasks\": []\n",
    "            }\n",
    "\n",
    "            # 🔄 Buscar tareas asociadas a la épica\n",
    "            story_start = 0\n",
    "            while True:\n",
    "                story_params = {\n",
    "                    \"jql\": f'\"Epic Link\" = {epic_key}',\n",
    "                    \"maxResults\": 100,\n",
    "                    \"startAt\": story_start,\n",
    "                    \"fields\": \"key,customfield_10016,status\"\n",
    "                }\n",
    "\n",
    "                story_resp = requests.get(BASE_URL, headers=HEADERS, params=story_params, auth=AUTH)\n",
    "                story_resp.raise_for_status()\n",
    "                story_data = story_resp.json()\n",
    "\n",
    "                for story in story_data[\"issues\"]:\n",
    "                    story_key = story[\"key\"]\n",
    "                \n",
    "                    sp_estimate = story[\"fields\"].get(\"customfield_10016\")  #  Story Points\n",
    "                    status = story[\"fields\"].get(\"status\", {}).get(\"name\", \"Sin estado\")\n",
    "                    all_epics[epic_key][\"tasks\"].append({\n",
    "                        \"key\": story_key,\n",
    "                        \"story_points\": sp_estimate,\n",
    "                        \"status\": status\n",
    "                    })\n",
    "\n",
    "                if len(story_data[\"issues\"]) < 100:\n",
    "                    break\n",
    "                story_start += 100\n",
    "\n",
    "        if len(data[\"issues\"]) < 100:\n",
    "            break\n",
    "        start_at += 100\n",
    "\n",
    "    return all_epics\n",
    "\n",
    "epics = fetch_epics()\n",
    "\n",
    "# Guardar en archivo si lo deseas\n",
    "with open(\"epics_due_lookup.json\", \"w\") as f:\n",
    "    json.dump(epics, f, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f606bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc0aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e65b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = '346436483896-non6bmg405eh4avr5saql5m1r0r37rim.apps.googleusercontent.com'\n",
    "client_secret = '346436483896-non6bmg405eh4avr5saql5m1r0r37rim.apps.googleusercontent.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "711b5556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Consultando reuniones de Luis Uran (luisuran@biamex.com)...\n",
      "🔎 Consultando reuniones de Diego Martin Gogorza (diegogogorza@biamex.com)...\n",
      "🔎 Consultando reuniones de Nicolas Pardo (nicolaspardo@biamex.com)...\n",
      "🔎 Consultando reuniones de Martin Horn (martinhorn@biamex.com)...\n",
      "🔎 Consultando reuniones de Facundo Capua (facundocapua@biamex.com)...\n",
      "🔎 Consultando reuniones de Franco Lorenzo (francolorenzo@biamex.com)...\n",
      "🔎 Consultando reuniones de Alan Mori - Carestino (alanmori@biamex.com)...\n",
      "🔎 Consultando reuniones de Gastón Ojeda (gastonojeda@biamex.com)...\n",
      "🔎 Consultando reuniones de Miguel Armentano (miguelarmentano@biamex.com)...\n",
      "🔎 Consultando reuniones de Juan Ignacio Morelis - Carestino (juanmorelis@biamex.com)...\n",
      "📅 Luis Uran: 10 bloque(s) ocupado(s)\n",
      "   🕓 2025-08-18 08:30 → 09:00\n",
      "   🕓 2025-08-19 08:30 → 09:00\n",
      "   🕓 2025-08-20 08:30 → 09:00\n",
      "   🕓 2025-08-20 09:00 → 09:30\n",
      "   🕓 2025-08-21 08:30 → 09:00\n",
      "   🕓 2025-08-22 08:30 → 09:00\n",
      "   🕓 2025-08-25 08:30 → 09:00\n",
      "   🕓 2025-08-26 08:30 → 09:00\n",
      "   🕓 2025-08-27 08:30 → 09:00\n",
      "   🕓 2025-08-28 08:30 → 09:00\n",
      "📅 Diego Martin Gogorza: 25 bloque(s) ocupado(s)\n",
      "   🕓 2025-08-18 08:30 → 09:00\n",
      "   🕓 2025-08-18 11:00 → 12:00\n",
      "   🕓 2025-08-18 14:30 → 15:00\n",
      "   🕓 2025-08-19 07:30 → 08:30\n",
      "   🕓 2025-08-19 08:30 → 09:00\n",
      "   🕓 2025-08-19 14:30 → 15:00\n",
      "   🕓 2025-08-19 16:00 → 16:30\n",
      "   🕓 2025-08-20 08:30 → 09:00\n",
      "   🕓 2025-08-20 09:00 → 09:30\n",
      "   🕓 2025-08-20 10:00 → 12:00\n",
      "   🕓 2025-08-20 11:00 → 12:00\n",
      "   🕓 2025-08-21 07:30 → 08:30\n",
      "   🕓 2025-08-21 08:30 → 09:00\n",
      "   🕓 2025-08-22 08:30 → 09:00\n",
      "   🕓 2025-08-25 08:30 → 09:00\n",
      "   🕓 2025-08-25 11:00 → 12:00\n",
      "   🕓 2025-08-25 14:30 → 15:00\n",
      "   🕓 2025-08-26 07:30 → 08:30\n",
      "   🕓 2025-08-26 08:30 → 09:00\n",
      "   🕓 2025-08-26 14:30 → 15:00\n",
      "   🕓 2025-08-27 08:30 → 09:00\n",
      "   🕓 2025-08-27 10:00 → 12:00\n",
      "   🕓 2025-08-27 11:00 → 12:00\n",
      "   🕓 2025-08-28 07:30 → 08:30\n",
      "   🕓 2025-08-28 08:30 → 09:00\n",
      "📅 Nicolas Pardo: 30 bloque(s) ocupado(s)\n",
      "   🕓 2025-08-18 08:30 → 09:00\n",
      "   🕓 2025-08-18 09:00 → 10:00\n",
      "   🕓 2025-08-18 10:30 → 11:00\n",
      "   🕓 2025-08-18 11:00 → 12:00\n",
      "   🕓 2025-08-19 07:30 → 08:30\n",
      "   🕓 2025-08-19 08:30 → 09:00\n",
      "   🕓 2025-08-20 08:30 → 09:00\n",
      "   🕓 2025-08-20 09:00 → 09:30\n",
      "   🕓 2025-08-20 09:30 → 10:00\n",
      "   🕓 2025-08-20 10:00 → 12:00\n",
      "   🕓 2025-08-20 11:00 → 12:00\n",
      "   🕓 2025-08-20 13:00 → 14:00\n",
      "   🕓 2025-08-21 07:30 → 08:30\n",
      "   🕓 2025-08-21 08:30 → 09:00\n",
      "   🕓 2025-08-21 09:00 → 10:00\n",
      "   🕓 2025-08-22 08:30 → 09:00\n",
      "   🕓 2025-08-25 08:30 → 09:00\n",
      "   🕓 2025-08-25 09:00 → 10:00\n",
      "   🕓 2025-08-25 10:30 → 11:00\n",
      "   🕓 2025-08-25 11:00 → 12:00\n",
      "   🕓 2025-08-26 07:30 → 08:30\n",
      "   🕓 2025-08-26 08:30 → 09:00\n",
      "   🕓 2025-08-27 08:30 → 09:00\n",
      "   🕓 2025-08-27 09:30 → 10:00\n",
      "   🕓 2025-08-27 10:00 → 12:00\n",
      "   🕓 2025-08-27 11:00 → 12:00\n",
      "   🕓 2025-08-27 13:00 → 14:00\n",
      "   🕓 2025-08-28 07:30 → 08:30\n",
      "   🕓 2025-08-28 08:30 → 09:00\n",
      "   🕓 2025-08-28 09:00 → 10:00\n",
      "📅 Martin Horn: 53 bloque(s) ocupado(s)\n",
      "   🕓 2025-08-18 08:30 → 08:35\n",
      "   🕓 2025-08-18 09:15 → 09:25\n",
      "   🕓 2025-08-18 10:00 → 10:30\n",
      "   🕓 2025-08-18 11:30 → 12:30\n",
      "   🕓 2025-08-18 12:30 → 13:15\n",
      "   🕓 2025-08-18 14:30 → 15:00\n",
      "   🕓 2025-08-18 15:00 → 15:30\n",
      "   🕓 2025-08-18 16:30 → 17:00\n",
      "   🕓 2025-08-18 17:30 → 17:35\n",
      "   🕓 2025-08-19 10:00 → 11:00\n",
      "   🕓 2025-08-19 14:00 → 14:30\n",
      "   🕓 2025-08-19 14:30 → 15:00\n",
      "   🕓 2025-08-19 16:00 → 16:30\n",
      "   🕓 2025-08-19 17:30 → 17:35\n",
      "   🕓 2025-08-19 19:00 → 22:00\n",
      "   🕓 2025-08-20 10:00 → 12:00\n",
      "   🕓 2025-08-20 14:00 → 14:45\n",
      "   🕓 2025-08-20 15:00 → 15:45\n",
      "   🕓 2025-08-20 16:30 → 17:00\n",
      "   🕓 2025-08-20 17:00 → 17:30\n",
      "   🕓 2025-08-20 17:30 → 17:35\n",
      "   🕓 2025-08-21 09:30 → 10:00\n",
      "   🕓 2025-08-21 13:00 → 14:00\n",
      "   🕓 2025-08-21 14:00 → 15:00\n",
      "   🕓 2025-08-21 17:30 → 17:35\n",
      "   🕓 2025-08-22 15:00 → 16:00\n",
      "   🕓 2025-08-22 17:30 → 17:35\n",
      "   🕓 2025-08-22 19:00 → 22:00\n",
      "   🕓 2025-08-25 09:15 → 09:25\n",
      "   🕓 2025-08-25 10:00 → 10:30\n",
      "   🕓 2025-08-25 11:30 → 12:30\n",
      "   🕓 2025-08-25 12:30 → 13:15\n",
      "   🕓 2025-08-25 14:30 → 15:00\n",
      "   🕓 2025-08-25 15:00 → 15:30\n",
      "   🕓 2025-08-25 16:30 → 17:00\n",
      "   🕓 2025-08-25 17:30 → 17:35\n",
      "   🕓 2025-08-26 10:00 → 11:00\n",
      "   🕓 2025-08-26 14:00 → 14:30\n",
      "   🕓 2025-08-26 14:30 → 15:00\n",
      "   🕓 2025-08-26 17:30 → 17:35\n",
      "   🕓 2025-08-26 19:00 → 22:00\n",
      "   🕓 2025-08-27 10:00 → 12:00\n",
      "   🕓 2025-08-27 14:00 → 14:45\n",
      "   🕓 2025-08-27 15:00 → 15:45\n",
      "   🕓 2025-08-27 16:30 → 17:00\n",
      "   🕓 2025-08-27 17:00 → 17:30\n",
      "   🕓 2025-08-27 17:30 → 19:00\n",
      "   🕓 2025-08-27 17:30 → 17:35\n",
      "   🕓 2025-08-28 05:30 → 08:30\n",
      "   🕓 2025-08-28 09:30 → 10:00\n",
      "   🕓 2025-08-28 13:00 → 14:00\n",
      "   🕓 2025-08-28 14:00 → 15:00\n",
      "   🕓 2025-08-28 17:30 → 17:35\n",
      "📅 Facundo Capua: 0 bloque(s) ocupado(s)\n",
      "📅 Franco Lorenzo: 32 bloque(s) ocupado(s)\n",
      "   🕓 2025-08-18 00:00 → 00:00\n",
      "   🕓 2025-08-18 08:30 → 09:00\n",
      "   🕓 2025-08-18 10:00 → 10:50\n",
      "   🕓 2025-08-18 13:00 → 14:00\n",
      "   🕓 2025-08-19 08:30 → 09:00\n",
      "   🕓 2025-08-19 09:00 → 09:40\n",
      "   🕓 2025-08-19 13:00 → 14:00\n",
      "   🕓 2025-08-19 15:00 → 15:30\n",
      "   🕓 2025-08-20 08:30 → 09:00\n",
      "   🕓 2025-08-20 09:00 → 09:30\n",
      "   🕓 2025-08-20 10:00 → 10:50\n",
      "   🕓 2025-08-20 13:00 → 14:00\n",
      "   🕓 2025-08-21 08:30 → 09:00\n",
      "   🕓 2025-08-21 09:00 → 09:40\n",
      "   🕓 2025-08-21 13:00 → 14:00\n",
      "   🕓 2025-08-21 15:00 → 15:30\n",
      "   🕓 2025-08-22 08:30 → 09:00\n",
      "   🕓 2025-08-22 13:00 → 14:00\n",
      "   🕓 2025-08-25 08:30 → 09:00\n",
      "   🕓 2025-08-25 10:00 → 10:50\n",
      "   🕓 2025-08-25 13:00 → 14:00\n",
      "   🕓 2025-08-26 08:30 → 09:00\n",
      "   🕓 2025-08-26 09:00 → 09:40\n",
      "   🕓 2025-08-26 13:00 → 14:00\n",
      "   🕓 2025-08-26 15:00 → 15:30\n",
      "   🕓 2025-08-27 08:30 → 09:00\n",
      "   🕓 2025-08-27 10:00 → 10:50\n",
      "   🕓 2025-08-27 13:00 → 14:00\n",
      "   🕓 2025-08-28 08:30 → 09:00\n",
      "   🕓 2025-08-28 09:00 → 09:40\n",
      "   🕓 2025-08-28 13:00 → 14:00\n",
      "   🕓 2025-08-28 15:00 → 15:30\n",
      "📅 Alan Mori - Carestino: 19 bloque(s) ocupado(s)\n",
      "   🕓 2025-08-18 08:30 → 09:00\n",
      "   🕓 2025-08-18 10:30 → 10:35\n",
      "   🕓 2025-08-19 08:30 → 09:00\n",
      "   🕓 2025-08-19 10:30 → 10:35\n",
      "   🕓 2025-08-20 08:30 → 09:00\n",
      "   🕓 2025-08-20 09:00 → 09:30\n",
      "   🕓 2025-08-20 10:30 → 10:35\n",
      "   🕓 2025-08-21 08:30 → 09:00\n",
      "   🕓 2025-08-21 10:30 → 10:35\n",
      "   🕓 2025-08-22 08:30 → 09:00\n",
      "   🕓 2025-08-22 10:30 → 10:35\n",
      "   🕓 2025-08-25 08:30 → 09:00\n",
      "   🕓 2025-08-25 10:30 → 10:35\n",
      "   🕓 2025-08-26 08:30 → 09:00\n",
      "   🕓 2025-08-26 10:30 → 10:35\n",
      "   🕓 2025-08-27 08:30 → 09:00\n",
      "   🕓 2025-08-27 10:30 → 10:35\n",
      "   🕓 2025-08-28 08:30 → 09:00\n",
      "   🕓 2025-08-28 10:30 → 10:35\n",
      "📅 Gastón Ojeda: 29 bloque(s) ocupado(s)\n",
      "   🕓 2025-08-18 08:30 → 09:00\n",
      "   🕓 2025-08-18 11:00 → 12:00\n",
      "   🕓 2025-08-18 12:00 → 13:00\n",
      "   🕓 2025-08-19 07:30 → 08:30\n",
      "   🕓 2025-08-19 08:30 → 09:00\n",
      "   🕓 2025-08-19 12:00 → 13:00\n",
      "   🕓 2025-08-19 14:30 → 15:00\n",
      "   🕓 2025-08-20 08:30 → 09:00\n",
      "   🕓 2025-08-20 09:00 → 09:30\n",
      "   🕓 2025-08-20 11:00 → 12:00\n",
      "   🕓 2025-08-20 12:00 → 13:00\n",
      "   🕓 2025-08-21 07:30 → 08:30\n",
      "   🕓 2025-08-21 08:30 → 09:00\n",
      "   🕓 2025-08-21 12:00 → 13:00\n",
      "   🕓 2025-08-22 08:30 → 09:00\n",
      "   🕓 2025-08-22 12:00 → 13:00\n",
      "   🕓 2025-08-25 08:30 → 09:00\n",
      "   🕓 2025-08-25 11:00 → 12:00\n",
      "   🕓 2025-08-25 12:00 → 13:00\n",
      "   🕓 2025-08-26 07:30 → 08:30\n",
      "   🕓 2025-08-26 08:30 → 09:00\n",
      "   🕓 2025-08-26 12:00 → 13:00\n",
      "   🕓 2025-08-26 14:30 → 15:00\n",
      "   🕓 2025-08-27 08:30 → 09:00\n",
      "   🕓 2025-08-27 11:00 → 12:00\n",
      "   🕓 2025-08-27 12:00 → 13:00\n",
      "   🕓 2025-08-28 07:30 → 08:30\n",
      "   🕓 2025-08-28 08:30 → 09:00\n",
      "   🕓 2025-08-28 12:00 → 13:00\n",
      "📅 Miguel Armentano: 19 bloque(s) ocupado(s)\n",
      "   🕓 2025-08-18 08:30 → 09:00\n",
      "   🕓 2025-08-18 12:00 → 13:00\n",
      "   🕓 2025-08-19 08:30 → 09:00\n",
      "   🕓 2025-08-19 12:00 → 13:00\n",
      "   🕓 2025-08-20 08:30 → 09:00\n",
      "   🕓 2025-08-20 09:00 → 09:30\n",
      "   🕓 2025-08-20 12:00 → 13:00\n",
      "   🕓 2025-08-21 08:30 → 09:00\n",
      "   🕓 2025-08-21 12:00 → 13:00\n",
      "   🕓 2025-08-22 08:30 → 09:00\n",
      "   🕓 2025-08-22 12:00 → 13:00\n",
      "   🕓 2025-08-25 08:30 → 09:00\n",
      "   🕓 2025-08-25 12:00 → 13:00\n",
      "   🕓 2025-08-26 08:30 → 09:00\n",
      "   🕓 2025-08-26 12:00 → 13:00\n",
      "   🕓 2025-08-27 08:30 → 09:00\n",
      "   🕓 2025-08-27 12:00 → 13:00\n",
      "   🕓 2025-08-28 08:30 → 09:00\n",
      "   🕓 2025-08-28 12:00 → 13:00\n",
      "📅 Juan Ignacio Morelis - Carestino: 28 bloque(s) ocupado(s)\n",
      "   🕓 2025-08-18 12:30 → 14:00\n",
      "   🕓 2025-08-18 14:00 → 15:00\n",
      "   🕓 2025-08-18 14:30 → 15:30\n",
      "   🕓 2025-08-19 12:00 → 12:30\n",
      "   🕓 2025-08-19 14:00 → 15:00\n",
      "   🕓 2025-08-19 15:00 → 16:00\n",
      "   🕓 2025-08-20 12:30 → 14:00\n",
      "   🕓 2025-08-20 14:00 → 15:00\n",
      "   🕓 2025-08-20 14:30 → 15:30\n",
      "   🕓 2025-08-20 16:00 → 16:30\n",
      "   🕓 2025-08-21 12:00 → 12:30\n",
      "   🕓 2025-08-21 14:00 → 15:00\n",
      "   🕓 2025-08-22 14:00 → 15:00\n",
      "   🕓 2025-08-22 16:00 → 16:30\n",
      "   🕓 2025-08-23 14:00 → 15:00\n",
      "   🕓 2025-08-24 14:00 → 15:00\n",
      "   🕓 2025-08-25 12:30 → 14:00\n",
      "   🕓 2025-08-25 14:00 → 15:00\n",
      "   🕓 2025-08-25 14:30 → 15:30\n",
      "   🕓 2025-08-26 12:00 → 12:30\n",
      "   🕓 2025-08-26 14:00 → 15:00\n",
      "   🕓 2025-08-26 15:00 → 16:00\n",
      "   🕓 2025-08-27 12:30 → 14:00\n",
      "   🕓 2025-08-27 14:00 → 15:00\n",
      "   🕓 2025-08-27 14:30 → 15:30\n",
      "   🕓 2025-08-27 16:00 → 16:30\n",
      "   🕓 2025-08-28 12:00 → 12:30\n",
      "   🕓 2025-08-28 14:00 → 15:00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "from collections import defaultdict\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "# 📌 Permisos necesarios: lectura del calendario\n",
    "SCOPES = ['https://www.googleapis.com/auth/calendar.readonly']\n",
    "\n",
    "# 📂 Archivos de autenticación\n",
    "CREDENTIALS_PATH = 'client_secret.json'\n",
    "TOKEN_PATH = 'token.json'\n",
    "\n",
    "\n",
    "\n",
    "def obtener_credenciales():\n",
    "    creds = None\n",
    "    if os.path.exists(TOKEN_PATH):\n",
    "        creds = Credentials.from_authorized_user_file(TOKEN_PATH, SCOPES)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(CREDENTIALS_PATH, SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open(TOKEN_PATH, 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return creds\n",
    "\n",
    "def obtener_bloques_ocupados(email, creds, start_dt, end_dt):\n",
    "    service = build('calendar', 'v3', credentials=creds)\n",
    "    eventos_resultado = service.events().list(\n",
    "        calendarId=email,\n",
    "        timeMin=start_dt.isoformat(),\n",
    "        timeMax=end_dt.isoformat(),\n",
    "        singleEvents=True,\n",
    "        orderBy=\"startTime\"\n",
    "    ).execute()\n",
    "\n",
    "    eventos = eventos_resultado.get('items', [])\n",
    "    bloques_ocupados = []\n",
    "\n",
    "    for evento in eventos:\n",
    "        start_str = evento['start'].get('dateTime')\n",
    "        end_str = evento['end'].get('dateTime')\n",
    "        if not start_str or not end_str:\n",
    "            continue  # Omitir eventos de todo el día\n",
    "\n",
    "        start_time = datetime.datetime.fromisoformat(start_str)\n",
    "        end_time = datetime.datetime.fromisoformat(end_str)\n",
    "        bloques_ocupados.append((start_time, end_time))\n",
    "\n",
    "    return bloques_ocupados\n",
    "\n",
    "def obtener_bloques_por_dev():\n",
    "    creds = obtener_credenciales()\n",
    "    bloques_por_dev = {}\n",
    "\n",
    "    for dev, email in MAIL_MAP.items():\n",
    "        print(f\"🔎 Consultando reuniones de {dev} ({email})...\")\n",
    "        try:\n",
    "            bloques = obtener_bloques_ocupados(email, creds, DEFAULT_START_DATE_with_timezone, DEFAULT_END_DATE_with_timezone)\n",
    "            bloques_por_dev[dev] = bloques\n",
    "            #print(f\"   ✅ {len(bloques)} reuniones encontradas.\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error consultando {email}: {str(e)}\\n\")\n",
    "            bloques_por_dev[dev] = []\n",
    "\n",
    "    return bloques_por_dev\n",
    "\n",
    "# Para usar de forma aislada:\n",
    "if __name__ == \"__main__\":\n",
    "    bloques = obtener_bloques_por_dev()\n",
    "    for dev, bloques_list in bloques.items():\n",
    "        print(f\"📅 {dev}: {len(bloques_list)} bloque(s) ocupado(s)\")\n",
    "        for start, end in bloques_list:\n",
    "            print(f\"   🕓 {start.strftime('%Y-%m-%d %H:%M')} → {end.strftime('%H:%M')}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "761eeca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Alan Mori - Carestino:\n",
      "  🎯 Epic target: 70.0%\n",
      "  📊 Total in range: 20.0 h | Epic in range: 20.0 h\n",
      "  🔍 Epic tasks out of range: 9\n",
      "    - IT-21015 (4.0 h) due 2025-09-01\n",
      "    - IT-21006 (8.0 h) due 2025-09-09\n",
      "    - IT-20258 (4.0 h) due 2025-09-26\n",
      "    - IT-20783 (3.0 h) due 2025-10-10\n",
      "    - IT-20531 (24.0 h) due 2025-10-31\n",
      "    - IT-20876 (4.0 h) due 2025-11-07\n",
      "    - IT-21013 (16.0 h) due 2025-12-19\n",
      "    - IT-20781 (18.0 h) due 2025-12-19\n",
      "    - IT-17639 (4.0 h) due 2100-01-01\n",
      " modificando IT-21015 due 2100-01-01\n",
      "✔️ Ratio tras forzar IT-21015: 24.0 / (55.0) = 43.6%\n",
      " modificando IT-21006 due 2100-01-01\n",
      "✔️ Ratio tras forzar IT-21006: 32.0 / (55.0) = 58.2%\n",
      " modificando IT-20258 due 2100-01-01\n",
      "✔️ Ratio tras forzar IT-20258: 36.0 / (55.0) = 65.5%\n",
      " modificando IT-20783 due 2100-01-01\n",
      "✔️ Ratio tras forzar IT-20783: 39.0 / (55.0) = 70.9%\n",
      "\n",
      "🔎 Luis Uran:\n",
      "  🎯 Epic target: 50.0%\n",
      "  📊 Total in range: 4.0 h | Epic in range: 0.0 h\n",
      "  🔍 Epic tasks out of range: 2\n",
      "    - IT-19532 (2.0 h) due 2025-04-11\n",
      "    - IT-19694 (2.0 h) due 2025-05-15\n",
      " modificando IT-19532 due 2025-05-15\n",
      "✔️ Ratio tras forzar IT-19532: 2.0 / (60.0) = 3.3%\n",
      " modificando IT-19694 due 2025-05-15\n",
      "✔️ Ratio tras forzar IT-19694: 4.0 / (60.0) = 6.7%\n",
      "\n",
      "🔎 Gastón Ojeda:\n",
      "  🎯 Epic target: 30.0%\n",
      "  📊 Total in range: 0.0 h | Epic in range: 0.0 h\n",
      "  🔍 Epic tasks out of range: 14\n",
      "    - IT-18842 (24.0 h) due 2025-06-05\n",
      "    - IT-20212 (5.0 h) due 2025-07-11\n",
      "    - IT-20952 (8.0 h) due 2025-07-18\n",
      "    - IT-20828 (40.0 h) due 2025-08-01\n",
      "    - IT-20386 (8.0 h) due 2025-11-28\n",
      "    - IT-20655 (32.0 h) due 2025-12-26\n",
      "    - IT-15941 (6.0 h) due 2100-01-01\n",
      "    - IT-15936 (4.0 h) due 2100-01-01\n",
      "    - IT-15935 (8.0 h) due 2100-01-01\n",
      "    - IT-15932 (5.0 h) due 2100-01-01\n",
      "    - IT-15931 (1.0 h) due 2100-01-01\n",
      "    - IT-15929 (5.0 h) due 2100-01-01\n",
      "    - IT-15927 (5.0 h) due 2100-01-01\n",
      "    - IT-15922 (16.0 h) due 2100-01-01\n",
      " modificando IT-18842 due 2100-01-01\n",
      "✔️ Ratio tras forzar IT-18842: 24.0 / (50.0) = 48.0%\n",
      "\n",
      "🔎 Franco Lorenzo:\n",
      "  🎯 Epic target: 50.0%\n",
      "  📊 Total in range: 40.0 h | Epic in range: 32.0 h\n",
      "  🔍 Epic tasks out of range: 5\n",
      "    - IT-20114 (40.0 h) due 2025-07-02\n",
      "    - IT-20162 (76.0 h) due 2025-09-30\n",
      "    - IT-20472 (4.0 h) due 2025-10-10\n",
      "    - IT-20697 (20.0 h) due 2025-12-26\n",
      "    - IT-20880 (24.0 h) due 2100-01-01\n",
      " modificando IT-20114 due 2100-01-01\n",
      "✔️ Ratio tras forzar IT-20114: 72.0 / (50.0) = 144.0%\n",
      "\n",
      "🔎 Miguel Armentano:\n",
      "  🎯 Epic target: 50.0%\n",
      "  📊 Total in range: 7.0 h | Epic in range: 0.0 h\n",
      "  🔍 Epic tasks out of range: 30\n",
      "    - IT-20103 (1.0 h) due 2025-08-08\n",
      "    - IT-20573 (10.0 h) due 2026-02-20\n",
      "    - IT-11525 (32.0 h) due 2026-02-20\n",
      "    - IT-11523 (8.0 h) due 2026-02-20\n",
      "    - IT-20034 (4.0 h) due 2100-01-01\n",
      "    - IT-20033 (2.0 h) due 2100-01-01\n",
      "    - IT-20032 (4.0 h) due 2100-01-01\n",
      "    - IT-20031 (4.0 h) due 2100-01-01\n",
      "    - IT-20030 (2.0 h) due 2100-01-01\n",
      "    - IT-20029 (5.0 h) due 2100-01-01\n",
      "    - IT-20028 (3.0 h) due 2100-01-01\n",
      "    - IT-20027 (3.0 h) due 2100-01-01\n",
      "    - IT-20026 (4.0 h) due 2100-01-01\n",
      "    - IT-20025 (4.0 h) due 2100-01-01\n",
      "    - IT-20024 (3.0 h) due 2100-01-01\n",
      "    - IT-20023 (3.0 h) due 2100-01-01\n",
      "    - IT-20022 (4.0 h) due 2100-01-01\n",
      "    - IT-20021 (2.0 h) due 2100-01-01\n",
      "    - IT-20020 (3.0 h) due 2100-01-01\n",
      "    - IT-20019 (3.0 h) due 2100-01-01\n",
      "    - IT-20018 (8.0 h) due 2100-01-01\n",
      "    - IT-20017 (2.0 h) due 2100-01-01\n",
      "    - IT-20016 (8.0 h) due 2100-01-01\n",
      "    - IT-20015 (3.0 h) due 2100-01-01\n",
      "    - IT-20014 (8.0 h) due 2100-01-01\n",
      "    - IT-20013 (2.0 h) due 2100-01-01\n",
      "    - IT-20012 (4.0 h) due 2100-01-01\n",
      "    - IT-20011 (2.0 h) due 2100-01-01\n",
      "    - IT-20010 (2.0 h) due 2100-01-01\n",
      "    - IT-11789 (2.0 h) due 2100-01-01\n",
      " modificando IT-20103 due 2100-01-01\n",
      "✔️ Ratio tras forzar IT-20103: 1.0 / (50.0) = 2.0%\n",
      " modificando IT-20573 due 2100-01-01\n",
      "✔️ Ratio tras forzar IT-20573: 11.0 / (50.0) = 22.0%\n",
      " modificando IT-11525 due 2100-01-01\n",
      "✔️ Ratio tras forzar IT-11525: 43.0 / (50.0) = 86.0%\n",
      "\n",
      "🔎 Facundo Capua:\n",
      "  🎯 Epic target: 10.0%\n",
      "  📊 Total in range: 0.0 h | Epic in range: 0.0 h\n",
      "  🔍 Epic tasks out of range: 3\n",
      "    - IT-17833 (0 h) due 2100-01-01\n",
      "    - IT-17547 (24.0 h) due 2100-01-01\n",
      "    - IT-15195 (24.0 h) due 2100-01-01\n",
      " modificando IT-17833 due 2100-01-01\n",
      "✔️ Ratio tras forzar IT-17833: 0.0 / (80.0) = 0.0%\n",
      " modificando IT-17547 due 2100-01-01\n",
      "✔️ Ratio tras forzar IT-17547: 24.0 / (80.0) = 30.0%\n",
      "\n",
      "🔎 Nicolas Pardo:\n",
      "  🎯 Epic target: 10.0%\n",
      "  📊 Total in range: 4.0 h | Epic in range: 0.0 h\n",
      "  🔍 Epic tasks out of range: 10\n",
      "    - IT-20821 (21.0 h) due 2025-06-30\n",
      "    - IT-20343 (100.0 h) due 2025-07-31\n",
      "    - IT-20545 (8.0 h) due 2025-09-30\n",
      "    - IT-20544 (20.0 h) due 2025-09-30\n",
      "    - IT-20543 (22.0 h) due 2025-09-30\n",
      "    - IT-20542 (20.0 h) due 2025-09-30\n",
      "    - IT-20541 (20.0 h) due 2025-09-30\n",
      "    - IT-20540 (22.0 h) due 2025-09-30\n",
      "    - IT-20411 (0.0 h) due 2025-09-30\n",
      "    - IT-20427 (5.0 h) due 2025-12-26\n",
      " modificando IT-20821 due 2025-12-26\n",
      "✔️ Ratio tras forzar IT-20821: 21.0 / (80.0) = 26.2%\n",
      "\n",
      "🔎 Juan Ignacio Morelis - Carestino:\n",
      "  🎯 Epic target: 10.0%\n",
      "  📊 Total in range: 0.0 h | Epic in range: 0.0 h\n",
      "  🔍 Epic tasks out of range: 1\n",
      "    - IT-19182 (4.0 h) due 2100-01-01\n",
      " modificando IT-19182 due 2100-01-01\n",
      "✔️ Ratio tras forzar IT-19182: 4.0 / (80.0) = 5.0%\n",
      "\n",
      "🔎 Diego Martin Gogorza:\n",
      "  🎯 Epic target: 10.0%\n",
      "  📊 Total in range: 0.0 h | Epic in range: 0.0 h\n",
      "  🔍 Epic tasks out of range: 2\n",
      "    - IT-16252 (0 h) due 2020-06-30\n",
      "    - IT-16305 (0 h) due 2100-01-01\n",
      " modificando IT-16252 due 2100-01-01\n",
      "✔️ Ratio tras forzar IT-16252: 0.0 / (60.0) = 0.0%\n",
      " modificando IT-16305 due 2100-01-01\n",
      "✔️ Ratio tras forzar IT-16305: 0.0 / (60.0) = 0.0%\n",
      "\n",
      "📝 Developer Task Schedule Summary:\n",
      "\n",
      "👨‍💻 Developer: Alan Mori - Carestino\n",
      "   🔹 IT-21002: 4.0h → Due: 2025-05-13 | Finish: Start: 2025-08-18 09:00 | End: 2025-08-18 13:05\n",
      "   🔹 IT-20643: 8.0h → Due: 2025-08-08 | Finish: Start: 2025-08-18 13:05 | End: 2025-08-20 10:30\n",
      "   🔹 IT-21006: 8.0h → Due: 2025-08-18 | Finish: Start: 2025-08-20 10:35 | End: 2025-08-21 12:35\n",
      "   🔹 IT-20258: 4.0h → Due: 2025-08-18 | Finish: Start: 2025-08-21 12:35 | End: 2025-08-22 11:05\n",
      "     🚨 Puede derivarse a: Luis Uran\n",
      "   🔹 IT-20783: 3.0h → Due: 2025-08-18 | Finish: Start: 2025-08-22 11:05 | End: 2025-08-22 14:05\n",
      "   🔹 IT-21015: 4.0h → Due: 2025-08-18 | Finish: Start: 2025-08-22 14:05 | End: 2025-08-25 12:35\n",
      "     📛 Debido a bloqueo de: IT-21004: Worpik / Formulario entrevistas en nueva pestaña (Alan Mori - Carestino, Due: 2025-08-26)\n",
      "   🔹 IT-21008: 4.0h → Due: 2025-08-25 | Finish: Start: 2025-08-25 12:35 | End: 2025-08-26 11:05\n",
      "     🕓 Fecha de vencimiento ajustada por bloqueo a tarjeta ['IT-21010'] que vence el: 2025-08-25\n",
      "     🕓 Fecha de vencimiento ajustada por bloqueo a tarjeta ['IT-21010'] que vence el: 2025-08-25\n",
      "   🔹 IT-21004: 12.0h → Due: 2025-08-26 | Finish: Start: 2025-08-26 11:05 | End: 2025-08-28 12:05\n",
      "     🕓 Fecha de vencimiento ya correcta por bloqueo a tarjeta ['IT-21015'] que vence el: 2025-08-31\n",
      "     🕓 Fecha de vencimiento ya correcta por bloqueo a tarjeta ['IT-21015'] que vence el: 2025-08-31\n",
      "   🔹 IT-21010: 4.0h → Due: 2025-08-26 | Finish: Start: 2025-08-28 12:05 | End: 2025-08-29 10:00\n",
      "     📛 Debido a bloqueo de: IT-21008: Worpik / Inactivar proyecto al alcanzar su fecha de finalización (Alan Mori - Carestino, Due: 2025-08-25)\n",
      "   🔹 IT-20779: 3.0h → Due: 2025-10-01 | Finish: Start: 2025-08-29 10:00 | End: 2025-08-29 13:00\n",
      "     🚨 Puede derivarse a: Nicolas Pardo, Gastón Ojeda\n",
      "   🔹 IT-20777: 12.0h → Due: 2025-10-01 | Finish: Start: 2025-08-29 13:00 | End: 2025-09-02 14:00\n",
      "     🚨 Puede derivarse a: Gastón Ojeda\n",
      "   🔹 IT-19746: 7.0h → Due: 2025-10-03 | Finish: Start: 2025-09-03 08:30 | End: 2025-09-04 10:00\n",
      "     🚨 Puede derivarse a: Gastón Ojeda, Nicolas Pardo, Luis Uran, Miguel Armentano\n",
      "   🔹 IT-20819: 8.0h → Due: 2025-10-17 | Finish: Start: 2025-09-04 10:00 | End: 2025-09-05 12:30\n",
      "   🔹 IT-20531: 24.0h → Due: 2025-10-31 | Finish: Start: 2025-09-05 12:30 | End: 2025-09-12 09:00\n",
      "   🔹 IT-20876: 4.0h → Due: 2025-11-07 | Finish: Start: 2025-09-12 09:00 | End: 2025-09-12 13:00\n",
      "   🔹 IT-21013: 16.0h → Due: 2025-12-19 | Finish: Start: 2025-09-12 13:00 | End: 2025-09-17 12:30\n",
      "   🔹 IT-20781: 18.0h → Due: 2025-12-19 | Finish: Start: 2025-09-17 12:30 | End: 2025-09-22 14:00\n",
      "   🔹 IT-20640: 5.0h → Due: 2025-12-23 | Finish: Start: 2025-09-23 08:30 | End: 2025-09-23 13:30\n",
      "   🔹 IT-17639: 4.0h → Due: 2100-01-01 | Finish: Start: 2025-09-23 13:30 | End: 2025-09-24 12:00\n",
      "     🚨 Puede derivarse a: Luis Uran\n",
      "     📛 Debido a bloqueo de: IT-18145: Guías de Remisión / Perú / Impresión masiva y ajustes a la emisión masiva (Alan Mori - Carestino, Due: 2025-03-21)\n",
      "\n",
      "👨‍💻 Developer: Luis Uran\n",
      "   🔹 IT-20973: 3.0h → Due: 2025-06-10 | Finish: Start: 2025-08-18 09:00 | End: 2025-08-18 12:00\n",
      "     🕓 Fecha de vencimiento ajustada por bloqueo a tarjeta ['IT-20657', 'IT-19976'] que vence el: 2025-06-10\n",
      "     🚨 Puede derivarse a: Nicolas Pardo, Gastón Ojeda\n",
      "     🕓 Fecha de vencimiento ajustada por bloqueo a tarjeta ['IT-20657', 'IT-19976'] que vence el: 2025-06-10\n",
      "   🔹 IT-20642: 3.0h → Due: 2025-06-14 | Finish: Start: 2025-08-18 12:00 | End: 2025-08-18 15:00\n",
      "   🔹 IT-20286: 5.0h → Due: 2025-07-02 | Finish: Start: 2025-08-19 09:00 | End: 2025-08-19 14:00\n",
      "     🚨 Puede derivarse a: Gastón Ojeda, Alan Mori - Carestino, Nicolas Pardo, Miguel Armentano\n",
      "   🔹 IT-19910: 3.0h → Due: 2025-07-11 | Finish: Start: 2025-08-19 14:00 | End: 2025-08-20 11:30\n",
      "   🔹 IT-20759: 8.0h → Due: 2025-08-04 | Finish: Start: 2025-08-20 11:30 | End: 2025-08-21 13:00\n",
      "     🚨 Puede derivarse a: Miguel Armentano, Gastón Ojeda\n",
      "   🔹 IT-19532: 2.0h → Due: 2025-08-18 | Finish: Start: 2025-08-21 13:00 | End: 2025-08-21 15:00\n",
      "     🚨 Puede derivarse a: Miguel Armentano\n",
      "   🔹 IT-19694: 2.0h → Due: 2025-08-18 | Finish: Start: 2025-08-22 09:00 | End: 2025-08-22 11:00\n",
      "     🚨 Puede derivarse a: Gastón Ojeda\n",
      "   🔹 IT-20774: 4.0h → Due: 2025-08-26 | Finish: Start: 2025-08-22 11:00 | End: 2025-08-22 15:00\n",
      "     🚨 Puede derivarse a: Alan Mori - Carestino, Gastón Ojeda\n",
      "   🔹 IT-20765: 8.0h → Due: 2025-09-09 | Finish: Start: 2025-08-25 09:00 | End: 2025-08-26 11:00\n",
      "   🔹 IT-20761: 6.0h → Due: 2025-09-09 | Finish: Start: 2025-08-26 11:00 | End: 2025-08-27 11:00\n",
      "     🚨 Puede derivarse a: Miguel Armentano\n",
      "   🔹 IT-20772: 3.0h → Due: 2025-09-12 | Finish: Start: 2025-08-27 11:00 | End: 2025-08-27 14:00\n",
      "     🚨 Puede derivarse a: Miguel Armentano, Gastón Ojeda\n",
      "   🔹 IT-20687: 10.0h → Due: 2025-09-19 | Finish: Start: 2025-08-27 14:00 | End: 2025-08-29 11:30\n",
      "   🔹 IT-20866: 3.0h → Due: 2025-09-26 | Finish: Start: 2025-08-29 11:30 | End: 2025-08-29 14:30\n",
      "     🚨 Puede derivarse a: Nicolas Pardo, Gastón Ojeda\n",
      "   🔹 IT-20865: 3.0h → Due: 2025-10-10 | Finish: Start: 2025-09-01 08:30 | End: 2025-09-01 11:30\n",
      "\n",
      "👨‍💻 Developer: Gastón Ojeda\n",
      "   🔹 IT-20424: 14.0h → Due: 2025-05-02 | Finish: Start: 2025-08-18 09:00 | End: 2025-08-20 15:30\n",
      "   🔹 IT-20391: 21.0h → Due: 2025-05-08 | Finish: Start: 2025-08-20 15:30 | End: 2025-08-26 15:30\n",
      "     🚨 Puede derivarse a: Miguel Armentano\n",
      "   🔹 IT-20212: 5.0h → Due: 2025-07-11 | Finish: Start: 2025-08-27 09:00 | End: 2025-08-27 16:00\n",
      "   🔹 IT-20952: 8.0h → Due: 2025-07-18 | Finish: Start: 2025-08-28 09:00 | End: 2025-08-29 11:30\n",
      "   🔹 IT-20628: 5.0h → Due: 2025-07-25 | Finish: Start: 2025-08-29 11:30 | End: 2025-09-01 11:30\n",
      "     🚨 Puede derivarse a: Luis Uran\n",
      "   🔹 IT-19892: 3.0h → Due: 2025-08-01 | Finish: Start: 2025-09-01 11:30 | End: 2025-09-02 09:30\n",
      "     🚨 Puede derivarse a: Nicolas Pardo\n",
      "   🔹 IT-20828: 40.0h → Due: 2025-08-01 | Finish: Start: 2025-09-02 09:30 | End: 2025-09-12 09:30\n",
      "   🔹 IT-20458: 3.0h → Due: 2025-08-05 | Finish: Start: 2025-09-12 09:30 | End: 2025-09-12 12:30\n",
      "     🚨 Puede derivarse a: Luis Uran\n",
      "   🔹 IT-18842: 24.0h → Due: 2025-08-18 | Finish: Start: 2025-09-12 12:30 | End: 2025-09-19 11:30\n",
      "     🚨 Puede derivarse a: Luis Uran\n",
      "   🔹 IT-19973: 4.0h → Due: 2025-09-05 | Finish: Start: 2025-09-19 11:30 | End: 2025-09-22 10:30\n",
      "   🔹 IT-20384: 10.0h → Due: 2025-09-12 | Finish: Start: 2025-09-22 10:30 | End: 2025-09-24 10:30\n",
      "     🚨 Puede derivarse a: Nicolas Pardo, Luis Uran\n",
      "   🔹 IT-20636: 32.0h → Due: 2025-09-19 | Finish: Start: 2025-09-24 10:30 | End: 2025-10-02 12:30\n",
      "   🔹 IT-20638: 3.0h → Due: 2025-09-30 | Finish: Start: 2025-10-02 12:30 | End: 2025-10-03 10:30\n",
      "   🔹 IT-20382: 6.0h → Due: 2025-10-03 | Finish: Start: 2025-10-03 10:30 | End: 2025-10-06 11:30\n",
      "     🚨 Puede derivarse a: Nicolas Pardo\n",
      "   🔹 IT-20473: 3.0h → Due: 2025-11-21 | Finish: Start: 2025-10-06 11:30 | End: 2025-10-07 09:30\n",
      "     🚨 Puede derivarse a: Alan Mori - Carestino, Nicolas Pardo, Luis Uran, Miguel Armentano\n",
      "   🔹 IT-20386: 8.0h → Due: 2025-11-28 | Finish: Start: 2025-10-07 09:30 | End: 2025-10-08 12:30\n",
      "   🔹 IT-20379: 6.0h → Due: 2025-12-05 | Finish: Start: 2025-10-08 12:30 | End: 2025-10-09 13:30\n",
      "     🚨 Puede derivarse a: Miguel Armentano\n",
      "   🔹 IT-20630: 12.0h → Due: 2025-12-05 | Finish: Start: 2025-10-10 08:30 | End: 2025-10-14 10:30\n",
      "   🔹 IT-20655: 32.0h → Due: 2025-12-26 | Finish: Start: 2025-10-14 10:30 | End: 2025-10-22 12:30\n",
      "   🔹 IT-15935: 8.0h → Due: 2100-01-01 | Finish: Start: 2025-10-22 12:30 | End: 2025-10-24 10:30\n",
      "   🔹 IT-15927: 5.0h → Due: 2100-01-01 | Finish: Start: 2025-10-24 10:30 | End: 2025-10-27 10:30\n",
      "   🔹 IT-15922: 16.0h → Due: 2100-01-01 | Finish: Start: 2025-10-27 10:30 | End: 2025-10-30 11:30\n",
      "   🔹 IT-15932: 5.0h → Due: 2100-01-01 | Finish: Start: 2025-10-30 11:30 | End: 2025-10-31 11:30\n",
      "   🔹 IT-15931: 1.0h → Due: 2100-01-01 | Finish: Start: 2025-10-31 11:30 | End: 2025-10-31 12:30\n",
      "   🔹 IT-15936: 4.0h → Due: 2100-01-01 | Finish: Start: 2025-10-31 12:30 | End: 2025-11-03 11:30\n",
      "   🔹 IT-15929: 5.0h → Due: 2100-01-01 | Finish: Start: 2025-11-03 11:30 | End: 2025-11-04 11:30\n",
      "   🔹 IT-15941: 6.0h → Due: 2100-01-01 | Finish: Start: 2025-11-04 11:30 | End: 2025-11-05 12:30\n",
      "\n",
      "👨‍💻 Developer: Franco Lorenzo\n",
      "   🔹 IT-20199: 6.0h → Due: 2025-05-30 | Finish: Start: 2025-08-19 00:00 | End: 2025-08-20 11:20\n",
      "   🔹 IT-20653: 2.0h → Due: 2025-07-31 | Finish: Start: 2025-08-20 11:20 | End: 2025-08-20 14:20\n",
      "   🔹 IT-20114: 40.0h → Due: 2025-08-18 | Finish: Start: 2025-08-20 14:20 | End: 2025-09-01 11:30\n",
      "     🚨 Puede derivarse a: Nicolas Pardo, Gastón Ojeda\n",
      "   🔹 IT-20724: 8.0h → Due: 2025-08-28 | Finish: Start: 2025-09-01 11:30 | End: 2025-09-03 09:30\n",
      "   🔹 IT-20946: 24.0h → Due: 2025-08-28 | Finish: Start: 2025-09-03 09:30 | End: 2025-09-09 13:30\n",
      "   🔹 IT-20728: 8.0h → Due: 2025-08-29 | Finish: Start: 2025-09-10 08:30 | End: 2025-09-11 11:30\n",
      "   🔹 IT-20162: 76.0h → Due: 2025-09-30 | Finish: Start: 2025-09-11 11:30 | End: 2025-10-02 12:30\n",
      "   🔹 IT-20472: 4.0h → Due: 2025-10-10 | Finish: Start: 2025-10-02 12:30 | End: 2025-10-03 11:30\n",
      "   🔹 IT-20697: 20.0h → Due: 2025-12-26 | Finish: Start: 2025-10-03 11:30 | End: 2025-10-09 11:30\n",
      "   🔹 IT-20428: 6.0h → Due: 2025-12-26 | Finish: Start: 2025-10-09 11:30 | End: 2025-10-10 12:30\n",
      "   🔹 IT-20880: 24.0h → Due: 2100-01-01 | Finish: Start: 2025-10-10 12:30 | End: 2025-10-17 11:30\n",
      "   🔹 IT-18825: 4.0h → Due: 2100-01-01 | Finish: Start: 2025-10-17 11:30 | End: 2025-10-20 10:30\n",
      "\n",
      "👨‍💻 Developer: Miguel Armentano\n",
      "   🔹 IT-20992: 5.0h → Due: 2025-05-16 | Finish: Start: 2025-08-18 09:00 | End: 2025-08-18 15:00\n",
      "     🚨 Puede derivarse a: Luis Uran\n",
      "   🔹 IT-21026: 4.0h → Due: 2025-08-15 | Finish: Start: 2025-08-19 09:00 | End: 2025-08-19 14:00\n",
      "     🚨 Puede derivarse a: Luis Uran\n",
      "   🔹 IT-11525: 32.0h → Due: 2025-08-18 | Finish: Start: 2025-08-19 14:00 | End: 2025-08-28 10:00\n",
      "   🔹 IT-20103: 1.0h → Due: 2025-08-18 | Finish: Start: 2025-08-28 10:00 | End: 2025-08-28 11:00\n",
      "     🚨 Puede derivarse a: Nicolas Pardo, Gastón Ojeda\n",
      "   🔹 IT-20573: 10.0h → Due: 2025-08-18 | Finish: Start: 2025-08-28 11:00 | End: 2025-09-01 10:30\n",
      "   🔹 IT-20995: 4.0h → Due: 2025-08-28 | Finish: Start: 2025-09-01 10:30 | End: 2025-09-02 09:30\n",
      "   🔹 IT-20997: 3.0h → Due: 2025-08-29 | Finish: Start: 2025-09-02 09:30 | End: 2025-09-02 12:30\n",
      "   🔹 IT-11523: 8.0h → Due: 2026-02-20 | Finish: Start: 2025-09-02 12:30 | End: 2025-09-04 10:30\n",
      "   🔹 IT-20015: 3.0h → Due: 2100-01-01 | Finish: Start: 2025-09-04 10:30 | End: 2025-09-04 13:30\n",
      "   🔹 IT-20034: 4.0h → Due: 2100-01-01 | Finish: Start: 2025-09-05 08:30 | End: 2025-09-05 12:30\n",
      "   🔹 IT-20029: 5.0h → Due: 2100-01-01 | Finish: Start: 2025-09-05 12:30 | End: 2025-09-08 12:30\n",
      "   🔹 IT-20019: 3.0h → Due: 2100-01-01 | Finish: Start: 2025-09-08 12:30 | End: 2025-09-09 10:30\n",
      "   🔹 IT-20017: 2.0h → Due: 2100-01-01 | Finish: Start: 2025-09-09 10:30 | End: 2025-09-09 12:30\n",
      "   🔹 IT-20032: 4.0h → Due: 2100-01-01 | Finish: Start: 2025-09-09 12:30 | End: 2025-09-10 11:30\n",
      "   🔹 IT-20016: 8.0h → Due: 2100-01-01 | Finish: Start: 2025-09-10 11:30 | End: 2025-09-12 09:30\n",
      "   🔹 IT-20018: 8.0h → Due: 2100-01-01 | Finish: Start: 2025-09-12 09:30 | End: 2025-09-15 12:30\n",
      "   🔹 IT-20023: 3.0h → Due: 2100-01-01 | Finish: Start: 2025-09-15 12:30 | End: 2025-09-16 10:30\n",
      "   🔹 IT-20010: 2.0h → Due: 2100-01-01 | Finish: Start: 2025-09-16 10:30 | End: 2025-09-16 12:30\n",
      "   🔹 IT-20033: 2.0h → Due: 2100-01-01 | Finish: Start: 2025-09-16 12:30 | End: 2025-09-17 09:30\n",
      "   🔹 IT-20030: 2.0h → Due: 2100-01-01 | Finish: Start: 2025-09-17 09:30 | End: 2025-09-17 11:30\n",
      "   🔹 IT-20020: 3.0h → Due: 2100-01-01 | Finish: Start: 2025-09-17 11:30 | End: 2025-09-18 09:30\n",
      "   🔹 IT-20031: 4.0h → Due: 2100-01-01 | Finish: Start: 2025-09-18 09:30 | End: 2025-09-18 13:30\n",
      "   🔹 IT-20022: 4.0h → Due: 2100-01-01 | Finish: Start: 2025-09-19 08:30 | End: 2025-09-19 12:30\n",
      "   🔹 IT-20021: 2.0h → Due: 2100-01-01 | Finish: Start: 2025-09-19 12:30 | End: 2025-09-22 09:30\n",
      "   🔹 IT-20025: 4.0h → Due: 2100-01-01 | Finish: Start: 2025-09-22 09:30 | End: 2025-09-22 13:30\n",
      "   🔹 IT-20027: 3.0h → Due: 2100-01-01 | Finish: Start: 2025-09-23 08:30 | End: 2025-09-23 11:30\n",
      "   🔹 IT-11789: 2.0h → Due: 2100-01-01 | Finish: Start: 2025-09-23 11:30 | End: 2025-09-23 13:30\n",
      "   🔹 IT-20011: 2.0h → Due: 2100-01-01 | Finish: Start: 2025-09-24 08:30 | End: 2025-09-24 10:30\n",
      "   🔹 IT-20013: 2.0h → Due: 2100-01-01 | Finish: Start: 2025-09-24 10:30 | End: 2025-09-24 12:30\n",
      "   🔹 IT-20012: 4.0h → Due: 2100-01-01 | Finish: Start: 2025-09-24 12:30 | End: 2025-09-25 11:30\n",
      "   🔹 IT-20028: 3.0h → Due: 2100-01-01 | Finish: Start: 2025-09-25 11:30 | End: 2025-09-26 09:30\n",
      "     🚨 Puede derivarse a: Nicolas Pardo, Gastón Ojeda\n",
      "   🔹 IT-20026: 4.0h → Due: 2100-01-01 | Finish: Start: 2025-09-26 09:30 | End: 2025-09-26 13:30\n",
      "   🔹 IT-20014: 8.0h → Due: 2100-01-01 | Finish: Start: 2025-09-29 08:30 | End: 2025-09-30 11:30\n",
      "   🔹 IT-20024: 3.0h → Due: 2100-01-01 | Finish: Start: 2025-09-30 11:30 | End: 2025-10-01 09:30\n",
      "\n",
      "👨‍💻 Developer: Facundo Capua\n",
      "   🔹 IT-20398: 16h → Due: 2025-08-15 | Finish: Start: 2025-08-18 08:30 | End: 2025-08-19 16:30\n",
      "   🔹 IT-17547: 24h → Due: 2025-08-18 | Finish: Start: 2025-08-20 08:30 | End: 2025-08-22 16:30\n",
      "   🔹 IT-17538: 12.0h → Due: 2100-01-01 | Finish: Start: 2025-08-25 08:30 | End: 2025-08-26 12:30\n",
      "   🔹 IT-17531: 24.0h → Due: 2100-01-01 | Finish: Start: 2025-08-26 12:30 | End: 2025-08-29 12:30\n",
      "   🔹 IT-15195: 24.0h → Due: 2100-01-01 | Finish: Start: 2025-08-29 12:30 | End: 2025-09-03 12:30\n",
      "   🔹 IT-17529: 12.0h → Due: 2100-01-01 | Finish: Start: 2025-09-03 12:30 | End: 2025-09-04 16:30\n",
      "   🔹 IT-17544: 40h → Due: 2100-01-01 | Finish: Start: 2025-09-05 08:30 | End: 2025-09-11 16:30\n",
      "\n",
      "👨‍💻 Developer: Nicolas Pardo\n",
      "   🔹 IT-20343: 100.0h → Due: 2025-07-31 | Finish: Start: 2025-08-18 10:00 | End: 2025-09-04 16:00\n",
      "     🚨 Puede derivarse a: Gastón Ojeda\n",
      "   🔹 IT-20821: 21.0h → Due: 2025-08-18 | Finish: Start: 2025-09-04 16:00 | End: 2025-09-09 13:00\n",
      "     🚨 Puede derivarse a: Gastón Ojeda\n",
      "   🔹 IT-21049: 4.0h → Due: 2025-08-28 | Finish: Start: 2025-09-09 13:00 | End: 2025-09-10 09:00\n",
      "     🚨 Puede derivarse a: Gastón Ojeda\n",
      "   🔹 IT-20541: 20.0h → Due: 2025-09-30 | Finish: Start: 2025-09-10 09:00 | End: 2025-09-12 13:00\n",
      "     🚨 Puede derivarse a: Franco Lorenzo\n",
      "   🔹 IT-20545: 8.0h → Due: 2025-09-30 | Finish: Start: 2025-09-12 13:00 | End: 2025-09-15 13:00\n",
      "     🚨 Puede derivarse a: Franco Lorenzo\n",
      "   🔹 IT-20540: 22.0h → Due: 2025-09-30 | Finish: Start: 2025-09-15 13:00 | End: 2025-09-18 11:00\n",
      "     🚨 Puede derivarse a: Franco Lorenzo\n",
      "   🔹 IT-20543: 22.0h → Due: 2025-09-30 | Finish: Start: 2025-09-18 11:00 | End: 2025-09-23 09:00\n",
      "     🚨 Puede derivarse a: Franco Lorenzo\n",
      "   🔹 IT-20544: 20.0h → Due: 2025-09-30 | Finish: Start: 2025-09-23 09:00 | End: 2025-09-25 13:00\n",
      "     🚨 Puede derivarse a: Franco Lorenzo\n",
      "   🔹 IT-20542: 20.0h → Due: 2025-09-30 | Finish: Start: 2025-09-25 13:00 | End: 2025-09-30 09:00\n",
      "     🚨 Puede derivarse a: Franco Lorenzo\n",
      "   🔹 IT-19751: 5.0h → Due: 2025-10-02 | Finish: Start: 2025-09-30 09:00 | End: 2025-09-30 14:00\n",
      "     🚨 Puede derivarse a: Alan Mori - Carestino, Gastón Ojeda\n",
      "   🔹 IT-20427: 5.0h → Due: 2025-12-26 | Finish: Start: 2025-09-30 14:00 | End: 2025-10-01 11:00\n",
      "     🚨 Puede derivarse a: Gastón Ojeda\n",
      "\n",
      "👨‍💻 Developer: Juan Ignacio Morelis - Carestino\n",
      "   🔹 IT-17739: 2.0h → Due: 2024-10-25 | Finish: Start: 2025-08-18 08:30 | End: 2025-08-18 10:30\n",
      "   🔹 IT-19182: 4.0h → Due: 2025-08-18 | Finish: Start: 2025-08-18 10:30 | End: 2025-08-18 17:30\n",
      "\n",
      "👨‍💻 Developer: Diego Martin Gogorza\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# === LOAD DATA ===\n",
    "with open(\"jira_it_issues.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    issues = json.load(f)[\"issues\"]\n",
    "\n",
    "with open(\"epics_due_lookup.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    epic_due_lookup = json.load(f)\n",
    "\n",
    "scheduled = []\n",
    "tasks_by_dev = {}\n",
    "issue_map = {}\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "def _opt_value(v):\n",
    "    \"\"\"Si es opción (dict), devuelve .value/.name; si es lista, lista de values; otro -> tal cual.\"\"\"\n",
    "    if isinstance(v, dict):\n",
    "        return v.get(\"value\") or v.get(\"name\")\n",
    "    if isinstance(v, list):\n",
    "        out = []\n",
    "        for x in v:\n",
    "            out.append(x.get(\"value\") or x.get(\"name\") if isinstance(x, dict) else x)\n",
    "        return out\n",
    "    return v\n",
    "\n",
    "def get_cf10209_from_sd_outward(f_fields, only_link_type=None):\n",
    "    \"\"\"\n",
    "    Busca en f_fields['issuelinks'] un outwardIssue cuya key empiece con 'SD-'\n",
    "    y devuelve customfield_10209 (normalizado). Si only_link_type se setea,\n",
    "    filtra por el nombre del tipo de vínculo (p.ej. 'Problem/Incident').\n",
    "    \"\"\"\n",
    "    links = f_fields.get(\"issuelinks\") or []\n",
    "    for link in links:\n",
    "        if only_link_type and link.get(\"type\", {}).get(\"name\") != only_link_type:\n",
    "            continue\n",
    "        out = link.get(\"outwardIssue\")\n",
    "        if not out:\n",
    "            continue\n",
    "        if not str(out.get(\"key\", \"\")).startswith(\"SD-\"):\n",
    "            continue\n",
    "        lfields = (out.get(\"fields\") or {})\n",
    "        val = _opt_value(lfields.get(\"customfield_10209\"))\n",
    "        if val:\n",
    "            return val\n",
    "    return None\n",
    "\n",
    "def get_epic_key(fields):\n",
    "    \"\"\"\n",
    "    Devuelve la key de la épica asociada al issue (si existe), probando:\n",
    "    1) customfield_10008 (Epic Link) – clásico\n",
    "    2) parent.key si el parent es de tipo 'Epic' – team-managed\n",
    "    3) fields['epic'] (algunas instancias Cloud)\n",
    "    \"\"\"\n",
    "    # 1) Epic Link clásico\n",
    "    epic_link = fields.get(\"customfield_10008\")\n",
    "    if isinstance(epic_link, str) and epic_link:\n",
    "        return epic_link\n",
    "\n",
    "    # 2) parent -> Epic\n",
    "    p = fields.get(\"parent\")\n",
    "    if isinstance(p, dict):\n",
    "        p_issuetype = (p.get(\"fields\") or {}).get(\"issuetype\") or p.get(\"issuetype\") or {}\n",
    "        if str(p_issuetype.get(\"name\", \"\")).lower() == \"epic\":\n",
    "            return p.get(\"key\")\n",
    "\n",
    "    # 3) objeto 'epic'\n",
    "    e = fields.get(\"epic\")\n",
    "    if isinstance(e, dict):\n",
    "        return e.get(\"key\") or e.get(\"id\")\n",
    "\n",
    "    return None\n",
    "\n",
    "def contar_dias_laborables(start_date, end_date):\n",
    "    dias = 0\n",
    "    current = start_date\n",
    "    while current <= end_date:\n",
    "        if current.weekday() < 5:  # Lunes a Viernes\n",
    "            dias += 1\n",
    "        current += timedelta(days=1)\n",
    "    return dias\n",
    "\n",
    "for issue in issues:\n",
    "    f = issue[\"fields\"]\n",
    "    status = f.get(\"status\", {}).get(\"name\", \"\")\n",
    "    assignee = f.get(\"assignee\")\n",
    "    if not assignee:\n",
    "        continue\n",
    "    dev = assignee[\"displayName\"]\n",
    "    report = f.get(\"reporter\")\n",
    "    if not report:\n",
    "        continue\n",
    "    reporter = report[\"displayName\"]\n",
    "    key = issue[\"key\"]\n",
    "    summary = f.get(\"summary\", \"\")\n",
    "    module_info = f.get(\"customfield_10212\")\n",
    "    module_value = module_info[\"value\"] if module_info else None\n",
    "    estimate_hours = f.get(\"customfield_10608\")\n",
    "\n",
    "    if estimate_hours is None:\n",
    "        estimate_hours = f.get(\"customfield_10016\")\n",
    "\n",
    "    if estimate_hours is None:\n",
    "        estimate_seconds = f.get(\"timetracking\", {}).get(\"originalEstimateSeconds\") or f.get(\"aggregatetimeoriginalestimate\")\n",
    "        estimate_hours = estimate_seconds / 3600 if estimate_seconds else 0\n",
    "    \n",
    "    issue_to_epic = {}\n",
    "    for ekey, edata in epic_due_lookup.items():\n",
    "        for t in edata.get(\"tasks\", []):\n",
    "            k = t.get(\"key\")\n",
    "            if k:\n",
    "                issue_to_epic[k] = ekey\n",
    "    \n",
    "    epic_key = get_epic_key(f) or issue_to_epic.get(key)  # 👈 fallback desde lookup\n",
    "    epic_obj = epic_due_lookup.get(epic_key) if epic_key else None\n",
    "    epic_due_str = (epic_obj or {}).get(\"due_date\")\n",
    "\n",
    "    # Prefiere due del issue; si no hay, usa el de la épica\n",
    "    due_str = f.get(\"duedate\") or epic_due_str\n",
    "    try:\n",
    "        due_date = datetime.strptime(due_str, \"%Y-%m-%d\") if due_str else datetime(2100, 1, 1)\n",
    "    except:\n",
    "        due_date = datetime(2100, 1, 1)\n",
    "\n",
    "    cf10442_raw = f.get(\"customfield_10442\") or []\n",
    "    cf10442_names = [u.get(\"displayName\") for u in cf10442_raw if u.get(\"displayName\")]\n",
    "    suggested_devs = MODULE_DEVS.get(module_value, []) if module_value else []\n",
    "    suggested_users = list(set(suggested_devs + cf10442_names))\n",
    "\n",
    "    if dev in suggested_users:\n",
    "        suggested_users.remove(dev)\n",
    "\n",
    "    can_be_delegated = dev not in suggested_users and bool(suggested_users)\n",
    "    delegation_note = f\"🚨 Puede derivarse a: {', '.join(suggested_users)}\" if can_be_delegated else \"\"\n",
    "\n",
    "\n",
    "\n",
    "    cf10209_value = get_cf10209_from_sd_outward(\n",
    "        f_fields=f,\n",
    "        only_link_type=\"Problem/Incident\"  # o None si no querés filtrar por tipo\n",
    "    )\n",
    "    \n",
    "    task = {\n",
    "        \"key\": key,\n",
    "        \"summary\": summary,\n",
    "        \"estimate_hours\": estimate_hours,\n",
    "        \"due_date\": due_date,\n",
    "        \"assignee\": dev,\n",
    "        \"status\": status,\n",
    "        \"due_reason\": None,\n",
    "        \"module\": module_value,\n",
    "        \"suggested_users\": suggested_users,\n",
    "        \"has_epic\": bool(epic_key),\n",
    "        \"reporter\": reporter,\n",
    "        \"cf10209\": cf10209_value\n",
    "    }\n",
    "    # 🔧 Nuevo: guardar claves de tareas que bloquean esta\n",
    "    \n",
    "    issue_map[key] = task\n",
    "\n",
    "    \n",
    "    if status in VALID_STATUSES:\n",
    "        tasks_by_dev.setdefault(dev, []).append(task)\n",
    "    graph.add_node(key)\n",
    "    \n",
    "\n",
    "    # for key, task in issue_map.items():\n",
    "    #     blocker_due_dates = [\n",
    "    #         issue_map[b][\"due_date\"]\n",
    "    #         for b in graph.predecessors(key)\n",
    "    #         if b in issue_map and issue_map[b][\"due_date\"]\n",
    "    #     ]\n",
    "\n",
    "    #     if blocker_due_dates:\n",
    "    #         max_blocker_due = min(blocker_due_dates)\n",
    "    #         if task[\"due_date\"] < max_blocker_due:\n",
    "    #             task[\"due_date_original\"] = task[\"due_date\"]\n",
    "    #             task[\"due_date\"] = max_blocker_due\n",
    "\n",
    "    for link in f.get(\"issuelinks\", []):\n",
    "        if \"inwardIssue\" in link and link[\"type\"][\"name\"] == \"Blocks\":\n",
    "            graph.add_edge(link[\"inwardIssue\"][\"key\"], key)\n",
    "        elif \"outwardIssue\" in link and link[\"type\"][\"name\"] == \"Blocks\":\n",
    "            graph.add_edge(key, link[\"outwardIssue\"][\"key\"])\n",
    "\n",
    "    blockers = [src for src, tgt in graph.edges() if tgt == key]\n",
    "    task[\"blockers\"] = blockers\n",
    "\n",
    "for key, task in issue_map.items():\n",
    "    # Para cada tarea, mirar a quién bloquea\n",
    "    blocked_keys = list(graph.successors(key))\n",
    "    \n",
    "    blocked_due_dates = [\n",
    "        issue_map[b][\"due_date\"]\n",
    "        for b in blocked_keys\n",
    "        if b in issue_map and issue_map[b][\"due_date\"]\n",
    "    ]\n",
    "\n",
    "    blocker_key = [issue_map[b][\"key\"] for b in blocked_keys if b in issue_map and issue_map[b][\"key\"]]\n",
    "\n",
    "    if blocked_due_dates:\n",
    "        min_blocked_due = min(blocked_due_dates)\n",
    "        suggested_due = min_blocked_due - timedelta(days=1)\n",
    "        task[\"note\"] = (\n",
    "            f\"🕓 Fecha de vencimiento {'ajustada' if task['due_date'] > suggested_due else 'ya correcta'} \"\n",
    "            f\"por bloqueo a tarjeta {blocker_key} que vence el: {suggested_due.strftime('%Y-%m-%d')}\"\n",
    "        )\n",
    "        if task[\"due_date\"] > suggested_due:\n",
    "            task[\"due_date_original\"] = task[\"due_date\"]\n",
    "            task[\"due_date\"] = suggested_due\n",
    "            task[\"note\"] = f\"🕓 Fecha de vencimiento ajustada por bloqueo a tarjeta {blocker_key} que vence el: {suggested_due.strftime('%Y-%m-%d')}\"\n",
    "\n",
    "\n",
    "# BLOQUES POR DEV (simulados)\n",
    "bloques_por_dev = bloques\n",
    "MINIMUM_SLOT_HOURS = 0.25\n",
    "# === PLANIFICADOR POR DESARROLLADOR ===\n",
    "def to_naive(dt):\n",
    "    return dt.replace(tzinfo=None) if dt.tzinfo else dt\n",
    "\n",
    "def planificar_tareas_para_dev(dev, tasks, bloques_ocupados):\n",
    "    current_time = datetime.combine(DEFAULT_START_DATE.date(), datetime.strptime(\"08:30\", \"%H:%M\").time())\n",
    "    hours_per_day = DAILY_HOURS.get(dev, DAILY_HOURS[\"Default\"])\n",
    "    schedule = {}\n",
    "    plan = []\n",
    "\n",
    "    try:\n",
    "        sorted_keys = list(nx.topological_sort(graph.subgraph([t[\"key\"] for t in tasks])))\n",
    "    except nx.NetworkXUnfeasible:\n",
    "        sorted_keys = [t[\"key\"] for t in tasks]\n",
    "    sorted_keys.sort(key=lambda k: issue_map[k][\"due_date\"])\n",
    "\n",
    "    def to_naive(dt):\n",
    "        return dt.replace(tzinfo=None) if dt.tzinfo else dt\n",
    "    \n",
    "    for start, end in sorted(bloques_ocupados):\n",
    "            plan.append({\n",
    "                \"developer\": dev,\n",
    "                \"key\": f\"REUNION-{start.strftime('%Y%m%d%H%M')}\",\n",
    "                \"summary\": \"⛔ Reunión\",\n",
    "                \"has_epic\": False,\n",
    "                \"due_date\": start.date(),  # o end.date()\n",
    "                \"start\": to_naive(start),\n",
    "                \"end\": to_naive(end),\n",
    "                \"duration_hours\": (to_naive(end) - to_naive(start)).total_seconds() / 3600,\n",
    "                \"type\": \"reunion\"\n",
    "            })\n",
    "\n",
    "    for key in sorted_keys:\n",
    "        task = issue_map[key]\n",
    "        hours_left = task[\"estimate_hours\"]\n",
    "        start_time = None\n",
    "       \n",
    "\n",
    "        \n",
    "\n",
    "        while hours_left > 0:\n",
    "            date_str = current_time.strftime('%Y-%m-%d')\n",
    "            used_today = schedule.get(date_str, 0)\n",
    "\n",
    "            end_of_day = datetime.combine(current_time.date(), datetime.strptime(\"17:30\", \"%H:%M\").time())\n",
    "            available_time = (end_of_day - current_time).total_seconds() / 3600\n",
    "            time_slot = min(available_time, hours_per_day - used_today, hours_left)\n",
    "\n",
    "             # 🔧 NUEVO BLOQUE: limitar time_slot al hueco libre real antes del próximo conflicto\n",
    "            next_conflict_start = None\n",
    "            for start, end in sorted(bloques_ocupados):\n",
    "                if to_naive(start) > to_naive(current_time):\n",
    "                    next_conflict_start = to_naive(start)\n",
    "                    break\n",
    "\n",
    "            if next_conflict_start:\n",
    "                gap_hours = (next_conflict_start - current_time).total_seconds() / 3600\n",
    "                if gap_hours > 0:\n",
    "                    time_slot = min(time_slot, gap_hours)\n",
    "\n",
    "            if time_slot <= 0:\n",
    "                next_day = current_time.date() + timedelta(days=1)\n",
    "                while next_day.weekday() in [5, 6]:\n",
    "                    next_day += timedelta(days=1)\n",
    "                current_time = datetime.combine(next_day, datetime.strptime(\"08:30\", \"%H:%M\").time())\n",
    "                continue\n",
    "\n",
    "            proposed_end = current_time + timedelta(hours=time_slot)\n",
    "\n",
    "            bloque_conflictivo = any(\n",
    "                to_naive(start) < to_naive(proposed_end) and to_naive(end) > to_naive(current_time)\n",
    "                for start, end in bloques_ocupados\n",
    "            )\n",
    "\n",
    "            if bloque_conflictivo:\n",
    "                conflictos = [\n",
    "                    (start, end) for start, end in bloques_ocupados\n",
    "                    if to_naive(start) < to_naive(proposed_end) and to_naive(end) > to_naive(current_time)\n",
    "                ]\n",
    "                conflictos.sort(key=lambda x: to_naive(x[0]))\n",
    "                next_start = to_naive(conflictos[0][1])\n",
    "                current_time = next_start\n",
    "                continue\n",
    "\n",
    "            if start_time is None:\n",
    "                start_time = current_time\n",
    "\n",
    "            if bloque_conflictivo:\n",
    "                conflictos = [\n",
    "                    (start, end) for start, end in bloques_ocupados\n",
    "                    if to_naive(start) < to_naive(proposed_end) and to_naive(end) > to_naive(current_time)\n",
    "                ]\n",
    "                conflictos.sort(key=lambda x: to_naive(x[0]))\n",
    "                next_start = to_naive(conflictos[0][1])\n",
    "                current_time = next_start\n",
    "                continue\n",
    "\n",
    "            if start_time is None:\n",
    "                start_time = current_time\n",
    "\n",
    "            end_time = current_time + timedelta(hours=time_slot)\n",
    "            plan.append({\n",
    "                \"developer\": dev,\n",
    "                \"key\": key,\n",
    "                \"summary\": task[\"summary\"],\n",
    "                \"has_epic\": task[\"has_epic\"],\n",
    "                \"due_date\": task[\"due_date\"],\n",
    "                \"start\": current_time,\n",
    "                \"end\": end_time,\n",
    "                \"duration_hours\": time_slot,\n",
    "                \"suggested_users\": task.get(\"suggested_users\", []),\n",
    "                \"blockers\": task.get(\"blockers\", []),\n",
    "                \"note\": task.get(\"note\", \"\"),\n",
    "                \"reporter\": task.get(\"reporter\", \"\"),\n",
    "                \"cf10209\": task.get(\"cf10209\")\n",
    "            })\n",
    "            \n",
    "\n",
    "            schedule[date_str] = used_today + time_slot\n",
    "            hours_left -= time_slot\n",
    "            current_time = end_time\n",
    "\n",
    "    return plan\n",
    "\n",
    "# === PLANIFICACIÓN INICIAL ===\n",
    "# for dev in tasks_by_dev:\n",
    "#     scheduled += planificar_tareas_para_dev(dev, tasks_by_dev[dev], bloques_por_dev[dev])\n",
    "\n",
    "# === REBALANCEO ===\n",
    "planned_hours_by_dev = defaultdict(float)\n",
    "project_hours_by_dev = defaultdict(float)\n",
    "\n",
    "for s in scheduled:\n",
    "    if s.get(\"type\") == \"reunion\":\n",
    "        continue\n",
    "    planned_hours_by_dev[s[\"developer\"]] += s[\"duration_hours\"]\n",
    "    if issue_map[s[\"key\"]][\"has_epic\"]:\n",
    "        project_hours_by_dev[s[\"developer\"]] += s[\"duration_hours\"]\n",
    "\n",
    "for dev in tasks_by_dev:\n",
    "    all_tasks = tasks_by_dev[dev]\n",
    "    \n",
    "    within_range = [t for t in all_tasks if DEFAULT_START_DATE <= t[\"due_date\"] <= DEFAULT_END_DATE]\n",
    "    epic_tasks_in_range = sorted([t for t in within_range if t[\"has_epic\"]], key=lambda t: t[\"due_date\"])\n",
    "    non_epic_tasks_in_range = sorted([t for t in within_range if not t[\"has_epic\"]], key=lambda t: t[\"due_date\"], reverse=True)\n",
    "    epic_tasks_out_of_range = sorted(\n",
    "        [t for t in all_tasks if t[\"has_epic\"] and t not in within_range],\n",
    "        key=lambda t: t[\"due_date\"]\n",
    "    )\n",
    "\n",
    "    total_in_range = sum(t[\"estimate_hours\"] for t in within_range)\n",
    "    current_epic = sum(t[\"estimate_hours\"] for t in epic_tasks_in_range)\n",
    "    non_epic_hours = sum(t[\"estimate_hours\"] for t in non_epic_tasks_in_range)\n",
    "    min_ratio = MIN_PROJECT_RATIO.get(dev, MIN_PROJECT_RATIO[\"Default\"])\n",
    "\n",
    "    print(f\"\\n🔎 {dev}:\")\n",
    "    print(f\"  🎯 Epic target: {min_ratio * 100:.1f}%\")\n",
    "    print(f\"  📊 Total in range: {total_in_range:.1f} h | Epic in range: {current_epic:.1f} h\")\n",
    "    print(f\"  🔍 Epic tasks out of range: {len(epic_tasks_out_of_range)}\")\n",
    "    for t in epic_tasks_out_of_range:\n",
    "        print(f\"    - {t['key']} ({t['estimate_hours']} h) due {t['due_date'].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    # 🟨 Forzar tareas con épica fuera de rango hasta cumplir el mínimo\n",
    "    # horas_planificables_en_rango = (\n",
    "    #         sum(t[\"estimate_hours\"] for t in epic_tasks_in_range) +\n",
    "    #         sum(t[\"estimate_hours\"] for t in non_epic_tasks_in_range) +\n",
    "    #         sum(t[\"estimate_hours\"] for t in epic_tasks_out_of_range)\n",
    "    #     )\n",
    "    \n",
    "    dias_laborables = contar_dias_laborables(DEFAULT_START_DATE, DEFAULT_END_DATE)\n",
    "    horas_por_dia = DAILY_HOURS.get(dev, DAILY_HOURS[\"Default\"])\n",
    "    horas_planificables_en_rango = dias_laborables * horas_por_dia\n",
    "    while epic_tasks_out_of_range:\n",
    "        task = epic_tasks_out_of_range.pop(0)\n",
    "        task_estimate = task[\"estimate_hours\"]\n",
    "\n",
    "        # Moverla dentro del rango\n",
    "        task[\"due_date_original\"] = task[\"due_date\"]\n",
    "        print(f\" modificando {task['key']} due {t['due_date'].strftime('%Y-%m-%d')}\")\n",
    "        task[\"due_date\"] = DEFAULT_START_DATE\n",
    "        epic_tasks_in_range.append(task)\n",
    "        current_epic += task_estimate\n",
    "\n",
    "        # Recalcular ratio después de agregarla\n",
    "        ratio_actual = current_epic / horas_planificables_en_rango if horas_planificables_en_rango > 0 else 0\n",
    "        print(f\"✔️ Ratio tras forzar {task['key']}: {current_epic:.1f} / ({horas_planificables_en_rango:.1f}) = {ratio_actual * 100:.1f}%\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        if ratio_actual >= min_ratio:\n",
    "            break\n",
    "\n",
    "    # ❌ Eliminar tareas sin épica si sigue sin cumplirse el mínimo\n",
    "    ratio_actual = current_epic / (current_epic + non_epic_hours) if (current_epic + non_epic_hours) > 0 else 0\n",
    "    while non_epic_tasks_in_range and ratio_actual < min_ratio:\n",
    "        removed = non_epic_tasks_in_range.pop()\n",
    "        non_epic_hours -= removed[\"estimate_hours\"]\n",
    "        ratio_actual = current_epic / (current_epic + non_epic_hours) if (current_epic + non_epic_hours) > 0 else 0\n",
    "\n",
    "    # 🔄 Reordenar: primero épicas, luego tareas normales\n",
    "    balanced_tasks = sorted(epic_tasks_in_range, key=lambda t: t[\"due_date\"]) + \\\n",
    "                     sorted(non_epic_tasks_in_range, key=lambda t: t[\"due_date\"])\n",
    "    leftovers = [t for t in all_tasks if t not in balanced_tasks]\n",
    "    tasks_by_dev[dev] = balanced_tasks + leftovers\n",
    "\n",
    "    # 🔁 Replanificar solo ese desarrollador\n",
    "    scheduled = [s for s in scheduled if s[\"developer\"] != dev]\n",
    "    scheduled += planificar_tareas_para_dev(dev, tasks_by_dev[dev], bloques_por_dev[dev])\n",
    "\n",
    "\n",
    "# === RESUMEN FINAL ===\n",
    "scheduled_by_dev_and_key = defaultdict(lambda: defaultdict(list))\n",
    "for s in scheduled:\n",
    "    scheduled_by_dev_and_key[s[\"developer\"]][s[\"key\"]].append(s)\n",
    "\n",
    "print(\"\\n📝 Developer Task Schedule Summary:\\n\")\n",
    "for dev, tasks in tasks_by_dev.items():\n",
    "    print(f\"👨‍💻 Developer: {dev}\")\n",
    "    try:\n",
    "        sorted_keys = list(nx.topological_sort(graph.subgraph([t[\"key\"] for t in tasks])))\n",
    "    except nx.NetworkXUnfeasible:\n",
    "        sorted_keys = [t[\"key\"] for t in tasks]\n",
    "    sorted_keys.sort(key=lambda k: issue_map[k][\"due_date\"])\n",
    "    for key in sorted_keys:\n",
    "        task = issue_map[key]\n",
    "        scheds = sorted(scheduled_by_dev_and_key[dev].get(key, []), key=lambda x: x[\"start\"])\n",
    "        if not scheds:\n",
    "            continue\n",
    "        start_time = scheds[0][\"start\"]\n",
    "        end_time = scheds[-1][\"end\"]\n",
    "        total_hours = sum(s[\"duration_hours\"] for s in scheds)\n",
    "        note_lines = []\n",
    "        if \"note\" in task and task[\"note\"]:\n",
    "            note_lines.append(task[\"note\"])\n",
    "\n",
    "        # 🚨 Sugerencias de derivación\n",
    "        if task.get(\"suggested_users\"):\n",
    "            note_lines.append(f\"🚨 Puede derivarse a: {', '.join(task['suggested_users'])}\")\n",
    "\n",
    "        # 📛 Bloqueadores\n",
    "        if task.get(\"blockers\"):\n",
    "            blocker_msgs = []\n",
    "            for blocker_key in task[\"blockers\"]:\n",
    "                blocker = issue_map.get(blocker_key)\n",
    "                if blocker:\n",
    "                    blocker_msgs.append(f\"{blocker_key}: {blocker['summary']} ({blocker['assignee']}, Due: {blocker['due_date'].strftime('%Y-%m-%d')})\")\n",
    "                else:\n",
    "                    blocker_msgs.append(blocker_key)\n",
    "            note_lines.append(f\"📛 Debido a bloqueo de: \" + \" | \".join(blocker_msgs))\n",
    "\n",
    "         # Agregar nota personalizada si existe\n",
    "        if \"note\" in task and task[\"note\"]:\n",
    "            note_lines.append(task[\"note\"])\n",
    "\n",
    "        note = \"\\n     \" + \"\\n     \".join(note_lines) if note_lines else \"\"\n",
    "        print(\n",
    "            f\"   🔹 {key}: {round(total_hours, 1)}h → Due: {task['due_date'].strftime('%Y-%m-%d')} | \"\n",
    "            f\"Finish: Start: {start_time.strftime('%Y-%m-%d %H:%M')} | End: {end_time.strftime('%Y-%m-%d %H:%M')}{note}\"\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1245495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Estadísticas de horas (entre 2025-08-18 y 2025-08-29):\n",
      "\n",
      "👨‍💻 Alan Mori - Carestino\n",
      "   🟨 Con épica: 0.0 h (0.0%)\n",
      "   🟦 Sin épica: 49.5 h (100.0%)\n",
      "   📌 Total: 49.5 h\n",
      "\n",
      "👨‍💻 Luis Uran\n",
      "   🟨 Con épica: 0.0 h (0.0%)\n",
      "   🟦 Sin épica: 54.0 h (100.0%)\n",
      "   📌 Total: 54.0 h\n",
      "\n",
      "👨‍💻 Gastón Ojeda\n",
      "   🟨 Con épica: 0.0 h (0.0%)\n",
      "   🟦 Sin épica: 45.0 h (100.0%)\n",
      "   📌 Total: 45.0 h\n",
      "\n",
      "👨‍💻 Franco Lorenzo\n",
      "   🟨 Con épica: 0.0 h (0.0%)\n",
      "   🟦 Sin épica: 40.0 h (100.0%)\n",
      "   📌 Total: 40.0 h\n",
      "\n",
      "👨‍💻 Miguel Armentano\n",
      "   🟨 Con épica: 0.0 h (0.0%)\n",
      "   🟦 Sin épica: 45.0 h (100.0%)\n",
      "   📌 Total: 45.0 h\n",
      "\n",
      "👨‍💻 Facundo Capua\n",
      "   🟨 Con épica: 0.0 h (0.0%)\n",
      "   🟦 Sin épica: 72.0 h (100.0%)\n",
      "   📌 Total: 72.0 h\n",
      "\n",
      "👨‍💻 Nicolas Pardo\n",
      "   🟨 Con épica: 0.0 h (0.0%)\n",
      "   🟦 Sin épica: 60.5 h (100.0%)\n",
      "   📌 Total: 60.5 h\n",
      "\n",
      "👨‍💻 Juan Ignacio Morelis - Carestino\n",
      "   🟨 Con épica: 0.0 h (0.0%)\n",
      "   🟦 Sin épica: 6.0 h (100.0%)\n",
      "   📌 Total: 6.0 h\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "# Cálculo de horas trabajadas con y sin épica por desarrollador SOLO en la ventana de 11 días\n",
    "epic_stats = defaultdict(lambda: {\"con_epica\": 0.0, \"sin_epica\": 0.0})\n",
    "\n",
    "for s in scheduled:\n",
    "    dev = s[\"developer\"]\n",
    "    key = s[\"key\"]\n",
    "    start = s[\"start\"]\n",
    "\n",
    "    # Solo incluir tareas dentro del rango\n",
    "    if not (DEFAULT_START_DATE <= start <= DEFAULT_END_DATE):\n",
    "        continue\n",
    "\n",
    "    task = issue_map.get(key)\n",
    "    if not task:\n",
    "        continue\n",
    "\n",
    "    estimate = s[\"duration_hours\"]\n",
    "    parent_key = issues[[i[\"key\"] for i in issues].index(key)][\"fields\"].get(\"parent\", {}).get(\"key\")\n",
    "\n",
    "    if parent_key:\n",
    "        epic_stats[dev][\"con_epica\"] += estimate\n",
    "    else:\n",
    "        epic_stats[dev][\"sin_epica\"] += estimate\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"\\n📊 Estadísticas de horas (entre {DEFAULT_START_DATE.strftime('%Y-%m-%d')} y {DEFAULT_END_DATE.strftime('%Y-%m-%d')}):\\n\")\n",
    "\n",
    "for dev, stats in epic_stats.items():\n",
    "    con_epica = stats[\"con_epica\"]\n",
    "    sin_epica = stats[\"sin_epica\"]\n",
    "    total = con_epica + sin_epica\n",
    "    pct_con = (con_epica / total * 100) if total > 0 else 0\n",
    "    pct_sin = (sin_epica / total * 100) if total > 0 else 0\n",
    "\n",
    "    print(f\"👨‍💻 {dev}\")\n",
    "    print(f\"   🟨 Con épica: {con_epica:.1f} h ({pct_con:.1f}%)\")\n",
    "    print(f\"   🟦 Sin épica: {sin_epica:.1f} h ({pct_sin:.1f}%)\")\n",
    "    print(f\"   📌 Total: {total:.1f} h\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfff08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"planificacion.json\", \"w\") as f:\n",
    "    json.dump(scheduled, f, default=str, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
